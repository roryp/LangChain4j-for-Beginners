<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f538a51cfd13147d40d84e936a0f485c",
  "translation_date": "2025-12-13T16:42:08+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "fr"
}
-->
# Module 03 : RAG (Retrieval-Augmented Generation)

## Table des mati√®res

- [Ce que vous apprendrez](../../../03-rag)
- [Pr√©requis](../../../03-rag)
- [Comprendre RAG](../../../03-rag)
- [Comment √ßa fonctionne](../../../03-rag)
  - [Traitement des documents](../../../03-rag)
  - [Cr√©ation des embeddings](../../../03-rag)
  - [Recherche s√©mantique](../../../03-rag)
  - [G√©n√©ration de r√©ponses](../../../03-rag)
- [Ex√©cuter l'application](../../../03-rag)
- [Utiliser l'application](../../../03-rag)
  - [T√©l√©charger un document](../../../03-rag)
  - [Poser des questions](../../../03-rag)
  - [V√©rifier les r√©f√©rences sources](../../../03-rag)
  - [Exp√©rimenter avec les questions](../../../03-rag)
- [Concepts cl√©s](../../../03-rag)
  - [Strat√©gie de d√©coupage](../../../03-rag)
  - [Scores de similarit√©](../../../03-rag)
  - [Stockage en m√©moire](../../../03-rag)
  - [Gestion de la fen√™tre de contexte](../../../03-rag)
- [Quand RAG est important](../../../03-rag)
- [√âtapes suivantes](../../../03-rag)

## Ce que vous apprendrez

Dans les modules pr√©c√©dents, vous avez appris √† avoir des conversations avec l'IA et √† structurer efficacement vos prompts. Mais il y a une limitation fondamentale : les mod√®les de langage ne savent que ce qu'ils ont appris pendant leur entra√Ænement. Ils ne peuvent pas r√©pondre √† des questions sur les politiques de votre entreprise, la documentation de votre projet, ou toute information sur laquelle ils n'ont pas √©t√© entra√Æn√©s.

RAG (Retrieval-Augmented Generation) r√©sout ce probl√®me. Au lieu d'essayer d'enseigner vos informations au mod√®le (ce qui est co√ªteux et peu pratique), vous lui donnez la capacit√© de rechercher dans vos documents. Lorsqu'une question est pos√©e, le syst√®me trouve les informations pertinentes et les inclut dans le prompt. Le mod√®le r√©pond alors en se basant sur ce contexte r√©cup√©r√©.

Pensez √† RAG comme √† une biblioth√®que de r√©f√©rence pour le mod√®le. Lorsque vous posez une question, le syst√®me :

1. **Requ√™te utilisateur** - Vous posez une question  
2. **Embedding** - Convertit votre question en vecteur  
3. **Recherche vectorielle** - Trouve des morceaux de documents similaires  
4. **Assemblage du contexte** - Ajoute les morceaux pertinents au prompt  
5. **R√©ponse** - Le LLM g√©n√®re une r√©ponse bas√©e sur le contexte  

Cela ancre les r√©ponses du mod√®le dans vos donn√©es r√©elles au lieu de s'appuyer sur ses connaissances d'entra√Ænement ou d'inventer des r√©ponses.

<img src="../../../translated_images/rag-architecture.ccb53b71a6ce407f.fr.png" alt="Architecture RAG" width="800"/>

*Flux de travail RAG - de la requ√™te utilisateur √† la recherche s√©mantique jusqu'√† la g√©n√©ration de r√©ponse contextuelle*

## Pr√©requis

- Module 01 compl√©t√© (ressources Azure OpenAI d√©ploy√©es)  
- Fichier `.env` dans le r√©pertoire racine avec les identifiants Azure (cr√©√© par `azd up` dans le Module 01)  

> **Note :** Si vous n'avez pas termin√© le Module 01, suivez d'abord les instructions de d√©ploiement l√†-bas.

## Comment √ßa fonctionne

**Traitement des documents** - [DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

Lorsque vous t√©l√©chargez un document, le syst√®me le d√©coupe en morceaux - des parties plus petites qui tiennent confortablement dans la fen√™tre de contexte du mod√®le. Ces morceaux se chevauchent l√©g√®rement pour ne pas perdre le contexte aux fronti√®res.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```
  
> **ü§ñ Essayez avec [GitHub Copilot](https://github.com/features/copilot) Chat :** Ouvrez [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) et demandez :  
> - "Comment LangChain4j d√©coupe-t-il les documents en morceaux et pourquoi le chevauchement est-il important ?"  
> - "Quelle est la taille optimale des morceaux pour diff√©rents types de documents et pourquoi ?"  
> - "Comment g√©rer les documents en plusieurs langues ou avec une mise en forme sp√©ciale ?"

**Cr√©ation des embeddings** - [LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Chaque morceau est converti en une repr√©sentation num√©rique appel√©e embedding - essentiellement une empreinte math√©matique qui capture le sens du texte. Des textes similaires produisent des embeddings similaires.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```
  
<img src="../../../translated_images/vector-embeddings.2ef7bdddac79a327.fr.png" alt="Espace des embeddings vectoriels" width="800"/>

*Documents repr√©sent√©s comme des vecteurs dans l'espace des embeddings - les contenus similaires se regroupent*

**Recherche s√©mantique** - [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Lorsque vous posez une question, votre question devient aussi un embedding. Le syst√®me compare l'embedding de votre question avec tous les embeddings des morceaux de documents. Il trouve les morceaux ayant les significations les plus proches - pas seulement des mots-cl√©s correspondants, mais une similarit√© s√©mantique r√©elle.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```
  
> **ü§ñ Essayez avec [GitHub Copilot](https://github.com/features/copilot) Chat :** Ouvrez [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) et demandez :  
> - "Comment fonctionne la recherche de similarit√© avec les embeddings et qu'est-ce qui d√©termine le score ?"  
> - "Quel seuil de similarit√© devrais-je utiliser et comment cela affecte-t-il les r√©sultats ?"  
> - "Comment g√©rer les cas o√π aucun document pertinent n'est trouv√© ?"

**G√©n√©ration de r√©ponses** - [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Les morceaux les plus pertinents sont inclus dans le prompt envoy√© au mod√®le. Le mod√®le lit ces morceaux sp√©cifiques et r√©pond √† votre question en se basant sur ces informations. Cela √©vite les hallucinations - le mod√®le ne peut r√©pondre qu'√† partir de ce qui lui est fourni.

## Ex√©cuter l'application

**V√©rifier le d√©ploiement :**

Assurez-vous que le fichier `.env` existe dans le r√©pertoire racine avec les identifiants Azure (cr√©√© lors du Module 01) :  
```bash
cat ../.env  # Devrait afficher AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**D√©marrer l'application :**

> **Note :** Si vous avez d√©j√† d√©marr√© toutes les applications avec `./start-all.sh` depuis le Module 01, ce module tourne d√©j√† sur le port 8081. Vous pouvez ignorer les commandes de d√©marrage ci-dessous et aller directement sur http://localhost:8081.

**Option 1 : Utiliser le Spring Boot Dashboard (recommand√© pour les utilisateurs VS Code)**

Le conteneur de d√©veloppement inclut l'extension Spring Boot Dashboard, qui fournit une interface visuelle pour g√©rer toutes les applications Spring Boot. Vous la trouverez dans la barre d'activit√© √† gauche de VS Code (cherchez l'ic√¥ne Spring Boot).

Depuis le Spring Boot Dashboard, vous pouvez :  
- Voir toutes les applications Spring Boot disponibles dans l'espace de travail  
- D√©marrer/arr√™ter les applications en un clic  
- Voir les logs des applications en temps r√©el  
- Surveiller l'√©tat des applications  

Cliquez simplement sur le bouton lecture √† c√¥t√© de "rag" pour d√©marrer ce module, ou d√©marrez tous les modules en m√™me temps.

<img src="../../../translated_images/dashboard.fbe6e28bf4267ffe.fr.png" alt="Spring Boot Dashboard" width="400"/>

**Option 2 : Utiliser les scripts shell**

D√©marrer toutes les applications web (modules 01-04) :

**Bash :**  
```bash
cd ..  # Depuis le r√©pertoire racine
./start-all.sh
```
  
**PowerShell :**  
```powershell
cd ..  # Depuis le r√©pertoire racine
.\start-all.ps1
```
  
Ou d√©marrer uniquement ce module :

**Bash :**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell :**  
```powershell
cd 03-rag
.\start.ps1
```
  
Les deux scripts chargent automatiquement les variables d'environnement depuis le fichier `.env` racine et construiront les JARs s'ils n'existent pas.

> **Note :** Si vous pr√©f√©rez construire manuellement tous les modules avant de d√©marrer :  
>  
> **Bash :**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
> **PowerShell :**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
Ouvrez http://localhost:8081 dans votre navigateur.

**Pour arr√™ter :**

**Bash :**  
```bash
./stop.sh  # Ce module uniquement
# Ou
cd .. && ./stop-all.sh  # Tous les modules
```
  
**PowerShell :**  
```powershell
.\stop.ps1  # Ce module seulement
# Ou
cd ..; .\stop-all.ps1  # Tous les modules
```
  
## Utiliser l'application

L'application fournit une interface web pour le t√©l√©chargement de documents et la pose de questions.

<a href="images/rag-homepage.png"><img src="../../../translated_images/rag-homepage.d90eb5ce1b3caa94.fr.png" alt="Interface de l'application RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Interface de l'application RAG - t√©l√©chargez des documents et posez des questions*

**T√©l√©charger un document**

Commencez par t√©l√©charger un document - les fichiers TXT fonctionnent le mieux pour les tests. Un `sample-document.txt` est fourni dans ce r√©pertoire, contenant des informations sur les fonctionnalit√©s de LangChain4j, l'impl√©mentation RAG, et les bonnes pratiques - parfait pour tester le syst√®me.

Le syst√®me traite votre document, le d√©coupe en morceaux, et cr√©e des embeddings pour chaque morceau. Cela se fait automatiquement lors du t√©l√©chargement.

**Poser des questions**

Posez maintenant des questions sp√©cifiques sur le contenu du document. Essayez quelque chose de factuel clairement indiqu√© dans le document. Le syst√®me recherche les morceaux pertinents, les inclut dans le prompt, et g√©n√®re une r√©ponse.

**V√©rifier les r√©f√©rences sources**

Notez que chaque r√©ponse inclut des r√©f√©rences sources avec des scores de similarit√©. Ces scores (de 0 √† 1) montrent √† quel point chaque morceau √©tait pertinent pour votre question. Des scores plus √©lev√©s signifient de meilleures correspondances. Cela vous permet de v√©rifier la r√©ponse par rapport au mat√©riel source.

<a href="images/rag-query-results.png"><img src="../../../translated_images/rag-query-results.6d69fcec5397f355.fr.png" alt="R√©sultats de requ√™te RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*R√©sultats de requ√™te montrant la r√©ponse avec r√©f√©rences sources et scores de pertinence*

**Exp√©rimenter avec les questions**

Essayez diff√©rents types de questions :  
- Faits sp√©cifiques : "Quel est le sujet principal ?"  
- Comparaisons : "Quelle est la diff√©rence entre X et Y ?"  
- R√©sum√©s : "R√©sumez les points cl√©s √† propos de Z"  

Observez comment les scores de pertinence changent en fonction de la correspondance entre votre question et le contenu du document.

## Concepts cl√©s

**Strat√©gie de d√©coupage**

Les documents sont d√©coup√©s en morceaux de 300 tokens avec un chevauchement de 30 tokens. Cet √©quilibre garantit que chaque morceau a suffisamment de contexte pour √™tre significatif tout en restant assez petit pour inclure plusieurs morceaux dans un prompt.

**Scores de similarit√©**

Les scores vont de 0 √† 1 :  
- 0,7-1,0 : Tr√®s pertinent, correspondance exacte  
- 0,5-0,7 : Pertinent, bon contexte  
- En dessous de 0,5 : Filtr√©, trop dissemblable  

Le syst√®me ne r√©cup√®re que les morceaux au-dessus du seuil minimum pour garantir la qualit√©.

**Stockage en m√©moire**

Ce module utilise un stockage en m√©moire pour la simplicit√©. Lorsque vous red√©marrez l'application, les documents t√©l√©charg√©s sont perdus. Les syst√®mes en production utilisent des bases de donn√©es vectorielles persistantes comme Qdrant ou Azure AI Search.

**Gestion de la fen√™tre de contexte**

Chaque mod√®le a une fen√™tre de contexte maximale. Vous ne pouvez pas inclure tous les morceaux d'un document volumineux. Le syst√®me r√©cup√®re les N morceaux les plus pertinents (par d√©faut 5) pour rester dans les limites tout en fournissant assez de contexte pour des r√©ponses pr√©cises.

## Quand RAG est important

**Utilisez RAG lorsque :**  
- Vous r√©pondez √† des questions sur des documents propri√©taires  
- Les informations changent fr√©quemment (politiques, prix, sp√©cifications)  
- La pr√©cision n√©cessite une attribution des sources  
- Le contenu est trop volumineux pour tenir dans un seul prompt  
- Vous avez besoin de r√©ponses v√©rifiables et fond√©es  

**N'utilisez pas RAG lorsque :**  
- Les questions n√©cessitent des connaissances g√©n√©rales que le mod√®le poss√®de d√©j√†  
- Des donn√©es en temps r√©el sont n√©cessaires (RAG fonctionne sur des documents t√©l√©charg√©s)  
- Le contenu est assez petit pour √™tre inclus directement dans les prompts  

## √âtapes suivantes

**Module suivant :** [04-tools - Agents IA avec outils](../04-tools/README.md)

---

**Navigation :** [‚Üê Pr√©c√©dent : Module 02 - Ing√©nierie des prompts](../02-prompt-engineering/README.md) | [Retour au principal](../README.md) | [Suivant : Module 04 - Outils ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Avertissement** :  
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle r√©alis√©e par un humain est recommand√©e. Nous d√©clinons toute responsabilit√© en cas de malentendus ou de mauvaises interpr√©tations r√©sultant de l‚Äôutilisation de cette traduction.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->