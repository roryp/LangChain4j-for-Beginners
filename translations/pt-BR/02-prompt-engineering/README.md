# M√≥dulo 02: Engenharia de Prompt com GPT-5

## √çndice

- [O Que Voc√™ Vai Aprender](../../../02-prompt-engineering)
- [Pr√©-requisitos](../../../02-prompt-engineering)
- [Entendendo Engenharia de Prompt](../../../02-prompt-engineering)
- [Como Isso Usa LangChain4j](../../../02-prompt-engineering)
- [Os Padr√µes Principais](../../../02-prompt-engineering)
- [Usando Recursos Existentes do Azure](../../../02-prompt-engineering)
- [Capturas de Tela da Aplica√ß√£o](../../../02-prompt-engineering)
- [Explorando os Padr√µes](../../../02-prompt-engineering)
  - [Baixa vs Alta Disposi√ß√£o](../../../02-prompt-engineering)
  - [Execu√ß√£o de Tarefas (Pre√¢mbulos de Ferramentas)](../../../02-prompt-engineering)
  - [C√≥digo Auto-Reflexivo](../../../02-prompt-engineering)
  - [An√°lise Estruturada](../../../02-prompt-engineering)
  - [Chat Multi-Turno](../../../02-prompt-engineering)
  - [Racioc√≠nio Passo a Passo](../../../02-prompt-engineering)
  - [Sa√≠da Constrangida](../../../02-prompt-engineering)
- [O Que Voc√™ Est√° Realmente Aprendendo](../../../02-prompt-engineering)
- [Pr√≥ximos Passos](../../../02-prompt-engineering)

## O Que Voc√™ Vai Aprender

No m√≥dulo anterior, voc√™ viu como a mem√≥ria habilita IA conversacional e usou Modelos do GitHub para intera√ß√µes b√°sicas. Agora vamos focar em como voc√™ faz perguntas - os pr√≥prios prompts - usando o GPT-5 do Azure OpenAI. A forma como voc√™ estrutura seus prompts afeta dramaticamente a qualidade das respostas que recebe.

Usaremos o GPT-5 porque ele introduz controle de racioc√≠nio - voc√™ pode dizer ao modelo quanto pensar antes de responder. Isso torna diferentes estrat√©gias de prompting mais evidentes e ajuda voc√™ a entender quando usar cada abordagem. Tamb√©m nos beneficiaremos dos limites de taxa menores do Azure para GPT-5 em compara√ß√£o com os Modelos do GitHub.

## Pr√©-requisitos

- M√≥dulo 01 conclu√≠do (recursos Azure OpenAI implantados)
- Arquivo `.env` no diret√≥rio raiz com credenciais do Azure (criado pelo `azd up` no M√≥dulo 01)

> **Nota:** Se voc√™ n√£o concluiu o M√≥dulo 01, siga primeiro as instru√ß√µes de implanta√ß√£o l√°.

## Entendendo Engenharia de Prompt

Engenharia de prompt √© sobre projetar texto de entrada que consistentemente lhe d√° os resultados que voc√™ precisa. N√£o √© apenas fazer perguntas - √© estruturar solicita√ß√µes para que o modelo entenda exatamente o que voc√™ quer e como entregar.

Pense nisso como dar instru√ß√µes a um colega. "Conserte o bug" √© vago. "Conserte a exce√ß√£o de ponteiro nulo em UserService.java linha 45 adicionando uma verifica√ß√£o de nulo" √© espec√≠fico. Modelos de linguagem funcionam da mesma forma - especificidade e estrutura importam.

## Como Isso Usa LangChain4j

Este m√≥dulo demonstra padr√µes avan√ßados de prompting usando a mesma base LangChain4j dos m√≥dulos anteriores, com foco na estrutura do prompt e controle de racioc√≠nio.

<img src="../../../translated_images/pt-BR/langchain4j-flow.48e534666213010b.webp" alt="Fluxo LangChain4j" width="800"/>

*Como LangChain4j conecta seus prompts ao Azure OpenAI GPT-5*

**Depend√™ncias** - O M√≥dulo 02 usa as seguintes depend√™ncias langchain4j definidas em `pom.xml`:
```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Configura√ß√£o OpenAiOfficialChatModel** - [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java)

O modelo de chat √© configurado manualmente como um bean Spring usando o cliente oficial OpenAI, que suporta endpoints Azure OpenAI. A principal diferen√ßa do M√≥dulo 01 √© como estruturamos os prompts enviados para `chatModel.chat()`, n√£o a configura√ß√£o do modelo em si.

**Mensagens do Sistema e do Usu√°rio** - [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)

LangChain4j separa tipos de mensagem para clareza. `SystemMessage` define o comportamento e contexto da IA (como "Voc√™ √© um revisor de c√≥digo"), enquanto `UserMessage` cont√©m a solicita√ß√£o real. Essa separa√ß√£o permite manter comportamento consistente da IA em diferentes consultas de usu√°rio.

```java
SystemMessage systemMsg = SystemMessage.from(
    "You are a helpful Java programming expert."
);

UserMessage userMsg = UserMessage.from(
    "Explain what a List is in Java"
);

String response = chatModel.chat(systemMsg, userMsg);
```

<img src="../../../translated_images/pt-BR/message-types.93e0779798a17c9d.webp" alt="Arquitetura dos Tipos de Mensagem" width="800"/>

*SystemMessage fornece contexto persistente enquanto UserMessages cont√™m solicita√ß√µes individuais*

**MessageWindowChatMemory para Multi-Turno** - Para o padr√£o de conversa multi-turno, reutilizamos `MessageWindowChatMemory` do M√≥dulo 01. Cada sess√£o recebe sua pr√≥pria inst√¢ncia de mem√≥ria armazenada em um `Map<String, ChatMemory>`, permitindo m√∫ltiplas conversas simult√¢neas sem mistura de contexto.

**Templates de Prompt** - O foco real aqui √© engenharia de prompt, n√£o novas APIs LangChain4j. Cada padr√£o (baixa disposi√ß√£o, alta disposi√ß√£o, execu√ß√£o de tarefa, etc.) usa o mesmo m√©todo `chatModel.chat(prompt)` mas com strings de prompt cuidadosamente estruturadas. As tags XML, instru√ß√µes e formata√ß√£o s√£o todas parte do texto do prompt, n√£o recursos do LangChain4j.

**Controle de Racioc√≠nio** - O esfor√ßo de racioc√≠nio do GPT-5 √© controlado por instru√ß√µes no prompt como "m√°ximo 2 passos de racioc√≠nio" ou "explore minuciosamente". Essas s√£o t√©cnicas de engenharia de prompt, n√£o configura√ß√µes do LangChain4j. A biblioteca simplesmente entrega seus prompts ao modelo.

A principal li√ß√£o: LangChain4j fornece a infraestrutura (conex√£o do modelo via [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java), mem√≥ria, manipula√ß√£o de mensagens via [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)), enquanto este m√≥dulo ensina como criar prompts eficazes dentro dessa infraestrutura.

## Os Padr√µes Principais

Nem todos os problemas precisam da mesma abordagem. Algumas perguntas precisam de respostas r√°pidas, outras de pensamento profundo. Algumas precisam de racioc√≠nio vis√≠vel, outras s√≥ dos resultados. Este m√≥dulo cobre oito padr√µes de prompting - cada um otimizado para diferentes cen√°rios. Voc√™ experimentar√° todos para aprender quando cada abordagem funciona melhor.

<img src="../../../translated_images/pt-BR/eight-patterns.fa1ebfdf16f71e9a.webp" alt="Oito Padr√µes de Prompting" width="800"/>

*Vis√£o geral dos oito padr√µes de engenharia de prompt e seus casos de uso*

<img src="../../../translated_images/pt-BR/reasoning-effort.db4a3ba5b8e392c1.webp" alt="Compara√ß√£o de Esfor√ßo de Racioc√≠nio" width="800"/>

*Baixa disposi√ß√£o (r√°pido, direto) vs Alta disposi√ß√£o (minucioso, explorat√≥rio) abordagens de racioc√≠nio*

**Baixa Disposi√ß√£o (R√°pido & Focado)** - Para perguntas simples onde voc√™ quer respostas r√°pidas e diretas. O modelo faz racioc√≠nio m√≠nimo - m√°ximo 2 passos. Use para c√°lculos, consultas ou perguntas diretas.

```java
String prompt = """
    <reasoning_effort>low</reasoning_effort>
    <instruction>maximum 2 reasoning steps</instruction>
    
    What is 15% of 200?
    """;

String response = chatModel.chat(prompt);
```

> üí° **Explore com GitHub Copilot:** Abra [`Gpt5PromptService.java`](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java) e pergunte:
> - "Qual a diferen√ßa entre os padr√µes de prompting de baixa disposi√ß√£o e alta disposi√ß√£o?"
> - "Como as tags XML nos prompts ajudam a estruturar a resposta da IA?"
> - "Quando devo usar padr√µes de autorreflex√£o vs instru√ß√£o direta?"

**Alta Disposi√ß√£o (Profundo & Minucioso)** - Para problemas complexos onde voc√™ quer an√°lise abrangente. O modelo explora minuciosamente e mostra racioc√≠nio detalhado. Use para design de sistemas, decis√µes de arquitetura ou pesquisas complexas.

```java
String prompt = """
    <reasoning_effort>high</reasoning_effort>
    <instruction>explore thoroughly, show detailed reasoning</instruction>
    
    Design a caching strategy for a high-traffic REST API.
    """;

String response = chatModel.chat(prompt);
```

**Execu√ß√£o de Tarefas (Progresso Passo a Passo)** - Para fluxos de trabalho multi-etapas. O modelo fornece um plano inicial, narra cada passo enquanto trabalha, depois d√° um resumo. Use para migra√ß√µes, implementa√ß√µes ou qualquer processo multi-etapas.

```java
String prompt = """
    <task>Create a REST endpoint for user registration</task>
    <preamble>Provide an upfront plan</preamble>
    <narration>Narrate each step as you work</narration>
    <summary>Summarize what was accomplished</summary>
    """;

String response = chatModel.chat(prompt);
```

Prompting Chain-of-Thought pede explicitamente ao modelo para mostrar seu processo de racioc√≠nio, melhorando a precis√£o para tarefas complexas. A divis√£o passo a passo ajuda humanos e IA a entenderem a l√≥gica.

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Pergunte sobre este padr√£o:
> - "Como eu adaptaria o padr√£o de execu√ß√£o de tarefas para opera√ß√µes de longa dura√ß√£o?"
> - "Quais s√£o as melhores pr√°ticas para estruturar pre√¢mbulos de ferramentas em aplica√ß√µes de produ√ß√£o?"
> - "Como posso capturar e exibir atualiza√ß√µes intermedi√°rias de progresso em uma interface?"

<img src="../../../translated_images/pt-BR/task-execution-pattern.9da3967750ab5c1e.webp" alt="Padr√£o de Execu√ß√£o de Tarefas" width="800"/>

*Planejar ‚Üí Executar ‚Üí Resumir fluxo de trabalho para tarefas multi-etapas*

**C√≥digo Auto-Reflexivo** - Para gerar c√≥digo com qualidade de produ√ß√£o. O modelo gera c√≥digo, verifica contra crit√©rios de qualidade e melhora iterativamente. Use ao construir novas funcionalidades ou servi√ßos.

```java
String prompt = """
    <task>Create an email validation service</task>
    <quality_criteria>
    - Correct logic and error handling
    - Best practices (clean code, proper naming)
    - Performance optimization
    - Security considerations
    </quality_criteria>
    <instruction>Generate code, evaluate against criteria, improve iteratively</instruction>
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/pt-BR/self-reflection-cycle.6f71101ca0bd28cc.webp" alt="Ciclo de Auto-Reflex√£o" width="800"/>

*Loop de melhoria iterativa - gerar, avaliar, identificar problemas, melhorar, repetir*

**An√°lise Estruturada** - Para avalia√ß√£o consistente. O modelo revisa c√≥digo usando um framework fixo (corre√ß√£o, pr√°ticas, desempenho, seguran√ßa). Use para revis√µes de c√≥digo ou avalia√ß√µes de qualidade.

```java
String prompt = """
    <code>
    public List getUsers() {
        return database.query("SELECT * FROM users");
    }
    </code>
    
    <framework>
    Evaluate using these categories:
    1. Correctness - Logic and functionality
    2. Best Practices - Code quality
    3. Performance - Efficiency concerns
    4. Security - Vulnerabilities
    </framework>
    """;

String response = chatModel.chat(prompt);
```

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Pergunte sobre an√°lise estruturada:
> - "Como posso personalizar o framework de an√°lise para diferentes tipos de revis√£o de c√≥digo?"
> - "Qual a melhor forma de analisar e agir sobre sa√≠da estruturada programaticamente?"
> - "Como garantir n√≠veis consistentes de severidade em diferentes sess√µes de revis√£o?"

<img src="../../../translated_images/pt-BR/structured-analysis-pattern.0af3b690b60cf2d6.webp" alt="Padr√£o de An√°lise Estruturada" width="800"/>

*Framework de quatro categorias para revis√µes de c√≥digo consistentes com n√≠veis de severidade*

**Chat Multi-Turno** - Para conversas que precisam de contexto. O modelo lembra mensagens anteriores e constr√≥i sobre elas. Use para sess√µes de ajuda interativas ou Q&A complexos.

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("What is Spring Boot?"));
AiMessage aiMessage1 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage1);

memory.add(UserMessage.from("Show me an example"));
AiMessage aiMessage2 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage2);
```

<img src="../../../translated_images/pt-BR/context-memory.dff30ad9fa78832a.webp" alt="Mem√≥ria de Contexto" width="800"/>

*Como o contexto da conversa se acumula em m√∫ltiplos turnos at√© atingir o limite de tokens*

**Racioc√≠nio Passo a Passo** - Para problemas que requerem l√≥gica vis√≠vel. O modelo mostra racioc√≠nio expl√≠cito para cada passo. Use para problemas matem√°ticos, quebra-cabe√ßas l√≥gicos ou quando precisar entender o processo de pensamento.

```java
String prompt = """
    <instruction>Show your reasoning step-by-step</instruction>
    
    If a train travels 120 km in 2 hours, then stops for 30 minutes,
    then travels another 90 km in 1.5 hours, what is the average speed
    for the entire journey including the stop?
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/pt-BR/step-by-step-pattern.a99ea4ca1c48578c.webp" alt="Padr√£o Passo a Passo" width="800"/>

*Dividindo problemas em passos l√≥gicos expl√≠citos*

**Sa√≠da Constrangida** - Para respostas com requisitos espec√≠ficos de formato. O modelo segue estritamente regras de formato e comprimento. Use para resumos ou quando precisar de estrutura precisa na sa√≠da.

```java
String prompt = """
    <constraints>
    - Exactly 100 words
    - Bullet point format
    - Technical terms only
    </constraints>
    
    Summarize the key concepts of machine learning.
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/pt-BR/constrained-output-pattern.0ce39a682a6795c2.webp" alt="Padr√£o de Sa√≠da Constrangida" width="800"/>

*Impondo requisitos espec√≠ficos de formato, comprimento e estrutura*

## Usando Recursos Existentes do Azure

**Verifique a implanta√ß√£o:**

Certifique-se de que o arquivo `.env` existe no diret√≥rio raiz com credenciais do Azure (criado durante o M√≥dulo 01):
```bash
cat ../.env  # Deve mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Inicie a aplica√ß√£o:**

> **Nota:** Se voc√™ j√° iniciou todas as aplica√ß√µes usando `./start-all.sh` do M√≥dulo 01, este m√≥dulo j√° est√° rodando na porta 8083. Voc√™ pode pular os comandos de in√≠cio abaixo e ir direto para http://localhost:8083.

**Op√ß√£o 1: Usando Spring Boot Dashboard (Recomendado para usu√°rios VS Code)**

O container de desenvolvimento inclui a extens√£o Spring Boot Dashboard, que fornece uma interface visual para gerenciar todas as aplica√ß√µes Spring Boot. Voc√™ pode encontr√°-la na Barra de Atividades √† esquerda do VS Code (procure o √≠cone do Spring Boot).

No Spring Boot Dashboard, voc√™ pode:
- Ver todas as aplica√ß√µes Spring Boot dispon√≠veis no workspace
- Iniciar/parar aplica√ß√µes com um clique
- Visualizar logs da aplica√ß√£o em tempo real
- Monitorar o status da aplica√ß√£o

Basta clicar no bot√£o de play ao lado de "prompt-engineering" para iniciar este m√≥dulo, ou iniciar todos os m√≥dulos de uma vez.

<img src="../../../translated_images/pt-BR/dashboard.da2c2130c904aaf0.webp" alt="Spring Boot Dashboard" width="400"/>

**Op√ß√£o 2: Usando scripts shell**

Inicie todas as aplica√ß√µes web (m√≥dulos 01-04):

**Bash:**
```bash
cd ..  # A partir do diret√≥rio raiz
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # A partir do diret√≥rio raiz
.\start-all.ps1
```

Ou inicie apenas este m√≥dulo:

**Bash:**
```bash
cd 02-prompt-engineering
./start.sh
```

**PowerShell:**
```powershell
cd 02-prompt-engineering
.\start.ps1
```

Ambos os scripts carregam automaticamente vari√°veis de ambiente do arquivo `.env` raiz e ir√£o construir os JARs se eles n√£o existirem.

> **Nota:** Se preferir construir todos os m√≥dulos manualmente antes de iniciar:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

Abra http://localhost:8083 no seu navegador.

**Para parar:**

**Bash:**
```bash
./stop.sh  # Apenas este m√≥dulo
# Ou
cd .. && ./stop-all.sh  # Todos os m√≥dulos
```

**PowerShell:**
```powershell
.\stop.ps1  # Apenas este m√≥dulo
# Ou
cd ..; .\stop-all.ps1  # Todos os m√≥dulos
```

## Capturas de Tela da Aplica√ß√£o

<img src="../../../translated_images/pt-BR/dashboard-home.5444dbda4bc1f79d.webp" alt="Tela Inicial do Dashboard" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/>

*O dashboard principal mostrando todos os 8 padr√µes de engenharia de prompt com suas caracter√≠sticas e casos de uso*

## Explorando os Padr√µes

A interface web permite que voc√™ experimente diferentes estrat√©gias de prompting. Cada padr√£o resolve problemas diferentes - experimente para ver quando cada abordagem se destaca.

### Baixa vs Alta Disposi√ß√£o

Fa√ßa uma pergunta simples como "Qual √© 15% de 200?" usando Baixa Disposi√ß√£o. Voc√™ receber√° uma resposta instant√¢nea e direta. Agora pergunte algo complexo como "Projete uma estrat√©gia de cache para uma API de alto tr√°fego" usando Alta Disposi√ß√£o. Observe como o modelo desacelera e fornece racioc√≠nio detalhado. Mesmo modelo, mesma estrutura de pergunta - mas o prompt diz quanto pensar.

<img src="../../../translated_images/pt-BR/low-eagerness-demo.898894591fb23aa0.webp" alt="Demonstra√ß√£o Baixa Disposi√ß√£o" width="800"/>
*C√°lculo r√°pido com racioc√≠nio m√≠nimo*

<img src="../../../translated_images/pt-BR/high-eagerness-demo.4ac93e7786c5a376.webp" alt="Demonstra√ß√£o de Alta Disposi√ß√£o" width="800"/>

*Estrat√©gia abrangente de cache (2.8MB)*

### Execu√ß√£o de Tarefas (Pre√¢mbulos de Ferramentas)

Fluxos de trabalho em m√∫ltiplas etapas se beneficiam de planejamento antecipado e narra√ß√£o do progresso. O modelo descreve o que far√°, narra cada passo e depois resume os resultados.

<img src="../../../translated_images/pt-BR/tool-preambles-demo.3ca4881e417f2e28.webp" alt="Demonstra√ß√£o de Execu√ß√£o de Tarefas" width="800"/>

*Criando um endpoint REST com narra√ß√£o passo a passo (3.9MB)*

### C√≥digo Auto-Reflexivo

Tente "Criar um servi√ßo de valida√ß√£o de email". Em vez de apenas gerar c√≥digo e parar, o modelo gera, avalia segundo crit√©rios de qualidade, identifica fraquezas e melhora. Voc√™ ver√° ele iterar at√© que o c√≥digo atenda aos padr√µes de produ√ß√£o.

<img src="../../../translated_images/pt-BR/self-reflecting-code-demo.851ee05c988e743f.webp" alt="Demonstra√ß√£o de C√≥digo Auto-Reflexivo" width="800"/>

*Servi√ßo completo de valida√ß√£o de email (5.2MB)*

### An√°lise Estruturada

Revis√µes de c√≥digo precisam de frameworks de avalia√ß√£o consistentes. O modelo analisa o c√≥digo usando categorias fixas (corre√ß√£o, pr√°ticas, desempenho, seguran√ßa) com n√≠veis de severidade.

<img src="../../../translated_images/pt-BR/structured-analysis-demo.9ef892194cd23bc8.webp" alt="Demonstra√ß√£o de An√°lise Estruturada" width="800"/>

*Revis√£o de c√≥digo baseada em framework*

### Chat Multi-Turno

Pergunte "O que √© Spring Boot?" e logo em seguida "Mostre um exemplo". O modelo lembra sua primeira pergunta e fornece um exemplo espec√≠fico de Spring Boot. Sem mem√≥ria, essa segunda pergunta seria vaga demais.

<img src="../../../translated_images/pt-BR/multi-turn-chat-demo.0d2d9b9a86a12b4b.webp" alt="Demonstra√ß√£o de Chat Multi-Turno" width="800"/>

*Preserva√ß√£o de contexto entre perguntas*

### Racioc√≠nio Passo a Passo

Escolha um problema de matem√°tica e tente com Racioc√≠nio Passo a Passo e Baixa Disposi√ß√£o. Baixa disposi√ß√£o s√≥ d√° a resposta - r√°pido, mas opaco. Passo a passo mostra cada c√°lculo e decis√£o.

<img src="../../../translated_images/pt-BR/step-by-step-reasoning-demo.12139513356faecd.webp" alt="Demonstra√ß√£o de Racioc√≠nio Passo a Passo" width="800"/>

*Problema matem√°tico com passos expl√≠citos*

### Sa√≠da Constrangida

Quando voc√™ precisa de formatos espec√≠ficos ou contagem de palavras, esse padr√£o imp√µe ader√™ncia estrita. Tente gerar um resumo com exatamente 100 palavras em formato de t√≥picos.

<img src="../../../translated_images/pt-BR/constrained-output-demo.567cc45b75da1633.webp" alt="Demonstra√ß√£o de Sa√≠da Constrangida" width="800"/>

*Resumo de aprendizado de m√°quina com controle de formato*

## O Que Voc√™ Est√° Realmente Aprendendo

**Esfor√ßo de Racioc√≠nio Muda Tudo**

GPT-5 permite controlar o esfor√ßo computacional atrav√©s dos seus prompts. Baixo esfor√ßo significa respostas r√°pidas com explora√ß√£o m√≠nima. Alto esfor√ßo significa que o modelo leva tempo para pensar profundamente. Voc√™ est√° aprendendo a ajustar o esfor√ßo √† complexidade da tarefa - n√£o perca tempo com perguntas simples, mas tamb√©m n√£o apresse decis√µes complexas.

**Estrutura Guia o Comportamento**

Notou as tags XML nos prompts? Elas n√£o s√£o decorativas. Modelos seguem instru√ß√µes estruturadas de forma mais confi√°vel que texto livre. Quando voc√™ precisa de processos em m√∫ltiplas etapas ou l√≥gica complexa, a estrutura ajuda o modelo a acompanhar onde est√° e o que vem a seguir.

<img src="../../../translated_images/pt-BR/prompt-structure.a77763d63f4e2f89.webp" alt="Estrutura do Prompt" width="800"/>

*Anatomia de um prompt bem estruturado com se√ß√µes claras e organiza√ß√£o estilo XML*

**Qualidade Atrav√©s da Autoavalia√ß√£o**

Os padr√µes auto-reflexivos funcionam tornando expl√≠citos os crit√©rios de qualidade. Em vez de esperar que o modelo "fa√ßa certo", voc√™ diz exatamente o que "certo" significa: l√≥gica correta, tratamento de erros, desempenho, seguran√ßa. O modelo pode ent√£o avaliar sua pr√≥pria sa√≠da e melhorar. Isso transforma a gera√ß√£o de c√≥digo de uma loteria em um processo.

**Contexto √© Finito**

Conversas multi-turno funcionam incluindo o hist√≥rico de mensagens em cada requisi√ß√£o. Mas h√° um limite - todo modelo tem um m√°ximo de tokens. Conforme as conversas crescem, voc√™ precisar√° de estrat√©gias para manter o contexto relevante sem atingir esse limite. Este m√≥dulo mostra como a mem√≥ria funciona; depois voc√™ aprender√° quando resumir, quando esquecer e quando recuperar.

## Pr√≥ximos Passos

**Pr√≥ximo M√≥dulo:** [03-rag - RAG (Gera√ß√£o com Recupera√ß√£o)](../03-rag/README.md)

---

**Navega√ß√£o:** [‚Üê Anterior: M√≥dulo 01 - Introdu√ß√£o](../01-introduction/README.md) | [Voltar ao In√≠cio](../README.md) | [Pr√≥ximo: M√≥dulo 03 - RAG ‚Üí](../03-rag/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->