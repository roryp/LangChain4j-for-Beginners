<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "81d087662fb3dd7b7124bce1a9c9ec86",
  "translation_date": "2026-01-05T21:19:51+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "es"
}
-->
# M√≥dulo 03: RAG (Generaci√≥n Aumentada por Recuperaci√≥n)

## Tabla de Contenidos

- [Qu√© Aprender√°s](../../../03-rag)
- [Requisitos Previos](../../../03-rag)
- [Comprendiendo RAG](../../../03-rag)
- [C√≥mo Funciona](../../../03-rag)
  - [Procesamiento de Documentos](../../../03-rag)
  - [Creaci√≥n de Embeddings](../../../03-rag)
  - [B√∫squeda Sem√°ntica](../../../03-rag)
  - [Generaci√≥n de Respuestas](../../../03-rag)
- [Ejecutar la Aplicaci√≥n](../../../03-rag)
- [Usando la Aplicaci√≥n](../../../03-rag)
  - [Subir un Documento](../../../03-rag)
  - [Hacer Preguntas](../../../03-rag)
  - [Ver Referencias de Fuente](../../../03-rag)
  - [Experimentar con Preguntas](../../../03-rag)
- [Conceptos Clave](../../../03-rag)
  - [Estrategia de Divisi√≥n en Chunks](../../../03-rag)
  - [Puntuaciones de Similaridad](../../../03-rag)
  - [Almacenamiento en Memoria](../../../03-rag)
  - [Gesti√≥n de la Ventana de Contexto](../../../03-rag)
- [Cu√°ndo importa RAG](../../../03-rag)
- [Pr√≥ximos Pasos](../../../03-rag)

## Qu√© Aprender√°s

En los m√≥dulos anteriores, aprendiste c√≥mo mantener conversaciones con IA y estructurar tus prompts efectivamente. Pero hay una limitaci√≥n fundamental: los modelos de lenguaje solo saben lo que aprendieron durante el entrenamiento. No pueden responder preguntas sobre las pol√≠ticas de tu empresa, la documentaci√≥n de tu proyecto, o cualquier informaci√≥n en la que no hayan sido entrenados.

RAG (Generaci√≥n Aumentada por Recuperaci√≥n) resuelve este problema. En lugar de intentar ense√±ar al modelo tu informaci√≥n (lo cual es costoso e impr√°ctico), le das la capacidad de buscar en tus documentos. Cuando alguien hace una pregunta, el sistema encuentra informaci√≥n relevante e la incluye en el prompt. El modelo luego responde basado en ese contexto recuperado.

Piensa en RAG como brindar al modelo una biblioteca de referencia. Cuando haces una pregunta, el sistema:

1. **Consulta del Usuario** - Haces una pregunta  
2. **Embedding** - Convierte tu pregunta en un vector  
3. **B√∫squeda Vectorial** - Encuentra fragmentos similares en los documentos  
4. **Ensamblaje del Contexto** - A√±ade fragmentos relevantes al prompt  
5. **Respuesta** - El LLM genera una respuesta basada en el contexto  

Esto fundamenta las respuestas del modelo en tus datos reales en lugar de depender solo del conocimiento del entrenamiento o inventar respuestas.

<img src="../../../translated_images/es/rag-architecture.ccb53b71a6ce407f.webp" alt="Arquitectura RAG" width="800"/>

*Flujo de trabajo de RAG: desde la consulta del usuario hasta la b√∫squeda sem√°ntica y generaci√≥n contextual de respuestas*

## Requisitos Previos

- Completar el M√≥dulo 01 (recursos Azure OpenAI desplegados)  
- Archivo `.env` en el directorio ra√≠z con credenciales Azure (creado por `azd up` en M√≥dulo 01)  

> **Nota:** Si no has completado el M√≥dulo 01, primero sigue las instrucciones de despliegue de ese m√≥dulo.

## C√≥mo Funciona

### Procesamiento de Documentos

[DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

Cuando subes un documento, el sistema lo divide en fragmentos ‚Äî piezas m√°s peque√±as que caben c√≥modamente en la ventana de contexto del modelo. Estos fragmentos se solapan ligeramente para que no se pierda el contexto en los l√≠mites.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```
  
> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) y pregunta:  
> - "¬øC√≥mo divide LangChain4j los documentos en fragmentos y por qu√© es importante el solapamiento?"  
> - "¬øCu√°l es el tama√±o √≥ptimo de fragmento para diferentes tipos de documentos y por qu√©?"  
> - "¬øC√≥mo manejo documentos en m√∫ltiples idiomas o con formato especial?"

### Creaci√≥n de Embeddings

[LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Cada fragmento se convierte en una representaci√≥n num√©rica llamada embedding ‚Äî esencialmente una huella digital matem√°tica que captura el significado del texto. Textos similares producen embeddings similares.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```
  
<img src="../../../translated_images/es/vector-embeddings.2ef7bdddac79a327.webp" alt="Espacio de Embeddings Vectoriales" width="800"/>

*Documentos representados como vectores en el espacio de embeddings - contenido similar se agrupa*

### B√∫squeda Sem√°ntica

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Cuando haces una pregunta, tu pregunta tambi√©n se convierte en un embedding. El sistema compara el embedding de tu pregunta con todos los embeddings de los fragmentos de documentos. Encuentra los fragmentos con significados m√°s similares ‚Äî no solo coincidencias de palabras clave, sino similitud sem√°ntica real.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```
  
> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) y pregunta:  
> - "¬øC√≥mo funciona la b√∫squeda por similitud con embeddings y qu√© determina la puntuaci√≥n?"  
> - "¬øQu√© umbral de similitud debo usar y c√≥mo afecta a los resultados?"  
> - "¬øC√≥mo manejo casos donde no se encuentran documentos relevantes?"

### Generaci√≥n de Respuestas

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Los fragmentos m√°s relevantes se incluyen en el prompt para el modelo. El modelo lee esos fragmentos espec√≠ficos y responde tu pregunta basado en esa informaci√≥n. Esto previene la alucinaci√≥n ‚Äî el modelo solo puede responder con lo que tiene delante.

## Ejecutar la Aplicaci√≥n

**Verifica el despliegue:**  

Aseg√∫rate de que el archivo `.env` exista en el directorio ra√≠z con las credenciales Azure (creado durante el M√≥dulo 01):  
```bash
cat ../.env  # Debe mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**Inicia la aplicaci√≥n:**  

> **Nota:** Si ya iniciaste todas las aplicaciones usando `./start-all.sh` del M√≥dulo 01, este m√≥dulo ya est√° corriendo en el puerto 8081. Puedes saltarte los comandos de inicio abajo y entrar directamente a http://localhost:8081.

**Opci√≥n 1: Usando el Spring Boot Dashboard (Recomendado para usuarios de VS Code)**

El contenedor dev incluye la extensi√≥n Spring Boot Dashboard, que provee una interfaz visual para manejar todas las aplicaciones Spring Boot. La encontrar√°s en la Barra de Actividad al lado izquierdo de VS Code (busca el √≠cono de Spring Boot).

Desde el Spring Boot Dashboard, puedes:  
- Ver todas las aplicaciones Spring Boot disponibles en el espacio de trabajo  
- Iniciar/detener aplicaciones con un solo clic  
- Ver logs de aplicaciones en tiempo real  
- Monitorear el estado de la aplicaci√≥n  

Simplemente haz clic en el bot√≥n de play al lado de "rag" para iniciar este m√≥dulo, o inicia todos los m√≥dulos de una vez.

<img src="../../../translated_images/es/dashboard.fbe6e28bf4267ffe.webp" alt="Panel de Control Spring Boot" width="400"/>

**Opci√≥n 2: Usando scripts shell**

Inicia todas las aplicaciones web (m√≥dulos 01-04):

**Bash:**  
```bash
cd ..  # Desde el directorio ra√≠z
./start-all.sh
```
  
**PowerShell:**  
```powershell
cd ..  # Desde el directorio ra√≠z
.\start-all.ps1
```
  
O inicia solo este m√≥dulo:

**Bash:**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell:**  
```powershell
cd 03-rag
.\start.ps1
```
  
Ambos scripts cargan autom√°ticamente variables de entorno desde el archivo `.env` ra√≠z y construir√°n los JARs si no existen.

> **Nota:** Si prefieres construir todos los m√≥dulos manualmente antes de iniciar:  
>  
> **Bash:**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>  
> **PowerShell:**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
Abre http://localhost:8081 en tu navegador.

**Para detener:**  

**Bash:**  
```bash
./stop.sh  # Solo este m√≥dulo
# O
cd .. && ./stop-all.sh  # Todos los m√≥dulos
```
  
**PowerShell:**  
```powershell
.\stop.ps1  # Solo este m√≥dulo
# O
cd ..; .\stop-all.ps1  # Todos los m√≥dulos
```
  
## Usando la Aplicaci√≥n

La aplicaci√≥n provee una interfaz web para subir documentos y hacer preguntas.

<a href="images/rag-homepage.png"><img src="../../../translated_images/es/rag-homepage.d90eb5ce1b3caa94.webp" alt="Interfaz de la Aplicaci√≥n RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Interfaz de la aplicaci√≥n RAG - sube documentos y haz preguntas*

### Subir un Documento

Comienza subiendo un documento ‚Äî archivos TXT funcionan mejor para las pruebas. Se provee un `sample-document.txt` en este directorio que contiene informaci√≥n sobre caracter√≠sticas de LangChain4j, implementaci√≥n RAG y mejores pr√°cticas ‚Äî perfecto para probar el sistema.

El sistema procesa tu documento, lo divide en fragmentos y crea embeddings para cada fragmento. Esto sucede autom√°ticamente al subirlo.

### Hacer Preguntas

Ahora haz preguntas espec√≠ficas sobre el contenido del documento. Intenta con algo factual que est√© claramente indicado en el documento. El sistema busca fragmentos relevantes, los incluye en el prompt y genera una respuesta.

### Ver Referencias de Fuente

Observa que cada respuesta incluye referencias de fuente con puntuaciones de similitud. Estas puntuaciones (de 0 a 1) indican qu√© tan relevante fue cada fragmento para tu pregunta. Puntuaciones m√°s altas significan mejores coincidencias. Esto te permite verificar la respuesta contra el material original.

<a href="images/rag-query-results.png"><img src="../../../translated_images/es/rag-query-results.6d69fcec5397f355.webp" alt="Resultados de Consulta RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Resultados de consulta mostrando respuesta con referencias de fuente y puntuaciones de relevancia*

### Experimentar con Preguntas

Prueba diferentes tipos de preguntas:  
- Hechos espec√≠ficos: "¬øCu√°l es el tema principal?"  
- Comparaciones: "¬øCu√°l es la diferencia entre X y Y?"  
- Res√∫menes: "Resume los puntos clave sobre Z"

Observa c√≥mo cambian las puntuaciones de relevancia seg√∫n c√≥mo tu pregunta coincida con el contenido del documento.

## Conceptos Clave

### Estrategia de Divisi√≥n en Chunks

Los documentos se dividen en fragmentos de 300 tokens con un solapamiento de 30 tokens. Este equilibrio asegura que cada fragmento tenga contexto suficiente para ser significativo, manteni√©ndose peque√±o para incluir m√∫ltiples fragmentos en un prompt.

### Puntuaciones de Similaridad

Las puntuaciones var√≠an de 0 a 1:  
- 0.7-1.0: Muy relevante, coincidencia exacta  
- 0.5-0.7: Relevante, buen contexto  
- Por debajo de 0.5: Filtrado, demasiado dis√≠mil  

El sistema solo recupera fragmentos por encima del umbral m√≠nimo para garantizar calidad.

### Almacenamiento en Memoria

Este m√≥dulo usa almacenamiento en memoria para simplicidad. Cuando reinicias la aplicaci√≥n, los documentos subidos se pierden. Sistemas en producci√≥n usan bases de datos vectoriales persistentes como Qdrant o Azure AI Search.

### Gesti√≥n de la Ventana de Contexto

Cada modelo tiene una ventana m√°xima de contexto. No puedes incluir todos los fragmentos de un documento grande. El sistema recupera los N fragmentos m√°s relevantes (por defecto 5) para mantenerse dentro de los l√≠mites mientras provee suficiente contexto para respuestas precisas.

## Cu√°ndo importa RAG

**Usa RAG cuando:**  
- Responder preguntas sobre documentos propietarios  
- La informaci√≥n cambia frecuentemente (pol√≠ticas, precios, especificaciones)  
- Se requiere precisi√≥n con atribuci√≥n de la fuente  
- El contenido es demasiado grande para un solo prompt  
- Necesitas respuestas verificables y fundamentadas

**No uses RAG cuando:**  
- Las preguntas requieren conocimiento general que el modelo ya tiene  
- Se necesitan datos en tiempo real (RAG trabaja con documentos subidos)  
- El contenido es lo suficientemente peque√±o para incluirse directamente en prompts

## Pr√≥ximos Pasos

**Pr√≥ximo M√≥dulo:** [04-tools - Agentes de IA con Herramientas](../04-tools/README.md)

---

**Navegaci√≥n:** [‚Üê Anterior: M√≥dulo 02 - Ingenier√≠a de Prompts](../02-prompt-engineering/README.md) | [Volver al Inicio](../README.md) | [Siguiente: M√≥dulo 04 - Herramientas ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso legal**:
Este documento ha sido traducido utilizando el servicio de traducci√≥n por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la exactitud, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional realizada por humanos. No somos responsables por malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->