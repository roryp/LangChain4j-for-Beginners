<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f538a51cfd13147d40d84e936a0f485c",
  "translation_date": "2025-12-13T16:42:45+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "es"
}
-->
# M√≥dulo 03: RAG (Generaci√≥n Aumentada por Recuperaci√≥n)

## Tabla de Contenidos

- [Lo que aprender√°s](../../../03-rag)
- [Requisitos previos](../../../03-rag)
- [Entendiendo RAG](../../../03-rag)
- [C√≥mo funciona](../../../03-rag)
  - [Procesamiento de documentos](../../../03-rag)
  - [Creaci√≥n de embeddings](../../../03-rag)
  - [B√∫squeda sem√°ntica](../../../03-rag)
  - [Generaci√≥n de respuestas](../../../03-rag)
- [Ejecutar la aplicaci√≥n](../../../03-rag)
- [Uso de la aplicaci√≥n](../../../03-rag)
  - [Subir un documento](../../../03-rag)
  - [Hacer preguntas](../../../03-rag)
  - [Ver referencias de la fuente](../../../03-rag)
  - [Experimentar con preguntas](../../../03-rag)
- [Conceptos clave](../../../03-rag)
  - [Estrategia de fragmentaci√≥n](../../../03-rag)
  - [Puntuaciones de similitud](../../../03-rag)
  - [Almacenamiento en memoria](../../../03-rag)
  - [Gesti√≥n de la ventana de contexto](../../../03-rag)
- [Cu√°ndo importa RAG](../../../03-rag)
- [Pr√≥ximos pasos](../../../03-rag)

## Lo que aprender√°s

En los m√≥dulos anteriores, aprendiste c√≥mo tener conversaciones con IA y estructurar tus prompts de manera efectiva. Pero hay una limitaci√≥n fundamental: los modelos de lenguaje solo saben lo que aprendieron durante el entrenamiento. No pueden responder preguntas sobre las pol√≠ticas de tu empresa, la documentaci√≥n de tu proyecto o cualquier informaci√≥n en la que no fueron entrenados.

RAG (Generaci√≥n Aumentada por Recuperaci√≥n) resuelve este problema. En lugar de intentar ense√±ar al modelo tu informaci√≥n (lo cual es costoso e impr√°ctico), le das la capacidad de buscar en tus documentos. Cuando alguien hace una pregunta, el sistema encuentra informaci√≥n relevante e la incluye en el prompt. El modelo entonces responde bas√°ndose en ese contexto recuperado.

Piensa en RAG como darle al modelo una biblioteca de referencia. Cuando haces una pregunta, el sistema:

1. **Consulta del usuario** - Haces una pregunta  
2. **Embedding** - Convierte tu pregunta en un vector  
3. **B√∫squeda vectorial** - Encuentra fragmentos de documentos similares  
4. **Ensamblaje del contexto** - A√±ade fragmentos relevantes al prompt  
5. **Respuesta** - El LLM genera una respuesta basada en el contexto  

Esto fundamenta las respuestas del modelo en tus datos reales en lugar de depender de su conocimiento de entrenamiento o inventar respuestas.

<img src="../../../translated_images/rag-architecture.ccb53b71a6ce407fa8a6394c7a747eb9ad40f6334b4c217be0439d700f22bbcc.es.png" alt="Arquitectura RAG" width="800"/>

*Flujo de trabajo RAG - desde la consulta del usuario hasta la b√∫squeda sem√°ntica y la generaci√≥n contextual de respuestas*

## Requisitos previos

- Completar el M√≥dulo 01 (recursos Azure OpenAI desplegados)  
- Archivo `.env` en el directorio ra√≠z con credenciales de Azure (creado por `azd up` en el M√≥dulo 01)  

> **Nota:** Si no has completado el M√≥dulo 01, sigue primero las instrucciones de despliegue all√≠.

## C√≥mo funciona

**Procesamiento de documentos** - [DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

Cuando subes un documento, el sistema lo divide en fragmentos ‚Äî piezas m√°s peque√±as que caben c√≥modamente en la ventana de contexto del modelo. Estos fragmentos se superponen ligeramente para que no se pierda contexto en los l√≠mites.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```
  
> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) y pregunta:  
> - "¬øC√≥mo divide LangChain4j los documentos en fragmentos y por qu√© es importante la superposici√≥n?"  
> - "¬øCu√°l es el tama√±o √≥ptimo de fragmento para diferentes tipos de documentos y por qu√©?"  
> - "¬øC√≥mo manejo documentos en varios idiomas o con formato especial?"

**Creaci√≥n de embeddings** - [LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Cada fragmento se convierte en una representaci√≥n num√©rica llamada embedding ‚Äî esencialmente una huella matem√°tica que captura el significado del texto. Textos similares producen embeddings similares.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```
  
<img src="../../../translated_images/vector-embeddings.2ef7bdddac79a327ad9e3e46cde9a86f5eeefbeb3edccd387e33018c1671cecd.es.png" alt="Espacio de embeddings vectoriales" width="800"/>

*Documentos representados como vectores en el espacio de embeddings - contenido similar se agrupa*

**B√∫squeda sem√°ntica** - [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Cuando haces una pregunta, tu pregunta tambi√©n se convierte en un embedding. El sistema compara el embedding de tu pregunta con los embeddings de todos los fragmentos del documento. Encuentra los fragmentos con significados m√°s similares ‚Äî no solo palabras clave coincidentes, sino similitud sem√°ntica real.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```
  
> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) y pregunta:  
> - "¬øC√≥mo funciona la b√∫squeda por similitud con embeddings y qu√© determina la puntuaci√≥n?"  
> - "¬øQu√© umbral de similitud deber√≠a usar y c√≥mo afecta los resultados?"  
> - "¬øC√≥mo manejo casos donde no se encuentran documentos relevantes?"

**Generaci√≥n de respuestas** - [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Los fragmentos m√°s relevantes se incluyen en el prompt para el modelo. El modelo lee esos fragmentos espec√≠ficos y responde tu pregunta bas√°ndose en esa informaci√≥n. Esto previene alucinaciones ‚Äî el modelo solo puede responder con lo que tiene delante.

## Ejecutar la aplicaci√≥n

**Verificar despliegue:**

Aseg√∫rate de que el archivo `.env` exista en el directorio ra√≠z con las credenciales de Azure (creado durante el M√≥dulo 01):  
```bash
cat ../.env  # Debe mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**Iniciar la aplicaci√≥n:**

> **Nota:** Si ya iniciaste todas las aplicaciones usando `./start-all.sh` del M√≥dulo 01, este m√≥dulo ya est√° corriendo en el puerto 8081. Puedes saltarte los comandos de inicio a continuaci√≥n e ir directamente a http://localhost:8081.

**Opci√≥n 1: Usar Spring Boot Dashboard (Recomendado para usuarios de VS Code)**

El contenedor de desarrollo incluye la extensi√≥n Spring Boot Dashboard, que proporciona una interfaz visual para gestionar todas las aplicaciones Spring Boot. La encontrar√°s en la barra de actividades a la izquierda de VS Code (busca el √≠cono de Spring Boot).

Desde el Spring Boot Dashboard puedes:  
- Ver todas las aplicaciones Spring Boot disponibles en el espacio de trabajo  
- Iniciar/detener aplicaciones con un solo clic  
- Ver logs de la aplicaci√≥n en tiempo real  
- Monitorear el estado de la aplicaci√≥n  

Simplemente haz clic en el bot√≥n de reproducir junto a "rag" para iniciar este m√≥dulo, o inicia todos los m√≥dulos a la vez.

<img src="../../../translated_images/dashboard.fbe6e28bf4267ffe4f95a708ecd46e78f69fd46a562d2a766e73c98fe0f53922.es.png" alt="Panel de control Spring Boot" width="400"/>

**Opci√≥n 2: Usar scripts de shell**

Inicia todas las aplicaciones web (m√≥dulos 01-04):

**Bash:**  
```bash
cd ..  # Desde el directorio ra√≠z
./start-all.sh
```
  
**PowerShell:**  
```powershell
cd ..  # Desde el directorio ra√≠z
.\start-all.ps1
```
  
O inicia solo este m√≥dulo:

**Bash:**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell:**  
```powershell
cd 03-rag
.\start.ps1
```
  
Ambos scripts cargan autom√°ticamente las variables de entorno desde el archivo `.env` ra√≠z y construir√°n los JARs si no existen.

> **Nota:** Si prefieres construir todos los m√≥dulos manualmente antes de iniciar:  
>  
> **Bash:**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
> **PowerShell:**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
Abre http://localhost:8081 en tu navegador.

**Para detener:**

**Bash:**  
```bash
./stop.sh  # Solo este m√≥dulo
# O
cd .. && ./stop-all.sh  # Todos los m√≥dulos
```
  
**PowerShell:**  
```powershell
.\stop.ps1  # Solo este m√≥dulo
# O
cd ..; .\stop-all.ps1  # Todos los m√≥dulos
```
  
## Uso de la aplicaci√≥n

La aplicaci√≥n proporciona una interfaz web para subir documentos y hacer preguntas.

<a href="images/rag-homepage.png"><img src="../../../translated_images/rag-homepage.d90eb5ce1b3caa94987b4fa2923d3cb884a67987cf2f994ca53756c6586a93b1.es.png" alt="Interfaz de la aplicaci√≥n RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Interfaz de la aplicaci√≥n RAG - sube documentos y haz preguntas*

**Subir un documento**

Comienza subiendo un documento ‚Äî los archivos TXT funcionan mejor para pruebas. Se proporciona un `sample-document.txt` en este directorio que contiene informaci√≥n sobre las caracter√≠sticas de LangChain4j, implementaci√≥n de RAG y mejores pr√°cticas ‚Äî perfecto para probar el sistema.

El sistema procesa tu documento, lo divide en fragmentos y crea embeddings para cada fragmento. Esto ocurre autom√°ticamente al subirlo.

**Hacer preguntas**

Ahora haz preguntas espec√≠ficas sobre el contenido del documento. Prueba con algo factual que est√© claramente indicado en el documento. El sistema busca fragmentos relevantes, los incluye en el prompt y genera una respuesta.

**Ver referencias de la fuente**

Observa que cada respuesta incluye referencias a las fuentes con puntuaciones de similitud. Estas puntuaciones (de 0 a 1) muestran qu√© tan relevante fue cada fragmento para tu pregunta. Puntuaciones m√°s altas significan mejores coincidencias. Esto te permite verificar la respuesta contra el material fuente.

<a href="images/rag-query-results.png"><img src="../../../translated_images/rag-query-results.6d69fcec5397f3558c788388bb395191616dad4c7c0417f1a68bd18590ad0a0e.es.png" alt="Resultados de consulta RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Resultados de consulta mostrando respuesta con referencias a fuentes y puntuaciones de relevancia*

**Experimentar con preguntas**

Prueba diferentes tipos de preguntas:  
- Hechos espec√≠ficos: "¬øCu√°l es el tema principal?"  
- Comparaciones: "¬øCu√°l es la diferencia entre X y Y?"  
- Res√∫menes: "Resume los puntos clave sobre Z"  

Observa c√≥mo cambian las puntuaciones de relevancia seg√∫n qu√© tan bien tu pregunta coincida con el contenido del documento.

## Conceptos clave

**Estrategia de fragmentaci√≥n**

Los documentos se dividen en fragmentos de 300 tokens con 30 tokens de superposici√≥n. Este equilibrio asegura que cada fragmento tenga suficiente contexto para ser significativo mientras se mantiene lo suficientemente peque√±o para incluir m√∫ltiples fragmentos en un prompt.

**Puntuaciones de similitud**

Las puntuaciones van de 0 a 1:  
- 0.7-1.0: Altamente relevante, coincidencia exacta  
- 0.5-0.7: Relevante, buen contexto  
- Por debajo de 0.5: Filtrado, demasiado dis√≠mil  

El sistema solo recupera fragmentos por encima del umbral m√≠nimo para asegurar calidad.

**Almacenamiento en memoria**

Este m√≥dulo usa almacenamiento en memoria para simplicidad. Cuando reinicias la aplicaci√≥n, los documentos subidos se pierden. Los sistemas de producci√≥n usan bases de datos vectoriales persistentes como Qdrant o Azure AI Search.

**Gesti√≥n de la ventana de contexto**

Cada modelo tiene una ventana de contexto m√°xima. No puedes incluir todos los fragmentos de un documento grande. El sistema recupera los N fragmentos m√°s relevantes (por defecto 5) para mantenerse dentro de los l√≠mites mientras proporciona suficiente contexto para respuestas precisas.

## Cu√°ndo importa RAG

**Usa RAG cuando:**  
- Respondes preguntas sobre documentos propietarios  
- La informaci√≥n cambia frecuentemente (pol√≠ticas, precios, especificaciones)  
- La precisi√≥n requiere atribuci√≥n de fuentes  
- El contenido es demasiado grande para caber en un solo prompt  
- Necesitas respuestas verificables y fundamentadas

**No uses RAG cuando:**  
- Las preguntas requieren conocimiento general que el modelo ya tiene  
- Se necesita informaci√≥n en tiempo real (RAG funciona con documentos subidos)  
- El contenido es lo suficientemente peque√±o para incluirse directamente en los prompts

## Pr√≥ximos pasos

**Siguiente m√≥dulo:** [04-tools - Agentes de IA con herramientas](../04-tools/README.md)

---

**Navegaci√≥n:** [‚Üê Anterior: M√≥dulo 02 - Ingenier√≠a de prompts](../02-prompt-engineering/README.md) | [Volver al inicio](../README.md) | [Siguiente: M√≥dulo 04 - Herramientas ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso legal**:
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->