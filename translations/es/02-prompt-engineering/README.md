# M√≥dulo 02: Ingenier√≠a de Prompts con GPT-5

## Tabla de Contenidos

- [Lo que Aprender√°s](../../../02-prompt-engineering)
- [Prerrequisitos](../../../02-prompt-engineering)
- [Entendiendo la Ingenier√≠a de Prompts](../../../02-prompt-engineering)
- [C√≥mo Esto Usa LangChain4j](../../../02-prompt-engineering)
- [Los Patrones Clave](../../../02-prompt-engineering)
- [Usando Recursos Existentes de Azure](../../../02-prompt-engineering)
- [Capturas de Pantalla de la Aplicaci√≥n](../../../02-prompt-engineering)
- [Explorando los Patrones](../../../02-prompt-engineering)
  - [Baja vs Alta Disposici√≥n](../../../02-prompt-engineering)
  - [Ejecuci√≥n de Tareas (Pre√°mbulos de Herramientas)](../../../02-prompt-engineering)
  - [C√≥digo Auto-Reflexivo](../../../02-prompt-engineering)
  - [An√°lisis Estructurado](../../../02-prompt-engineering)
  - [Chat Multi-Turno](../../../02-prompt-engineering)
  - [Razonamiento Paso a Paso](../../../02-prompt-engineering)
  - [Salida Restringida](../../../02-prompt-engineering)
- [Lo que Realmente Est√°s Aprendiendo](../../../02-prompt-engineering)
- [Pr√≥ximos Pasos](../../../02-prompt-engineering)

## Lo que Aprender√°s

En el m√≥dulo anterior, viste c√≥mo la memoria habilita la IA conversacional y usaste Modelos de GitHub para interacciones b√°sicas. Ahora nos enfocaremos en c√≥mo haces preguntas - los prompts en s√≠ - usando GPT-5 de Azure OpenAI. La forma en que estructuras tus prompts afecta dram√°ticamente la calidad de las respuestas que obtienes.

Usaremos GPT-5 porque introduce control de razonamiento - puedes indicarle al modelo cu√°nto debe pensar antes de responder. Esto hace que las diferentes estrategias de prompting sean m√°s evidentes y te ayuda a entender cu√°ndo usar cada enfoque. Tambi√©n nos beneficiaremos de los l√≠mites de tasa m√°s bajos de Azure para GPT-5 en comparaci√≥n con los Modelos de GitHub.

## Prerrequisitos

- Haber completado el M√≥dulo 01 (recursos de Azure OpenAI desplegados)
- Archivo `.env` en el directorio ra√≠z con credenciales de Azure (creado por `azd up` en el M√≥dulo 01)

> **Nota:** Si no has completado el M√≥dulo 01, sigue primero las instrucciones de despliegue all√≠.

## Entendiendo la Ingenier√≠a de Prompts

La ingenier√≠a de prompts consiste en dise√±ar texto de entrada que consistentemente te d√© los resultados que necesitas. No se trata solo de hacer preguntas, sino de estructurar las solicitudes para que el modelo entienda exactamente qu√© quieres y c√≥mo entregarlo.

Pi√©nsalo como dar instrucciones a un colega. "Arregla el error" es vago. "Arregla la excepci√≥n de puntero nulo en UserService.java l√≠nea 45 a√±adiendo una verificaci√≥n de nulo" es espec√≠fico. Los modelos de lenguaje funcionan igual: la especificidad y la estructura importan.

## C√≥mo Esto Usa LangChain4j

Este m√≥dulo demuestra patrones avanzados de prompting usando la misma base de LangChain4j de m√≥dulos anteriores, con un enfoque en la estructura del prompt y el control del razonamiento.

<img src="../../../translated_images/es/langchain4j-flow.48e534666213010b.webp" alt="LangChain4j Flow" width="800"/>

*C√≥mo LangChain4j conecta tus prompts con Azure OpenAI GPT-5*

**Dependencias** - El M√≥dulo 02 usa las siguientes dependencias de langchain4j definidas en `pom.xml`:
```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Configuraci√≥n de OpenAiOfficialChatModel** - [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java)

El modelo de chat se configura manualmente como un bean de Spring usando el cliente oficial de OpenAI, que soporta endpoints de Azure OpenAI. La diferencia clave con el M√≥dulo 01 es c√≥mo estructuramos los prompts enviados a `chatModel.chat()`, no la configuraci√≥n del modelo en s√≠.

**Mensajes de Sistema y Usuario** - [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)

LangChain4j separa los tipos de mensajes para mayor claridad. `SystemMessage` establece el comportamiento y contexto de la IA (como "Eres un revisor de c√≥digo"), mientras que `UserMessage` contiene la solicitud real. Esta separaci√≥n permite mantener un comportamiento consistente de la IA a trav√©s de diferentes consultas de usuario.

```java
SystemMessage systemMsg = SystemMessage.from(
    "You are a helpful Java programming expert."
);

UserMessage userMsg = UserMessage.from(
    "Explain what a List is in Java"
);

String response = chatModel.chat(systemMsg, userMsg);
```

<img src="../../../translated_images/es/message-types.93e0779798a17c9d.webp" alt="Message Types Architecture" width="800"/>

*SystemMessage proporciona contexto persistente mientras UserMessages contienen solicitudes individuales*

**MessageWindowChatMemory para Multi-Turno** - Para el patr√≥n de conversaci√≥n multi-turno, reutilizamos `MessageWindowChatMemory` del M√≥dulo 01. Cada sesi√≥n obtiene su propia instancia de memoria almacenada en un `Map<String, ChatMemory>`, permitiendo m√∫ltiples conversaciones concurrentes sin mezclar contexto.

**Plantillas de Prompt** - El verdadero enfoque aqu√≠ es la ingenier√≠a de prompts, no nuevas APIs de LangChain4j. Cada patr√≥n (baja disposici√≥n, alta disposici√≥n, ejecuci√≥n de tareas, etc.) usa el mismo m√©todo `chatModel.chat(prompt)` pero con cadenas de prompt cuidadosamente estructuradas. Las etiquetas XML, instrucciones y formato son parte del texto del prompt, no caracter√≠sticas de LangChain4j.

**Control de Razonamiento** - El esfuerzo de razonamiento de GPT-5 se controla mediante instrucciones en el prompt como "m√°ximo 2 pasos de razonamiento" o "explora a fondo". Estas son t√©cnicas de ingenier√≠a de prompts, no configuraciones de LangChain4j. La librer√≠a simplemente entrega tus prompts al modelo.

La conclusi√≥n clave: LangChain4j provee la infraestructura (conexi√≥n al modelo v√≠a [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java), memoria, manejo de mensajes v√≠a [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)), mientras que este m√≥dulo te ense√±a c√≥mo crear prompts efectivos dentro de esa infraestructura.

## Los Patrones Clave

No todos los problemas necesitan el mismo enfoque. Algunas preguntas requieren respuestas r√°pidas, otras un pensamiento profundo. Algunas necesitan razonamiento visible, otras solo resultados. Este m√≥dulo cubre ocho patrones de prompting, cada uno optimizado para diferentes escenarios. Experimentar√°s con todos para aprender cu√°ndo funciona mejor cada enfoque.

<img src="../../../translated_images/es/eight-patterns.fa1ebfdf16f71e9a.webp" alt="Eight Prompting Patterns" width="800"/>

*Resumen de los ocho patrones de ingenier√≠a de prompts y sus casos de uso*

<img src="../../../translated_images/es/reasoning-effort.db4a3ba5b8e392c1.webp" alt="Reasoning Effort Comparison" width="800"/>

*Disposici√≥n baja (r√°pido, directo) vs disposici√≥n alta (exhaustivo, exploratorio) en enfoques de razonamiento*

**Baja Disposici√≥n (R√°pido y Enfocado)** - Para preguntas simples donde quieres respuestas r√°pidas y directas. El modelo hace un razonamiento m√≠nimo - m√°ximo 2 pasos. √ösalo para c√°lculos, b√∫squedas o preguntas directas.

```java
String prompt = """
    <reasoning_effort>low</reasoning_effort>
    <instruction>maximum 2 reasoning steps</instruction>
    
    What is 15% of 200?
    """;

String response = chatModel.chat(prompt);
```

> üí° **Explora con GitHub Copilot:** Abre [`Gpt5PromptService.java`](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java) y pregunta:
> - "¬øCu√°l es la diferencia entre los patrones de prompting de baja disposici√≥n y alta disposici√≥n?"
> - "¬øC√≥mo ayudan las etiquetas XML en los prompts a estructurar la respuesta de la IA?"
> - "¬øCu√°ndo deber√≠a usar patrones de auto-reflexi√≥n vs instrucciones directas?"

**Alta Disposici√≥n (Profundo y Exhaustivo)** - Para problemas complejos donde quieres un an√°lisis completo. El modelo explora a fondo y muestra razonamiento detallado. √ösalo para dise√±o de sistemas, decisiones de arquitectura o investigaci√≥n compleja.

```java
String prompt = """
    <reasoning_effort>high</reasoning_effort>
    <instruction>explore thoroughly, show detailed reasoning</instruction>
    
    Design a caching strategy for a high-traffic REST API.
    """;

String response = chatModel.chat(prompt);
```

**Ejecuci√≥n de Tareas (Progreso Paso a Paso)** - Para flujos de trabajo de m√∫ltiples pasos. El modelo provee un plan inicial, narra cada paso mientras trabaja, luego da un resumen. √ösalo para migraciones, implementaciones o cualquier proceso multi-paso.

```java
String prompt = """
    <task>Create a REST endpoint for user registration</task>
    <preamble>Provide an upfront plan</preamble>
    <narration>Narrate each step as you work</narration>
    <summary>Summarize what was accomplished</summary>
    """;

String response = chatModel.chat(prompt);
```

El prompting de Cadena de Pensamiento (Chain-of-Thought) pide expl√≠citamente al modelo mostrar su proceso de razonamiento, mejorando la precisi√≥n en tareas complejas. El desglose paso a paso ayuda tanto a humanos como a la IA a entender la l√≥gica.

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Pregunta sobre este patr√≥n:
> - "¬øC√≥mo adaptar√≠a el patr√≥n de ejecuci√≥n de tareas para operaciones de larga duraci√≥n?"
> - "¬øCu√°les son las mejores pr√°cticas para estructurar pre√°mbulos de herramientas en aplicaciones de producci√≥n?"
> - "¬øC√≥mo puedo capturar y mostrar actualizaciones de progreso intermedias en una interfaz de usuario?"

<img src="../../../translated_images/es/task-execution-pattern.9da3967750ab5c1e.webp" alt="Task Execution Pattern" width="800"/>

*Flujo Planificar ‚Üí Ejecutar ‚Üí Resumir para tareas multi-paso*

**C√≥digo Auto-Reflexivo** - Para generar c√≥digo de calidad de producci√≥n. El modelo genera c√≥digo, lo verifica contra criterios de calidad y lo mejora iterativamente. √ösalo al construir nuevas funcionalidades o servicios.

```java
String prompt = """
    <task>Create an email validation service</task>
    <quality_criteria>
    - Correct logic and error handling
    - Best practices (clean code, proper naming)
    - Performance optimization
    - Security considerations
    </quality_criteria>
    <instruction>Generate code, evaluate against criteria, improve iteratively</instruction>
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/es/self-reflection-cycle.6f71101ca0bd28cc.webp" alt="Self-Reflection Cycle" width="800"/>

*Ciclo de mejora iterativa - generar, evaluar, identificar problemas, mejorar, repetir*

**An√°lisis Estructurado** - Para evaluaciones consistentes. El modelo revisa c√≥digo usando un marco fijo (correcci√≥n, pr√°cticas, rendimiento, seguridad). √ösalo para revisiones de c√≥digo o evaluaciones de calidad.

```java
String prompt = """
    <code>
    public List getUsers() {
        return database.query("SELECT * FROM users");
    }
    </code>
    
    <framework>
    Evaluate using these categories:
    1. Correctness - Logic and functionality
    2. Best Practices - Code quality
    3. Performance - Efficiency concerns
    4. Security - Vulnerabilities
    </framework>
    """;

String response = chatModel.chat(prompt);
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Pregunta sobre an√°lisis estructurado:
> - "¬øC√≥mo puedo personalizar el marco de an√°lisis para diferentes tipos de revisiones de c√≥digo?"
> - "¬øCu√°l es la mejor forma de analizar y actuar sobre salidas estructuradas program√°ticamente?"
> - "¬øC√≥mo aseguro niveles de severidad consistentes en diferentes sesiones de revisi√≥n?"

<img src="../../../translated_images/es/structured-analysis-pattern.0af3b690b60cf2d6.webp" alt="Structured Analysis Pattern" width="800"/>

*Marco de cuatro categor√≠as para revisiones de c√≥digo consistentes con niveles de severidad*

**Chat Multi-Turno** - Para conversaciones que necesitan contexto. El modelo recuerda mensajes previos y construye sobre ellos. √ösalo para sesiones de ayuda interactivas o preguntas y respuestas complejas.

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("What is Spring Boot?"));
AiMessage aiMessage1 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage1);

memory.add(UserMessage.from("Show me an example"));
AiMessage aiMessage2 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage2);
```

<img src="../../../translated_images/es/context-memory.dff30ad9fa78832a.webp" alt="Context Memory" width="800"/>

*C√≥mo el contexto de la conversaci√≥n se acumula a lo largo de m√∫ltiples turnos hasta alcanzar el l√≠mite de tokens*

**Razonamiento Paso a Paso** - Para problemas que requieren l√≥gica visible. El modelo muestra razonamiento expl√≠cito para cada paso. √ösalo para problemas matem√°ticos, acertijos l√≥gicos o cuando necesitas entender el proceso de pensamiento.

```java
String prompt = """
    <instruction>Show your reasoning step-by-step</instruction>
    
    If a train travels 120 km in 2 hours, then stops for 30 minutes,
    then travels another 90 km in 1.5 hours, what is the average speed
    for the entire journey including the stop?
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/es/step-by-step-pattern.a99ea4ca1c48578c.webp" alt="Step-by-Step Pattern" width="800"/>

*Desglose de problemas en pasos l√≥gicos expl√≠citos*

**Salida Restringida** - Para respuestas con requisitos espec√≠ficos de formato. El modelo sigue estrictamente reglas de formato y longitud. √ösalo para res√∫menes o cuando necesitas una estructura de salida precisa.

```java
String prompt = """
    <constraints>
    - Exactly 100 words
    - Bullet point format
    - Technical terms only
    </constraints>
    
    Summarize the key concepts of machine learning.
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/es/constrained-output-pattern.0ce39a682a6795c2.webp" alt="Constrained Output Pattern" width="800"/>

*Aplicando requisitos espec√≠ficos de formato, longitud y estructura*

## Usando Recursos Existentes de Azure

**Verificar despliegue:**

Aseg√∫rate de que el archivo `.env` exista en el directorio ra√≠z con las credenciales de Azure (creado durante el M√≥dulo 01):
```bash
cat ../.env  # Debe mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Iniciar la aplicaci√≥n:**

> **Nota:** Si ya iniciaste todas las aplicaciones usando `./start-all.sh` del M√≥dulo 01, este m√≥dulo ya est√° corriendo en el puerto 8083. Puedes saltarte los comandos de inicio a continuaci√≥n e ir directamente a http://localhost:8083.

**Opci√≥n 1: Usando Spring Boot Dashboard (Recomendado para usuarios de VS Code)**

El contenedor de desarrollo incluye la extensi√≥n Spring Boot Dashboard, que provee una interfaz visual para gestionar todas las aplicaciones Spring Boot. La encontrar√°s en la Barra de Actividad a la izquierda de VS Code (busca el √≠cono de Spring Boot).

Desde el Spring Boot Dashboard puedes:
- Ver todas las aplicaciones Spring Boot disponibles en el espacio de trabajo
- Iniciar/detener aplicaciones con un solo clic
- Ver logs de la aplicaci√≥n en tiempo real
- Monitorear el estado de la aplicaci√≥n

Simplemente haz clic en el bot√≥n de play junto a "prompt-engineering" para iniciar este m√≥dulo, o inicia todos los m√≥dulos a la vez.

<img src="../../../translated_images/es/dashboard.da2c2130c904aaf0.webp" alt="Spring Boot Dashboard" width="400"/>

**Opci√≥n 2: Usando scripts de shell**

Inicia todas las aplicaciones web (m√≥dulos 01-04):

**Bash:**
```bash
cd ..  # Desde el directorio ra√≠z
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Desde el directorio ra√≠z
.\start-all.ps1
```

O inicia solo este m√≥dulo:

**Bash:**
```bash
cd 02-prompt-engineering
./start.sh
```

**PowerShell:**
```powershell
cd 02-prompt-engineering
.\start.ps1
```

Ambos scripts cargan autom√°ticamente las variables de entorno desde el archivo `.env` ra√≠z y construir√°n los JARs si no existen.

> **Nota:** Si prefieres construir todos los m√≥dulos manualmente antes de iniciar:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

Abre http://localhost:8083 en tu navegador.

**Para detener:**

**Bash:**
```bash
./stop.sh  # Solo este m√≥dulo
# O
cd .. && ./stop-all.sh  # Todos los m√≥dulos
```

**PowerShell:**
```powershell
.\stop.ps1  # Solo este m√≥dulo
# O
cd ..; .\stop-all.ps1  # Todos los m√≥dulos
```

## Capturas de Pantalla de la Aplicaci√≥n

<img src="../../../translated_images/es/dashboard-home.5444dbda4bc1f79d.webp" alt="Dashboard Home" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/>

*El panel principal mostrando los 8 patrones de ingenier√≠a de prompts con sus caracter√≠sticas y casos de uso*

## Explorando los Patrones

La interfaz web te permite experimentar con diferentes estrategias de prompting. Cada patr√≥n resuelve problemas distintos - pru√©balos para ver cu√°ndo brilla cada enfoque.

### Baja vs Alta Disposici√≥n

Haz una pregunta simple como "¬øCu√°l es el 15% de 200?" usando Baja Disposici√≥n. Obtendr√°s una respuesta instant√°nea y directa. Ahora haz algo complejo como "Dise√±a una estrategia de cach√© para una API de alto tr√°fico" usando Alta Disposici√≥n. Observa c√≥mo el modelo se toma m√°s tiempo y proporciona razonamiento detallado. Mismo modelo, misma estructura de pregunta - pero el prompt le indica cu√°nto debe pensar.

<img src="../../../translated_images/es/low-eagerness-demo.898894591fb23aa0.webp" alt="Low Eagerness Demo" width="800"/>
*C√°lculo r√°pido con razonamiento m√≠nimo*

<img src="../../../translated_images/es/high-eagerness-demo.4ac93e7786c5a376.webp" alt="Demostraci√≥n de alta diligencia" width="800"/>

*Estrategia de almacenamiento en cach√© integral (2.8MB)*

### Ejecuci√≥n de tareas (Pre√°mbulos de herramientas)

Los flujos de trabajo de m√∫ltiples pasos se benefician de la planificaci√≥n previa y la narraci√≥n del progreso. El modelo describe lo que har√°, narra cada paso y luego resume los resultados.

<img src="../../../translated_images/es/tool-preambles-demo.3ca4881e417f2e28.webp" alt="Demostraci√≥n de ejecuci√≥n de tareas" width="800"/>

*Creaci√≥n de un endpoint REST con narraci√≥n paso a paso (3.9MB)*

### C√≥digo autorreflexivo

Prueba "Crear un servicio de validaci√≥n de correo electr√≥nico". En lugar de solo generar c√≥digo y detenerse, el modelo genera, eval√∫a seg√∫n criterios de calidad, identifica debilidades y mejora. Ver√°s que itera hasta que el c√≥digo cumple con los est√°ndares de producci√≥n.

<img src="../../../translated_images/es/self-reflecting-code-demo.851ee05c988e743f.webp" alt="Demostraci√≥n de c√≥digo autorreflexivo" width="800"/>

*Servicio completo de validaci√≥n de correo electr√≥nico (5.2MB)*

### An√°lisis estructurado

Las revisiones de c√≥digo necesitan marcos de evaluaci√≥n consistentes. El modelo analiza el c√≥digo usando categor√≠as fijas (correcci√≥n, pr√°cticas, rendimiento, seguridad) con niveles de severidad.

<img src="../../../translated_images/es/structured-analysis-demo.9ef892194cd23bc8.webp" alt="Demostraci√≥n de an√°lisis estructurado" width="800"/>

*Revisi√≥n de c√≥digo basada en un marco*

### Chat de m√∫ltiples turnos

Pregunta "¬øQu√© es Spring Boot?" y luego sigue inmediatamente con "Mu√©strame un ejemplo". El modelo recuerda tu primera pregunta y te da un ejemplo espec√≠fico de Spring Boot. Sin memoria, esa segunda pregunta ser√≠a demasiado vaga.

<img src="../../../translated_images/es/multi-turn-chat-demo.0d2d9b9a86a12b4b.webp" alt="Demostraci√≥n de chat de m√∫ltiples turnos" width="800"/>

*Preservaci√≥n del contexto a trav√©s de preguntas*

### Razonamiento paso a paso

Elige un problema matem√°tico y pru√©balo tanto con Razonamiento paso a paso como con Baja diligencia. La baja diligencia solo te da la respuesta, r√°pido pero opaco. El paso a paso te muestra cada c√°lculo y decisi√≥n.

<img src="../../../translated_images/es/step-by-step-reasoning-demo.12139513356faecd.webp" alt="Demostraci√≥n de razonamiento paso a paso" width="800"/>

*Problema matem√°tico con pasos expl√≠citos*

### Salida restringida

Cuando necesitas formatos espec√≠ficos o conteos de palabras, este patr√≥n hace cumplir una estricta adherencia. Prueba generar un resumen con exactamente 100 palabras en formato de vi√±etas.

<img src="../../../translated_images/es/constrained-output-demo.567cc45b75da1633.webp" alt="Demostraci√≥n de salida restringida" width="800"/>

*Resumen de aprendizaje autom√°tico con control de formato*

## Lo que realmente est√°s aprendiendo

**El esfuerzo de razonamiento lo cambia todo**

GPT-5 te permite controlar el esfuerzo computacional a trav√©s de tus indicaciones. Bajo esfuerzo significa respuestas r√°pidas con exploraci√≥n m√≠nima. Alto esfuerzo significa que el modelo se toma tiempo para pensar profundamente. Est√°s aprendiendo a ajustar el esfuerzo a la complejidad de la tarea: no pierdas tiempo en preguntas simples, pero tampoco apresures decisiones complejas.

**La estructura gu√≠a el comportamiento**

¬øNotas las etiquetas XML en las indicaciones? No son decorativas. Los modelos siguen instrucciones estructuradas de manera m√°s confiable que texto libre. Cuando necesitas procesos de m√∫ltiples pasos o l√≥gica compleja, la estructura ayuda al modelo a rastrear d√≥nde est√° y qu√© sigue.

<img src="../../../translated_images/es/prompt-structure.a77763d63f4e2f89.webp" alt="Estructura de la indicaci√≥n" width="800"/>

*Anatom√≠a de una indicaci√≥n bien estructurada con secciones claras y organizaci√≥n estilo XML*

**Calidad mediante autoevaluaci√≥n**

Los patrones autorreflexivos funcionan haciendo expl√≠citos los criterios de calidad. En lugar de esperar que el modelo "lo haga bien", le dices exactamente qu√© significa "bien": l√≥gica correcta, manejo de errores, rendimiento, seguridad. El modelo puede entonces evaluar su propia salida y mejorar. Esto convierte la generaci√≥n de c√≥digo de una loter√≠a en un proceso.

**El contexto es finito**

Las conversaciones de m√∫ltiples turnos funcionan incluyendo el historial de mensajes con cada solicitud. Pero hay un l√≠mite: cada modelo tiene un conteo m√°ximo de tokens. A medida que las conversaciones crecen, necesitar√°s estrategias para mantener el contexto relevante sin alcanzar ese l√≠mite. Este m√≥dulo te muestra c√≥mo funciona la memoria; m√°s adelante aprender√°s cu√°ndo resumir, cu√°ndo olvidar y cu√°ndo recuperar.

## Pr√≥ximos pasos

**Siguiente m√≥dulo:** [03-rag - RAG (Generaci√≥n aumentada por recuperaci√≥n)](../03-rag/README.md)

---

**Navegaci√≥n:** [‚Üê Anterior: M√≥dulo 01 - Introducci√≥n](../01-introduction/README.md) | [Volver al inicio](../README.md) | [Siguiente: M√≥dulo 03 - RAG ‚Üí](../03-rag/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso legal**:
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->