<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "377b3e3e6f8d02965bf0fbbc9ccb45c5",
  "translation_date": "2025-12-13T14:28:25+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "es"
}
-->
# M√≥dulo 00: Inicio R√°pido

## Tabla de Contenidos

- [Introducci√≥n](../../../00-quick-start)
- [¬øQu√© es LangChain4j?](../../../00-quick-start)
- [Dependencias de LangChain4j](../../../00-quick-start)
- [Requisitos Previos](../../../00-quick-start)
- [Configuraci√≥n](../../../00-quick-start)
  - [1. Obt√©n tu Token de GitHub](../../../00-quick-start)
  - [2. Configura tu Token](../../../00-quick-start)
- [Ejecuta los Ejemplos](../../../00-quick-start)
  - [1. Chat B√°sico](../../../00-quick-start)
  - [2. Patrones de Prompt](../../../00-quick-start)
  - [3. Llamada a Funciones](../../../00-quick-start)
  - [4. Preguntas y Respuestas sobre Documentos (RAG)](../../../00-quick-start)
- [Qu√© Muestra Cada Ejemplo](../../../00-quick-start)
- [Pr√≥ximos Pasos](../../../00-quick-start)
- [Soluci√≥n de Problemas](../../../00-quick-start)

## Introducci√≥n

Este inicio r√°pido est√° dise√±ado para que comiences a usar LangChain4j lo m√°s r√°pido posible. Cubre lo b√°sico absoluto para construir aplicaciones de IA con LangChain4j y GitHub Models. En los siguientes m√≥dulos usar√°s Azure OpenAI con LangChain4j para construir aplicaciones m√°s avanzadas.

## ¬øQu√© es LangChain4j?

LangChain4j es una biblioteca Java que simplifica la construcci√≥n de aplicaciones impulsadas por IA. En lugar de lidiar con clientes HTTP y an√°lisis JSON, trabajas con APIs limpias en Java.

La "cadena" en LangChain se refiere a encadenar m√∫ltiples componentes: puedes encadenar un prompt a un modelo, luego a un parser, o encadenar m√∫ltiples llamadas de IA donde la salida de una alimenta la entrada de la siguiente. Este inicio r√°pido se enfoca en los fundamentos antes de explorar cadenas m√°s complejas.

<img src="../../../translated_images/langchain-concept.ad1fe6cf063515e1e961a13c73d45cfa305fd03d81bd11e5d34d0e36ed28a44d.es.png" alt="Concepto de Encadenamiento en LangChain4j" width="800"/>

*Encadenando componentes en LangChain4j - bloques de construcci√≥n que se conectan para crear flujos de trabajo de IA poderosos*

Usaremos tres componentes principales:

**ChatLanguageModel** - La interfaz para interacciones con modelos de IA. Llama a `model.chat("prompt")` y obt√©n una cadena de respuesta. Usamos `OpenAiOfficialChatModel` que funciona con endpoints compatibles con OpenAI como GitHub Models.

**AiServices** - Crea interfaces de servicio de IA con tipado seguro. Define m√©todos, an√≥talos con `@Tool`, y LangChain4j maneja la orquestaci√≥n. La IA llama autom√°ticamente a tus m√©todos Java cuando es necesario.

**MessageWindowChatMemory** - Mantiene el historial de la conversaci√≥n. Sin esto, cada solicitud es independiente. Con esto, la IA recuerda mensajes previos y mantiene el contexto a trav√©s de m√∫ltiples turnos.

<img src="../../../translated_images/architecture.eedc993a1c57683951f20244f652fc7a9853f571eea835bc2b2828cf0dbf62d0.es.png" alt="Arquitectura de LangChain4j" width="800"/>

*Arquitectura de LangChain4j - componentes centrales trabajando juntos para potenciar tus aplicaciones de IA*

## Dependencias de LangChain4j

Este inicio r√°pido usa dos dependencias Maven en el [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

El m√≥dulo `langchain4j-open-ai-official` provee la clase `OpenAiOfficialChatModel` que se conecta a APIs compatibles con OpenAI. GitHub Models usa el mismo formato de API, por lo que no se necesita un adaptador especial: solo apunta la URL base a `https://models.github.ai/inference`.

## Requisitos Previos

**¬øUsando el Contenedor de Desarrollo?** Java y Maven ya est√°n instalados. Solo necesitas un Token de Acceso Personal de GitHub.

**Desarrollo Local:**
- Java 21+, Maven 3.9+
- Token de Acceso Personal de GitHub (instrucciones abajo)

> **Nota:** Este m√≥dulo usa `gpt-4.1-nano` de GitHub Models. No modifiques el nombre del modelo en el c√≥digo: est√° configurado para funcionar con los modelos disponibles de GitHub.

## Configuraci√≥n

### 1. Obt√©n tu Token de GitHub

1. Ve a [Configuraci√≥n de GitHub ‚Üí Tokens de Acceso Personal](https://github.com/settings/personal-access-tokens)
2. Haz clic en "Generate new token"
3. Pon un nombre descriptivo (ej., "Demo LangChain4j")
4. Establece la expiraci√≥n (7 d√≠as recomendado)
5. Bajo "Permisos de cuenta", busca "Models" y ponlo en "Solo lectura"
6. Haz clic en "Generate token"
7. Copia y guarda tu token - no lo ver√°s de nuevo

### 2. Configura tu Token

**Opci√≥n 1: Usando VS Code (Recomendado)**

Si usas VS Code, agrega tu token al archivo `.env` en la ra√≠z del proyecto:

Si el archivo `.env` no existe, copia `.env.example` a `.env` o crea un nuevo archivo `.env` en la ra√≠z del proyecto.

**Ejemplo de archivo `.env`:**
```bash
# En /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Luego simplemente haz clic derecho en cualquier archivo demo (ej., `BasicChatDemo.java`) en el Explorador y selecciona **"Run Java"** o usa las configuraciones de lanzamiento desde el panel de Ejecutar y Depurar.

**Opci√≥n 2: Usando Terminal**

Configura el token como variable de entorno:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## Ejecuta los Ejemplos

**Usando VS Code:** Simplemente haz clic derecho en cualquier archivo demo en el Explorador y selecciona **"Run Java"**, o usa las configuraciones de lanzamiento desde el panel de Ejecutar y Depurar (aseg√∫rate de haber agregado tu token al archivo `.env` primero).

**Usando Maven:** Alternativamente, puedes ejecutar desde la l√≠nea de comandos:

### 1. Chat B√°sico

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Patrones de Prompt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Muestra zero-shot, few-shot, chain-of-thought y prompting basado en roles.

### 3. Llamada a Funciones

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

La IA llama autom√°ticamente a tus m√©todos Java cuando es necesario.

### 4. Preguntas y Respuestas sobre Documentos (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Haz preguntas sobre el contenido en `document.txt`.

## Qu√© Muestra Cada Ejemplo

**Chat B√°sico** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Comienza aqu√≠ para ver LangChain4j en su forma m√°s simple. Crear√°s un `OpenAiOfficialChatModel`, enviar√°s un prompt con `.chat()`, y recibir√°s una respuesta. Esto demuestra la base: c√≥mo inicializar modelos con endpoints personalizados y claves API. Una vez que entiendas este patr√≥n, todo lo dem√°s se construye sobre √©l.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) y pregunta:
> - "¬øC√≥mo cambiar√≠a de GitHub Models a Azure OpenAI en este c√≥digo?"
> - "¬øQu√© otros par√°metros puedo configurar en OpenAiOfficialChatModel.builder()?"
> - "¬øC√≥mo agrego respuestas en streaming en lugar de esperar la respuesta completa?"

**Ingenier√≠a de Prompt** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Ahora que sabes c√≥mo hablar con un modelo, exploremos qu√© le dices. Este demo usa la misma configuraci√≥n de modelo pero muestra cuatro patrones diferentes de prompting. Prueba prompts zero-shot para instrucciones directas, few-shot que aprenden de ejemplos, chain-of-thought que revelan pasos de razonamiento, y prompts basados en roles que establecen contexto. Ver√°s c√≥mo el mismo modelo da resultados dram√°ticamente diferentes seg√∫n c√≥mo formules tu solicitud.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) y pregunta:
> - "¬øCu√°l es la diferencia entre zero-shot y few-shot prompting, y cu√°ndo deber√≠a usar cada uno?"
> - "¬øC√≥mo afecta el par√°metro de temperatura las respuestas del modelo?"
> - "¬øCu√°les son algunas t√©cnicas para prevenir ataques de inyecci√≥n de prompt en producci√≥n?"
> - "¬øC√≥mo puedo crear objetos PromptTemplate reutilizables para patrones comunes?"

**Integraci√≥n de Herramientas** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Aqu√≠ es donde LangChain4j se vuelve poderoso. Usar√°s `AiServices` para crear un asistente de IA que puede llamar a tus m√©todos Java. Solo anota m√©todos con `@Tool("descripci√≥n")` y LangChain4j maneja el resto: la IA decide autom√°ticamente cu√°ndo usar cada herramienta seg√∫n lo que el usuario pregunte. Esto demuestra la llamada a funciones, una t√©cnica clave para construir IA que puede tomar acciones, no solo responder preguntas.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) y pregunta:
> - "¬øC√≥mo funciona la anotaci√≥n @Tool y qu√© hace LangChain4j con ella detr√°s de escena?"
> - "¬øPuede la IA llamar a m√∫ltiples herramientas en secuencia para resolver problemas complejos?"
> - "¬øQu√© pasa si una herramienta lanza una excepci√≥n - c√≥mo deber√≠a manejar errores?"
> - "¬øC√≥mo integrar√≠a una API real en lugar de este ejemplo de calculadora?"

**Preguntas y Respuestas sobre Documentos (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Aqu√≠ ver√°s la base de RAG (generaci√≥n aumentada por recuperaci√≥n). En lugar de depender de los datos de entrenamiento del modelo, cargas contenido de [`document.txt`](../../../00-quick-start/document.txt) y lo incluyes en el prompt. La IA responde basado en tu documento, no en su conocimiento general. Este es el primer paso para construir sistemas que pueden trabajar con tus propios datos.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Nota:** Este enfoque simple carga el documento completo en el prompt. Para archivos grandes (>10KB), superar√°s los l√≠mites de contexto. El M√≥dulo 03 cubre fragmentaci√≥n y b√∫squeda vectorial para sistemas RAG en producci√≥n.

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) y pregunta:
> - "¬øC√≥mo previene RAG las alucinaciones de IA comparado con usar los datos de entrenamiento del modelo?"
> - "¬øCu√°l es la diferencia entre este enfoque simple y usar embeddings vectoriales para recuperaci√≥n?"
> - "¬øC√≥mo escalar√≠a esto para manejar m√∫ltiples documentos o bases de conocimiento m√°s grandes?"
> - "¬øCu√°les son las mejores pr√°cticas para estructurar el prompt y asegurar que la IA use solo el contexto proporcionado?"

## Depuraci√≥n

Los ejemplos incluyen `.logRequests(true)` y `.logResponses(true)` para mostrar llamadas API en la consola. Esto ayuda a solucionar errores de autenticaci√≥n, l√≠mites de tasa o respuestas inesperadas. Quita estas banderas en producci√≥n para reducir el ruido en los logs.

## Pr√≥ximos Pasos

**Siguiente M√≥dulo:** [01-introduction - Comenzando con LangChain4j y gpt-5 en Azure](../01-introduction/README.md)

---

**Navegaci√≥n:** [‚Üê Volver al Inicio](../README.md) | [Siguiente: M√≥dulo 01 - Introducci√≥n ‚Üí](../01-introduction/README.md)

---

## Soluci√≥n de Problemas

### Primera Compilaci√≥n con Maven

**Problema:** La compilaci√≥n inicial `mvn clean compile` o `mvn package` tarda mucho (10-15 minutos)

**Causa:** Maven necesita descargar todas las dependencias del proyecto (Spring Boot, bibliotecas LangChain4j, SDKs de Azure, etc.) en la primera compilaci√≥n.

**Soluci√≥n:** Este comportamiento es normal. Las compilaciones siguientes ser√°n mucho m√°s r√°pidas porque las dependencias se almacenan en cach√© localmente. El tiempo de descarga depende de la velocidad de tu red.

### Sintaxis de Comando Maven en PowerShell

**Problema:** Los comandos Maven fallan con error `Unknown lifecycle phase ".mainClass=..."`

**Causa:** PowerShell interpreta `=` como operador de asignaci√≥n de variable, rompiendo la sintaxis de propiedades de Maven.

**Soluci√≥n:** Usa el operador de detenci√≥n de an√°lisis `--%` antes del comando Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

El operador `--%` indica a PowerShell que pase todos los argumentos restantes literalmente a Maven sin interpretaci√≥n.

### Visualizaci√≥n de Emojis en Windows PowerShell

**Problema:** Las respuestas de IA muestran caracteres basura (ej., `????` o `√¢??`) en lugar de emojis en PowerShell

**Causa:** La codificaci√≥n predeterminada de PowerShell no soporta emojis UTF-8

**Soluci√≥n:** Ejecuta este comando antes de ejecutar aplicaciones Java:
```cmd
chcp 65001
```

Esto fuerza la codificaci√≥n UTF-8 en la terminal. Alternativamente, usa Windows Terminal que tiene mejor soporte Unicode.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso legal**:
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->