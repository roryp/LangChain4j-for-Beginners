# M√≥dulo 00: Inicio R√°pido

## Tabla de Contenidos

- [Introducci√≥n](../../../00-quick-start)
- [¬øQu√© es LangChain4j?](../../../00-quick-start)
- [Dependencias de LangChain4j](../../../00-quick-start)
- [Requisitos Previos](../../../00-quick-start)
- [Configuraci√≥n](../../../00-quick-start)
  - [1. Obt√©n Tu Token de GitHub](../../../00-quick-start)
  - [2. Establece Tu Token](../../../00-quick-start)
- [Ejecuta los Ejemplos](../../../00-quick-start)
  - [1. Chat B√°sico](../../../00-quick-start)
  - [2. Patrones de Prompt](../../../00-quick-start)
  - [3. Llamadas a Funciones](../../../00-quick-start)
  - [4. Preguntas y Respuestas de Documentos (RAG)](../../../00-quick-start)
  - [5. IA Responsable](../../../00-quick-start)
- [Qu√© Muestra Cada Ejemplo](../../../00-quick-start)
- [Pr√≥ximos Pasos](../../../00-quick-start)
- [Soluci√≥n de Problemas](../../../00-quick-start)

## Introducci√≥n

Este inicio r√°pido est√° dise√±ado para que comiences a usar LangChain4j lo m√°s pronto posible. Cubre lo b√°sico absoluto para construir aplicaciones de IA con LangChain4j y GitHub Models. En los pr√≥ximos m√≥dulos usar√°s Azure OpenAI con LangChain4j para crear aplicaciones m√°s avanzadas.

## ¬øQu√© es LangChain4j?

LangChain4j es una biblioteca de Java que simplifica la construcci√≥n de aplicaciones potenciadas por IA. En lugar de lidiar con clientes HTTP y an√°lisis JSON, trabajas con APIs limpias en Java.

La "cadena" en LangChain se refiere a encadenar m√∫ltiples componentes: puedes encadenar un prompt a un modelo y despu√©s a un analizador, o encadenar m√∫ltiples llamadas IA donde una salida alimenta la siguiente entrada. Este inicio r√°pido se enfoca en los fundamentos antes de explorar cadenas m√°s complejas.

<img src="../../../translated_images/es/langchain-concept.ad1fe6cf063515e1.webp" alt="Concepto de Encadenamiento LangChain4j" width="800"/>

*Componentes encadenados en LangChain4j: bloques de construcci√≥n conectados para crear flujos de trabajo de IA poderosos*

Usaremos tres componentes principales:

**ChatLanguageModel** - La interfaz para interacciones con modelos de IA. Llama a `model.chat("prompt")` y obt√©n una cadena de respuesta. Usamos `OpenAiOfficialChatModel` que funciona con puntos finales compatibles con OpenAI como GitHub Models.

**AiServices** - Crea interfaces de servicio IA tipo-seguro. Define m√©todos, an√≥talos con `@Tool`, y LangChain4j maneja la orquestaci√≥n. La IA llama autom√°ticamente tus m√©todos Java cuando es necesario.

**MessageWindowChatMemory** - Mantiene el historial de conversaci√≥n. Sin esto, cada petici√≥n es independiente. Con esto, la IA recuerda mensajes previos y mantiene el contexto en m√∫ltiples turnos.

<img src="../../../translated_images/es/architecture.eedc993a1c576839.webp" alt="Arquitectura LangChain4j" width="800"/>

*Arquitectura de LangChain4j: componentes centrales trabajando juntos para potenciar tus aplicaciones de IA*

## Dependencias de LangChain4j

Este inicio r√°pido utiliza dos dependencias Maven en el [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

El m√≥dulo `langchain4j-open-ai-official` provee la clase `OpenAiOfficialChatModel` que se conecta a APIs compatibles con OpenAI. GitHub Models usa el mismo formato de API, as√≠ que no se necesita un adaptador especial ‚Äì solo apunta la URL base a `https://models.github.ai/inference`.

## Requisitos Previos

**¬øUsando el Contenedor de Desarrollo?** Java y Maven ya est√°n instalados. Solo necesitas un Token de Acceso Personal de GitHub.

**Desarrollo Local:**
- Java 21+, Maven 3.9+
- Token de Acceso Personal de GitHub (instrucciones abajo)

> **Nota:** Este m√≥dulo usa `gpt-4.1-nano` de GitHub Models. No modifiques el nombre del modelo en el c√≥digo, est√° configurado para funcionar con los modelos disponibles en GitHub.

## Configuraci√≥n

### 1. Obt√©n Tu Token de GitHub

1. Ve a [Configuraci√≥n de GitHub ‚Üí Tokens de Acceso Personal](https://github.com/settings/personal-access-tokens)
2. Haz clic en "Generate new token" (Generar nuevo token)
3. Pon un nombre descriptivo (p.ej., "Demo LangChain4j")
4. Establece la expiraci√≥n (se recomiendan 7 d√≠as)
5. Bajo "Permisos de la cuenta", busca "Models" y ponlo en "Solo lectura"
6. Haz clic en "Generate token"
7. Copia y guarda tu token: no lo ver√°s de nuevo

### 2. Establece Tu Token

**Opci√≥n 1: Usando VS Code (Recomendado)**

Si usas VS Code, a√±ade tu token al archivo `.env` en la ra√≠z del proyecto:

Si el archivo `.env` no existe, copia `.env.example` a `.env` o crea un archivo `.env` nuevo en la ra√≠z del proyecto.

**Ejemplo de archivo `.env`:**
```bash
# En /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Luego puedes hacer clic derecho en cualquier archivo demo (ej., `BasicChatDemo.java`) en el Explorador y seleccionar **"Run Java"** o usar las configuraciones de lanzamiento en el panel de Ejecutar y Depurar.

**Opci√≥n 2: Usando Terminal**

Establece el token como variable de entorno:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## Ejecuta los Ejemplos

**Usando VS Code:** Simplemente haz clic derecho en cualquier archivo demo en el Explorador y selecciona **"Run Java"**, o usa las configuraciones de lanzamiento en el panel Ejecutar y Depurar (aseg√∫rate de haber a√±adido tu token al archivo `.env` primero).

**Usando Maven:** Alternativamente, puedes ejecutar desde l√≠nea de comandos:

### 1. Chat B√°sico

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Patrones de Prompt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Muestra prompting zero-shot, few-shot, cadena de pensamiento y basado en roles.

### 3. Llamadas a Funciones

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

La IA llama autom√°ticamente tus m√©todos Java cuando es necesario.

### 4. Preguntas y Respuestas de Documentos (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Haz preguntas sobre el contenido en `document.txt`.

### 5. IA Responsable

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

Muestra c√≥mo los filtros de seguridad de IA bloquean contenido da√±ino.

## Qu√© Muestra Cada Ejemplo

**Chat B√°sico** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Empieza aqu√≠ para ver LangChain4j en su forma m√°s simple. Crear√°s un `OpenAiOfficialChatModel`, enviar√°s un prompt con `.chat()`, y recibir√°s una respuesta. Esto demuestra la base: c√≥mo inicializar modelos con endpoints personalizados y claves API. Una vez entiendas este patr√≥n, todo lo dem√°s se construye sobre √©l.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) y pregunta:
> - "¬øC√≥mo cambiar√≠a de GitHub Models a Azure OpenAI en este c√≥digo?"
> - "¬øQu√© otros par√°metros puedo configurar en OpenAiOfficialChatModel.builder()?"
> - "¬øC√≥mo agrego respuestas en streaming en lugar de esperar la respuesta completa?"

**Ingenier√≠a de Prompt** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Ahora que sabes c√≥mo hablar con un modelo, exploremos qu√© le dices. Este demo usa la misma configuraci√≥n de modelo pero muestra cuatro patrones distintos de prompting. Prueba prompts zero-shot para instrucciones directas, few-shot que aprenden de ejemplos, cadena de pensamiento que revelan pasos de razonamiento, y prompts basados en roles que establecen contexto. Ver√°s c√≥mo el mismo modelo da resultados muy distintos seg√∫n c√≥mo formules tu solicitud.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) y pregunta:
> - "¬øCu√°l es la diferencia entre prompting zero-shot y few-shot, y cu√°ndo deber√≠a usar cada uno?"
> - "¬øC√≥mo afecta el par√°metro temperature las respuestas del modelo?"
> - "¬øQu√© t√©cnicas existen para prevenir ataques de inyecci√≥n de prompt en producci√≥n?"
> - "¬øC√≥mo puedo crear objetos PromptTemplate reutilizables para patrones comunes?"

**Integraci√≥n de Herramientas** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Aqu√≠ es donde LangChain4j se vuelve poderoso. Usar√°s `AiServices` para crear un asistente IA que puede llamar a tus m√©todos Java. Solo anota m√©todos con `@Tool("descripcion")` y LangChain4j se encarga del resto: la IA decide autom√°ticamente cu√°ndo usar cada herramienta seg√∫n lo que el usuario pregunte. Esto demuestra llamadas a funciones, una t√©cnica clave para construir IA que puede actuar, no solo responder preguntas.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) y pregunta:
> - "¬øC√≥mo funciona la anotaci√≥n @Tool y qu√© hace LangChain4j con ella internamente?"
> - "¬øPuede la IA llamar a m√∫ltiples herramientas en secuencia para resolver problemas complejos?"
> - "¬øQu√© pasa si una herramienta lanza una excepci√≥n? ¬øC√≥mo debo manejar errores?"
> - "¬øC√≥mo integrar√≠a una API real en lugar de este ejemplo de calculadora?"

**Preguntas y Respuestas de Documentos (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Aqu√≠ ver√°s la base de RAG (generaci√≥n aumentada por recuperaci√≥n). En lugar de depender de los datos de entrenamiento del modelo, cargas contenido desde [`document.txt`](../../../00-quick-start/document.txt) y lo incluyes en el prompt. La IA responde basada en tu documento, no en su conocimiento general. Este es el primer paso para construir sistemas que trabajan con tus propios datos.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Nota:** Este enfoque simple carga el documento entero en el prompt. Para archivos grandes (>10KB), superar√°s l√≠mites de contexto. El M√≥dulo 03 cubre fragmentaci√≥n y b√∫squeda vectorial para sistemas RAG en producci√≥n.

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) y pregunta:
> - "¬øC√≥mo previene RAG las alucinaciones de IA comparado con usar los datos de entrenamiento del modelo?"
> - "¬øCu√°l es la diferencia entre este enfoque simple y usar embeddings vectoriales para recuperaci√≥n?"
> - "¬øC√≥mo escalar√≠a esto para manejar m√∫ltiples documentos o bases de conocimiento m√°s grandes?"
> - "¬øCu√°les son las mejores pr√°cticas para estructurar el prompt para asegurar que la IA use solo el contexto proporcionado?"

**IA Responsable** - [ResponsibleAIDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java)

Construye seguridad en IA con defensa en profundidad. Este demo muestra dos capas de protecci√≥n trabajando juntas:

**Parte 1: LangChain4j Input Guardrails** - Bloquea prompts peligrosos antes de llegar al LLM. Crea guardrails personalizados que revisan palabras clave o patrones prohibidos. Estos corren en tu c√≥digo, por lo que son r√°pidos y gratuitos.

```java
class DangerousContentGuardrail implements InputGuardrail {
    @Override
    public InputGuardrailResult validate(UserMessage userMessage) {
        String text = userMessage.singleText().toLowerCase();
        if (text.contains("explosives")) {
            return fatal("Blocked: contains prohibited keyword");
        }
        return success();
    }
}
```

**Parte 2: Filtros de Seguridad del Proveedor** - GitHub Models tiene filtros incorporados que atrapan lo que tus guardrails puedan pasar por alto. Ver√°s bloqueos estrictos (errores HTTP 400) para violaciones graves y rechazos suaves donde la IA rechaza amablemente.

> **ü§ñ Prueba con [GitHub Copilot](https://github.com/features/copilot) Chat:** Abre [`ResponsibleAIDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java) y pregunta:
> - "¬øQu√© es InputGuardrail y c√≥mo creo la m√≠a?"
> - "¬øCu√°l es la diferencia entre un bloqueo estricto y un rechazo suave?"
> - "¬øPor qu√© usar tanto guardrails como filtros del proveedor juntos?"

## Pr√≥ximos Pasos

**Siguiente M√≥dulo:** [01-introducci√≥n - Comenzando con LangChain4j y gpt-5 en Azure](../01-introduction/README.md)

---

**Navegaci√≥n:** [‚Üê Volver al Inicio](../README.md) | [Siguiente: M√≥dulo 01 - Introducci√≥n ‚Üí](../01-introduction/README.md)

---

## Soluci√≥n de Problemas

### Primera Construcci√≥n con Maven

**Problema**: La compilaci√≥n inicial `mvn clean compile` o `mvn package` tarda mucho (10-15 minutos)

**Causa**: Maven necesita descargar todas las dependencias del proyecto (Spring Boot, librer√≠as LangChain4j, SDKs de Azure, etc.) en la primera compilaci√≥n.

**Soluci√≥n**: Este comportamiento es normal. Las compilaciones siguientes ser√°n mucho m√°s r√°pidas porque las dependencias se almacenan en cach√© localmente. El tiempo de descarga depende de tu velocidad de red.

### Sintaxis del Comando Maven en PowerShell

**Problema**: Los comandos Maven fallan con el error `Unknown lifecycle phase ".mainClass=..."`

**Causa**: PowerShell interpreta `=` como operador de asignaci√≥n de variable, lo que rompe la sintaxis de propiedad de Maven.
**Soluci√≥n**: Use el operador de parada de an√°lisis `--%` antes del comando Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

El operador `--%` indica a PowerShell que pase todos los argumentos restantes literalmente a Maven sin interpretaci√≥n.

### Visualizaci√≥n de emojis en Windows PowerShell

**Problema**: Las respuestas de la IA muestran caracteres basura (por ejemplo, `????` o `√¢??`) en lugar de emojis en PowerShell

**Causa**: La codificaci√≥n predeterminada de PowerShell no soporta emojis UTF-8

**Soluci√≥n**: Ejecute este comando antes de ejecutar aplicaciones Java:
```cmd
chcp 65001
```

Esto fuerza la codificaci√≥n UTF-8 en la terminal. Alternativamente, use Windows Terminal, que tiene mejor soporte para Unicode.

### Depuraci√≥n de llamadas a la API

**Problema**: Errores de autenticaci√≥n, l√≠mites de tasa, o respuestas inesperadas del modelo de IA

**Soluci√≥n**: Los ejemplos incluyen `.logRequests(true)` y `.logResponses(true)` para mostrar las llamadas a la API en la consola. Esto ayuda a solucionar errores de autenticaci√≥n, l√≠mites de tasa o respuestas inesperadas. Elimine estas opciones en producci√≥n para reducir el ruido en los registros.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->