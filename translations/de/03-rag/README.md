<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f538a51cfd13147d40d84e936a0f485c",
  "translation_date": "2025-12-13T16:43:23+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "de"
}
-->
# Modul 03: RAG (Retrieval-Augmented Generation)

## Inhaltsverzeichnis

- [Was Sie lernen werden](../../../03-rag)
- [Voraussetzungen](../../../03-rag)
- [Verst√§ndnis von RAG](../../../03-rag)
- [Wie es funktioniert](../../../03-rag)
  - [Dokumentenverarbeitung](../../../03-rag)
  - [Erstellung von Embeddings](../../../03-rag)
  - [Semantische Suche](../../../03-rag)
  - [Antwortgenerierung](../../../03-rag)
- [Anwendung starten](../../../03-rag)
- [Anwendung verwenden](../../../03-rag)
  - [Dokument hochladen](../../../03-rag)
  - [Fragen stellen](../../../03-rag)
  - [Quellenangaben pr√ºfen](../../../03-rag)
  - [Mit Fragen experimentieren](../../../03-rag)
- [Wichtige Konzepte](../../../03-rag)
  - [Chunking-Strategie](../../../03-rag)
  - [√Ñhnlichkeitsscores](../../../03-rag)
  - [In-Memory-Speicherung](../../../03-rag)
  - [Verwaltung des Kontextfensters](../../../03-rag)
- [Wann RAG wichtig ist](../../../03-rag)
- [N√§chste Schritte](../../../03-rag)

## Was Sie lernen werden

In den vorherigen Modulen haben Sie gelernt, wie man Gespr√§che mit KI f√ºhrt und Ihre Prompts effektiv strukturiert. Aber es gibt eine grundlegende Einschr√§nkung: Sprachmodelle wissen nur, was sie w√§hrend des Trainings gelernt haben. Sie k√∂nnen keine Fragen zu den Richtlinien Ihres Unternehmens, Ihrer Projektdokumentation oder zu Informationen beantworten, auf die sie nicht trainiert wurden.

RAG (Retrieval-Augmented Generation) l√∂st dieses Problem. Anstatt zu versuchen, dem Modell Ihre Informationen beizubringen (was teuer und unpraktisch ist), geben Sie ihm die F√§higkeit, in Ihren Dokumenten zu suchen. Wenn jemand eine Frage stellt, findet das System relevante Informationen und f√ºgt sie in den Prompt ein. Das Modell antwortet dann basierend auf diesem abgerufenen Kontext.

Man kann sich RAG vorstellen wie eine Referenzbibliothek f√ºr das Modell. Wenn Sie eine Frage stellen, macht das System:

1. **Benutzeranfrage** ‚Äì Sie stellen eine Frage
2. **Embedding** ‚Äì Wandelt Ihre Frage in einen Vektor um
3. **Vektorsuche** ‚Äì Findet √§hnliche Dokumentenabschnitte
4. **Kontextzusammenstellung** ‚Äì F√ºgt relevante Abschnitte dem Prompt hinzu
5. **Antwort** ‚Äì LLM generiert eine Antwort basierend auf dem Kontext

Dies verankert die Antworten des Modells in Ihren tats√§chlichen Daten, anstatt sich auf das Trainingswissen zu verlassen oder Antworten zu erfinden.

<img src="../../../translated_images/rag-architecture.ccb53b71a6ce407fa8a6394c7a747eb9ad40f6334b4c217be0439d700f22bbcc.de.png" alt="RAG Architektur" width="800"/>

*RAG-Workflow ‚Äì von der Benutzeranfrage √ºber die semantische Suche bis zur kontextuellen Antwortgenerierung*

## Voraussetzungen

- Abgeschlossenes Modul 01 (Azure OpenAI-Ressourcen bereitgestellt)
- `.env`-Datei im Stammverzeichnis mit Azure-Zugangsdaten (erstellt durch `azd up` in Modul 01)

> **Hinweis:** Wenn Sie Modul 01 noch nicht abgeschlossen haben, folgen Sie dort zuerst den Bereitstellungsanweisungen.

## Wie es funktioniert

**Dokumentenverarbeitung** ‚Äì [DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

Wenn Sie ein Dokument hochladen, zerlegt das System es in Chunks ‚Äì kleinere St√ºcke, die bequem in das Kontextfenster des Modells passen. Diese Chunks √ºberlappen sich leicht, damit am Rand kein Kontext verloren geht.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```

> **ü§ñ Probieren Sie es mit [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñffnen Sie [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) und fragen Sie:
> - "Wie teilt LangChain4j Dokumente in Chunks auf und warum ist √úberlappung wichtig?"
> - "Was ist die optimale Chunk-Gr√∂√üe f√ºr verschiedene Dokumenttypen und warum?"
> - "Wie gehe ich mit Dokumenten in mehreren Sprachen oder mit spezieller Formatierung um?"

**Erstellung von Embeddings** ‚Äì [LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Jeder Chunk wird in eine numerische Darstellung namens Embedding umgewandelt ‚Äì im Wesentlichen ein mathematischer Fingerabdruck, der die Bedeutung des Textes erfasst. √Ñhnliche Texte erzeugen √§hnliche Embeddings.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```

<img src="../../../translated_images/vector-embeddings.2ef7bdddac79a327ad9e3e46cde9a86f5eeefbeb3edccd387e33018c1671cecd.de.png" alt="Vektor-Embedding-Raum" width="800"/>

*Dokumente als Vektoren im Embedding-Raum dargestellt ‚Äì √§hnliche Inhalte gruppieren sich*

**Semantische Suche** ‚Äì [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Wenn Sie eine Frage stellen, wird auch Ihre Frage in ein Embedding umgewandelt. Das System vergleicht das Embedding Ihrer Frage mit allen Embeddings der Dokumentenabschnitte. Es findet die Abschnitte mit der gr√∂√üten semantischen √Ñhnlichkeit ‚Äì nicht nur passende Schl√ºsselw√∂rter, sondern tats√§chliche Bedeutungs√§hnlichkeit.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```

> **ü§ñ Probieren Sie es mit [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñffnen Sie [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) und fragen Sie:
> - "Wie funktioniert die √Ñhnlichkeitssuche mit Embeddings und was bestimmt den Score?"
> - "Welchen √Ñhnlichkeitsschwellenwert sollte ich verwenden und wie beeinflusst er die Ergebnisse?"
> - "Wie gehe ich mit F√§llen um, in denen keine relevanten Dokumente gefunden werden?"

**Antwortgenerierung** ‚Äì [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Die relevantesten Chunks werden in den Prompt an das Modell aufgenommen. Das Modell liest diese spezifischen Abschnitte und beantwortet Ihre Frage basierend auf diesen Informationen. Dies verhindert Halluzinationen ‚Äì das Modell kann nur aus dem antworten, was vorliegt.

## Anwendung starten

**Bereitstellung √ºberpr√ºfen:**

Stellen Sie sicher, dass die `.env`-Datei im Stammverzeichnis mit Azure-Zugangsdaten existiert (wurde w√§hrend Modul 01 erstellt):
```bash
cat ../.env  # Sollte AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT anzeigen
```

**Anwendung starten:**

> **Hinweis:** Wenn Sie bereits alle Anwendungen mit `./start-all.sh` aus Modul 01 gestartet haben, l√§uft dieses Modul bereits auf Port 8081. Sie k√∂nnen die Startbefehle unten √ºberspringen und direkt zu http://localhost:8081 gehen.

**Option 1: Verwendung des Spring Boot Dashboards (empfohlen f√ºr VS Code Nutzer)**

Der Dev-Container enth√§lt die Erweiterung Spring Boot Dashboard, die eine visuelle Oberfl√§che zur Verwaltung aller Spring Boot Anwendungen bietet. Sie finden sie in der Aktivit√§tsleiste links in VS Code (Suchen Sie nach dem Spring Boot Symbol).

Im Spring Boot Dashboard k√∂nnen Sie:
- Alle verf√ºgbaren Spring Boot Anwendungen im Workspace sehen
- Anwendungen mit einem Klick starten/stoppen
- Anwendungsprotokolle in Echtzeit ansehen
- Anwendungsstatus √ºberwachen

Klicken Sie einfach auf den Play-Button neben ‚Äûrag‚Äú, um dieses Modul zu starten, oder starten Sie alle Module gleichzeitig.

<img src="../../../translated_images/dashboard.fbe6e28bf4267ffe4f95a708ecd46e78f69fd46a562d2a766e73c98fe0f53922.de.png" alt="Spring Boot Dashboard" width="400"/>

**Option 2: Verwendung von Shell-Skripten**

Starten Sie alle Webanwendungen (Module 01-04):

**Bash:**
```bash
cd ..  # Vom Stammverzeichnis
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Vom Stammverzeichnis
.\start-all.ps1
```

Oder starten Sie nur dieses Modul:

**Bash:**
```bash
cd 03-rag
./start.sh
```

**PowerShell:**
```powershell
cd 03-rag
.\start.ps1
```

Beide Skripte laden automatisch Umgebungsvariablen aus der `.env`-Datei im Stammverzeichnis und bauen die JARs, falls sie nicht existieren.

> **Hinweis:** Wenn Sie alle Module manuell vor dem Start bauen m√∂chten:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

√ñffnen Sie http://localhost:8081 in Ihrem Browser.

**Zum Stoppen:**

**Bash:**
```bash
./stop.sh  # Nur dieses Modul
# Oder
cd .. && ./stop-all.sh  # Alle Module
```

**PowerShell:**
```powershell
.\stop.ps1  # Nur dieses Modul
# Oder
cd ..; .\stop-all.ps1  # Alle Module
```

## Anwendung verwenden

Die Anwendung bietet eine Weboberfl√§che zum Hochladen von Dokumenten und zum Stellen von Fragen.

<a href="images/rag-homepage.png"><img src="../../../translated_images/rag-homepage.d90eb5ce1b3caa94987b4fa2923d3cb884a67987cf2f994ca53756c6586a93b1.de.png" alt="RAG Anwendungsoberfl√§che" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Die RAG-Anwendungsoberfl√§che ‚Äì Dokumente hochladen und Fragen stellen*

**Dokument hochladen**

Beginnen Sie mit dem Hochladen eines Dokuments ‚Äì TXT-Dateien eignen sich am besten zum Testen. Eine `sample-document.txt` ist in diesem Verzeichnis enthalten, die Informationen √ºber LangChain4j-Funktionen, RAG-Implementierung und Best Practices enth√§lt ‚Äì perfekt zum Testen des Systems.

Das System verarbeitet Ihr Dokument, zerlegt es in Chunks und erstellt f√ºr jeden Chunk Embeddings. Dies geschieht automatisch beim Hochladen.

**Fragen stellen**

Stellen Sie nun spezifische Fragen zum Dokumentinhalt. Versuchen Sie etwas Faktisches, das klar im Dokument steht. Das System sucht nach relevanten Chunks, f√ºgt sie dem Prompt hinzu und generiert eine Antwort.

**Quellenangaben pr√ºfen**

Beachten Sie, dass jede Antwort Quellenangaben mit √Ñhnlichkeitsscores enth√§lt. Diese Scores (0 bis 1) zeigen, wie relevant jeder Chunk f√ºr Ihre Frage war. H√∂here Scores bedeuten bessere √úbereinstimmungen. So k√∂nnen Sie die Antwort mit dem Quellmaterial verifizieren.

<a href="images/rag-query-results.png"><img src="../../../translated_images/rag-query-results.6d69fcec5397f3558c788388bb395191616dad4c7c0417f1a68bd18590ad0a0e.de.png" alt="RAG Abfrageergebnisse" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Abfrageergebnisse mit Antwort, Quellenangaben und Relevanzscores*

**Mit Fragen experimentieren**

Probieren Sie verschiedene Fragetypen aus:
- Spezifische Fakten: ‚ÄûWas ist das Hauptthema?‚Äú
- Vergleiche: ‚ÄûWas ist der Unterschied zwischen X und Y?‚Äú
- Zusammenfassungen: ‚ÄûFassen Sie die wichtigsten Punkte zu Z zusammen‚Äú

Beobachten Sie, wie sich die Relevanzscores √§ndern, je nachdem, wie gut Ihre Frage zum Dokumentinhalt passt.

## Wichtige Konzepte

**Chunking-Strategie**

Dokumente werden in 300-Token-Chunks mit 30 Token √úberlappung aufgeteilt. Dieses Gleichgewicht stellt sicher, dass jeder Chunk genug Kontext hat, um sinnvoll zu sein, und gleichzeitig klein genug bleibt, um mehrere Chunks in einem Prompt unterzubringen.

**√Ñhnlichkeitsscores**

Scores reichen von 0 bis 1:
- 0,7‚Äì1,0: Hoch relevant, exakte √úbereinstimmung
- 0,5‚Äì0,7: Relevant, guter Kontext
- Unter 0,5: Gefiltert, zu un√§hnlich

Das System ruft nur Chunks oberhalb der Mindestgrenze ab, um Qualit√§t zu gew√§hrleisten.

**In-Memory-Speicherung**

Dieses Modul verwendet zur Vereinfachung eine In-Memory-Speicherung. Beim Neustart der Anwendung gehen hochgeladene Dokumente verloren. Produktionssysteme nutzen persistente Vektordatenbanken wie Qdrant oder Azure AI Search.

**Verwaltung des Kontextfensters**

Jedes Modell hat ein maximales Kontextfenster. Sie k√∂nnen nicht jeden Chunk eines gro√üen Dokuments einf√ºgen. Das System ruft die Top N relevantesten Chunks ab (Standard 5), um innerhalb der Grenzen zu bleiben und dennoch genug Kontext f√ºr genaue Antworten zu bieten.

## Wann RAG wichtig ist

**Verwenden Sie RAG, wenn:**
- Fragen zu propriet√§ren Dokumenten beantwortet werden sollen
- Informationen sich h√§ufig √§ndern (Richtlinien, Preise, Spezifikationen)
- Genauigkeit mit Quellenangabe erforderlich ist
- Inhalte zu gro√ü sind, um in einen einzelnen Prompt zu passen
- Sie √ºberpr√ºfbare, fundierte Antworten ben√∂tigen

**Verwenden Sie RAG nicht, wenn:**
- Fragen allgemeines Wissen erfordern, das das Modell bereits hat
- Echtzeitdaten ben√∂tigt werden (RAG arbeitet mit hochgeladenen Dokumenten)
- Inhalte klein genug sind, um direkt in Prompts eingef√ºgt zu werden

## N√§chste Schritte

**N√§chstes Modul:** [04-tools - KI-Agenten mit Tools](../04-tools/README.md)

---

**Navigation:** [‚Üê Vorheriges: Modul 02 - Prompt Engineering](../02-prompt-engineering/README.md) | [Zur√ºck zur √úbersicht](../README.md) | [N√§chstes: Modul 04 - Tools ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner Ursprungssprache gilt als ma√ügebliche Quelle. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->