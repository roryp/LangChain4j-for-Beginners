# ModuÅ‚ 00: Szybki start

## Spis treÅ›ci

- [Wprowadzenie](../../../00-quick-start)
- [Czym jest LangChain4j?](../../../00-quick-start)
- [ZaleÅ¼noÅ›ci LangChain4j](../../../00-quick-start)
- [Wymagania wstÄ™pne](../../../00-quick-start)
- [Konfiguracja](../../../00-quick-start)
  - [1. Pobierz swÃ³j token GitHub](../../../00-quick-start)
  - [2. Ustaw swÃ³j token](../../../00-quick-start)
- [Uruchom przykÅ‚ady](../../../00-quick-start)
  - [1. Podstawowy czat](../../../00-quick-start)
  - [2. Wzorce promptÃ³w](../../../00-quick-start)
  - [3. WywoÅ‚ywanie funkcji](../../../00-quick-start)
  - [4. Pytania i odpowiedzi na podstawie dokumentÃ³w (RAG)](../../../00-quick-start)
  - [5. Odpowiedzialna sztuczna inteligencja](../../../00-quick-start)
- [Co pokazuje kaÅ¼dy przykÅ‚ad](../../../00-quick-start)
- [Kolejne kroki](../../../00-quick-start)
- [RozwiÄ…zywanie problemÃ³w](../../../00-quick-start)

## Wprowadzenie

Ten szybki start ma na celu jak najszybsze uruchomienie LangChain4j. Obejmuje absolutne podstawy budowania aplikacji AI z LangChain4j i modelami GitHub. W kolejnych moduÅ‚ach uÅ¼yjesz Azure OpenAI z LangChain4j, aby tworzyÄ‡ bardziej zaawansowane aplikacje.

## Czym jest LangChain4j?

LangChain4j to biblioteka Java, ktÃ³ra upraszcza tworzenie aplikacji napÄ™dzanych sztucznÄ… inteligencjÄ…. Zamiast zajmowaÄ‡ siÄ™ klientami HTTP i analizÄ… JSON, pracujesz z czystymi interfejsami API w jÄ™zyku Java.

â€Chainâ€ w LangChain odnosi siÄ™ do Å‚Ä…czenia ze sobÄ… wielu komponentÃ³w â€“ moÅ¼esz powiÄ…zaÄ‡ prompt z modelem i parserem lub poÅ‚Ä…czyÄ‡ wiele wywoÅ‚aÅ„ AI, gdzie jedno wyjÅ›cie jest wejÅ›ciem do nastÄ™pnego. Ten szybki start koncentruje siÄ™ na podstawach, zanim przejdziemy do bardziej zÅ‚oÅ¼onych Å‚aÅ„cuchÃ³w.

<img src="../../../translated_images/pl/langchain-concept.ad1fe6cf063515e1.webp" alt="Koncept Å‚aÅ„cuchowania w LangChain4j" width="800"/>

*ÅÄ…czenie komponentÃ³w w LangChain4j â€“ bloki konstrukcyjne tworzÄ… potÄ™Å¼ne przepÅ‚ywy AI*

UÅ¼yjemy trzech gÅ‚Ã³wnych komponentÃ³w:

**ChatLanguageModel** â€“ interfejs do interakcji z modelem AI. WywoÅ‚aj `model.chat("prompt")` i otrzymaj odpowiedÅº w postaci Å‚aÅ„cucha znakÃ³w. UÅ¼ywamy `OpenAiOfficialChatModel`, ktÃ³ry wspÃ³Å‚pracuje z punktami koÅ„cowymi kompatybilnymi z OpenAI, takimi jak GitHub Models.

**AiServices** â€“ tworzy bezpieczne typowo interfejsy usÅ‚ug AI. Definiujesz metody, oznaczasz je adnotacjÄ… `@Tool`, a LangChain4j zajmuje siÄ™ orkiestracjÄ…. AI automatycznie wywoÅ‚uje Twoje metody w Javie w razie potrzeby.

**MessageWindowChatMemory** â€“ utrzymuje historiÄ™ rozmowy. Bez tego kaÅ¼de zapytanie jest niezaleÅ¼ne. Z tym komponentem AI pamiÄ™ta poprzednie wiadomoÅ›ci i utrzymuje kontekst przez wiele tur.

<img src="../../../translated_images/pl/architecture.eedc993a1c576839.webp" alt="Architektura LangChain4j" width="800"/>

*Architektura LangChain4j â€“ gÅ‚Ã³wne komponenty wspÃ³Å‚pracujÄ…, aby zasilaÄ‡ twoje aplikacje AI*

## ZaleÅ¼noÅ›ci LangChain4j

Ten szybki start uÅ¼ywa dwÃ³ch zaleÅ¼noÅ›ci Maven w [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```
  
ModuÅ‚ `langchain4j-open-ai-official` dostarcza klasÄ™ `OpenAiOfficialChatModel` Å‚Ä…czÄ…cÄ… siÄ™ z API kompatybilnymi z OpenAI. GitHub Models uÅ¼ywa tego samego formatu API, wiÄ™c nie jest potrzebny specjalny adapter â€“ wystarczy wskazaÄ‡ podstawowy adres URL na `https://models.github.ai/inference`.

## Wymagania wstÄ™pne

**UÅ¼ywasz kontenera deweloperskiego?** Java i Maven sÄ… juÅ¼ zainstalowane. Potrzebujesz tylko osobistego tokena dostÄ™pu GitHub.

**Lokalny rozwÃ³j:**  
- Java 21+, Maven 3.9+  
- Osobisty token dostÄ™pu GitHub (instrukcje poniÅ¼ej)

> **Uwaga:** Ten moduÅ‚ uÅ¼ywa modelu `gpt-4.1-nano` z GitHub Models. Nie modyfikuj nazwy modelu w kodzie â€“ jest skonfigurowany do pracy z dostÄ™pnymi modelami GitHub.

## Konfiguracja

### 1. Pobierz swÃ³j token GitHub

1. PrzejdÅº do [Ustawienia GitHub â†’ Personal Access Tokens](https://github.com/settings/personal-access-tokens)  
2. Kliknij â€Generate new tokenâ€  
3. Ustaw opisowÄ… nazwÄ™ (np. â€LangChain4j Demoâ€)  
4. Ustaw czas waÅ¼noÅ›ci (zalecane 7 dni)  
5. W sekcji â€Account permissionsâ€ znajdÅº â€Modelsâ€ i ustaw na â€Read-onlyâ€  
6. Kliknij â€Generate tokenâ€  
7. Skopiuj i zapisz token â€“ nie zobaczysz go ponownie

### 2. Ustaw swÃ³j token

**Opcja 1: UÅ¼ywajÄ…c VS Code (zalecane)**

JeÅ›li uÅ¼ywasz VS Code, dodaj token do pliku `.env` w katalogu gÅ‚Ã³wnym projektu:

JeÅ›li plik `.env` nie istnieje, skopiuj `.env.example` do `.env` lub utwÃ³rz nowy plik `.env` w katalogu gÅ‚Ã³wnym projektu.

**PrzykÅ‚adowy plik `.env`:**  
```bash
# W /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```
  
NastÄ™pnie moÅ¼esz kliknÄ…Ä‡ prawym przyciskiem myszy dowolny plik demo (np. `BasicChatDemo.java`) w Eksploratorze i wybraÄ‡ **â€Run Javaâ€** lub uÅ¼yÄ‡ konfiguracji uruchamiania z panelu Run and Debug.

**Opcja 2: UÅ¼ywajÄ…c terminala**

Ustaw token jako zmiennÄ… Å›rodowiskowÄ…:

**Bash:**  
```bash
export GITHUB_TOKEN=your_token_here
```
  
**PowerShell:**  
```powershell
$env:GITHUB_TOKEN=your_token_here
```
  
## Uruchom przykÅ‚ady

**UÅ¼ywajÄ…c VS Code:** Wystarczy kliknÄ…Ä‡ prawym przyciskiem myszy dowolny plik demo w Eksploratorze i wybraÄ‡ **â€Run Javaâ€** lub uÅ¼yÄ‡ konfiguracji uruchamiania z panelu Run and Debug (upewnij siÄ™, Å¼e najpierw dodaÅ‚eÅ› token do pliku `.env`).

**UÅ¼ywajÄ…c Maven:** Alternatywnie moÅ¼esz uruchomiÄ‡ z linii poleceÅ„:

### 1. Podstawowy czat

**Bash:**  
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```
  
**PowerShell:**  
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```
  
### 2. Wzorce promptÃ³w

**Bash:**  
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```
  
**PowerShell:**  
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```
  
Pokazuje prompt zero-shot, few-shot, chain-of-thought oraz role-based.

### 3. WywoÅ‚ywanie funkcji

**Bash:**  
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```
  
**PowerShell:**  
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```
  
AI automatycznie wywoÅ‚uje twoje metody w Javie, gdy jest to potrzebne.

### 4. Pytania i odpowiedzi na podstawie dokumentÃ³w (RAG)

**Bash:**  
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```
  
**PowerShell:**  
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```
  
Zadaj pytania dotyczÄ…ce zawartoÅ›ci pliku `document.txt`.

### 5. Odpowiedzialna sztuczna inteligencja

**Bash:**  
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```
  
**PowerShell:**  
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```
  
Zobacz, jak filtry bezpieczeÅ„stwa AI blokujÄ… szkodliwe treÅ›ci.

## Co pokazuje kaÅ¼dy przykÅ‚ad

**Podstawowy czat** â€“ [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Zacznij tutaj, aby zobaczyÄ‡ LangChain4j w najprostszej formie. Utworzysz `OpenAiOfficialChatModel`, wyÅ›lesz prompt przez `.chat()` i otrzymasz odpowiedÅº. To pokazuje fundamenty: jak inicjalizowaÄ‡ modele z niestandardowymi punktami koÅ„cowymi i kluczami API. Gdy zrozumiesz ten wzÃ³r, wszystko inne na nim bazuje.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```
  
> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) i zapytaj:  
> - â€Jak przeÅ‚Ä…czyÄ‡ siÄ™ z GitHub Models na Azure OpenAI w tym kodzie?â€  
> - â€Jakie inne parametry mogÄ™ skonfigurowaÄ‡ w OpenAiOfficialChatModel.builder()?â€  
> - â€Jak dodaÄ‡ strumieniowe odpowiedzi zamiast czekaÄ‡ na peÅ‚nÄ… odpowiedÅº?â€

**InÅ¼ynieria promptÃ³w** â€“ [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Teraz, gdy wiesz jak rozmawiaÄ‡ z modelem, zobaczmy co do niego mÃ³wisz. Demo pokazuje cztery rÃ³Å¼ne wzorce promptÃ³w, uÅ¼ywajÄ…c tego samego modelu. WyprÃ³buj prompt zero-shot z bezpoÅ›rednimi instrukcjami, few-shot uczÄ…ce na przykÅ‚adach, chain-of-thought pokazujÄ…ce kroki rozumowania oraz role-based ustawiajÄ…ce kontekst. Zobaczysz, jak ten sam model daje zupeÅ‚nie inne wyniki w zaleÅ¼noÅ›ci od konstrukcji promptu.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```
  
> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) i zapytaj:  
> - â€Jaka jest rÃ³Å¼nica miÄ™dzy promptem zero-shot, a few-shot i kiedy ich uÅ¼ywaÄ‡?â€  
> - â€Jak parametr temperature wpÅ‚ywa na odpowiedzi modelu?â€  
> - â€Jakie sÄ… techniki zapobiegania atakom typu prompt injection w produkcji?â€  
> - â€Jak stworzyÄ‡ wielokrotnego uÅ¼ytku obiekty PromptTemplate dla popularnych wzorcÃ³w?â€

**Integracja narzÄ™dzi** â€“ [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Tu LangChain4j staje siÄ™ potÄ™Å¼ny. UÅ¼yjesz `AiServices`, aby stworzyÄ‡ asystenta AI, ktÃ³ry moÅ¼e wywoÅ‚ywaÄ‡ twoje metody Java. Wystarczy oznaczyÄ‡ metody adnotacjÄ… `@Tool("opis")` a LangChain4j zajmie siÄ™ resztÄ… â€“ AI sam decyduje, ktÃ³rego narzÄ™dzia uÅ¼yÄ‡ na podstawie zapytaÅ„ uÅ¼ytkownika. To pokazuje wywoÅ‚ywanie funkcji, kluczowÄ… technikÄ™ do budowania AI, ktÃ³re potrafi dziaÅ‚aÄ‡, a nie tylko odpowiadaÄ‡ na pytania.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```
  
> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) i zapytaj:  
> - â€Jak dziaÅ‚a adnotacja @Tool i co LangChain4j robi z niÄ… w tle?â€  
> - â€Czy AI moÅ¼e wywoÅ‚aÄ‡ kilka narzÄ™dzi kolejno, by rozwiÄ…zaÄ‡ zÅ‚oÅ¼one problemy?â€  
> - â€Co siÄ™ stanie, jeÅ›li narzÄ™dzie rzuci wyjÄ…tek â€“ jak obsÅ‚ugiwaÄ‡ bÅ‚Ä™dy?â€  
> - â€Jak zintegrowaÄ‡ prawdziwe API zamiast tego przykÅ‚adu kalkulatora?â€

**Pytania i odpowiedzi na podstawie dokumentÃ³w (RAG)** â€“ [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Tu zobaczysz fundament podejÅ›cia RAG (retrieval-augmented generation). Zamiast opieraÄ‡ siÄ™ na danych treningowych modelu, Å‚adujesz zawartoÅ›Ä‡ z [`document.txt`](../../../00-quick-start/document.txt) i wÅ‚Ä…czasz jÄ… do promptu. AI odpowiada na podstawie twojego dokumentu, a nie ogÃ³lnej wiedzy. To pierwszy krok do budowy systemÃ³w pracujÄ…cych na wÅ‚asnych danych.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```
  
> **Uwaga:** To proste podejÅ›cie Å‚aduje caÅ‚y dokument do promptu. Dla duÅ¼ych plikÃ³w (>10KB) przekroczysz limity kontekstu. ModuÅ‚ 03 omawia dzielenie plikÃ³w i wyszukiwanie wektorowe dla produkcyjnych systemÃ³w RAG.

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) i zapytaj:  
> - â€Jak RAG zapobiega halucynacjom AI w porÃ³wnaniu do danych treningowych modelu?â€  
> - â€Jaka jest rÃ³Å¼nica miÄ™dzy tym prostym podejÅ›ciem a uÅ¼ywaniem osadzeÅ„ wektorowych do wyszukiwania?â€  
> - â€Jak skalowaÄ‡ to rozwiÄ…zanie do wielu dokumentÃ³w lub wiÄ™kszych baz wiedzy?â€  
> - â€Jak najlepiej strukturyzowaÄ‡ prompt, by AI korzystaÅ‚a wyÅ‚Ä…cznie z dostarczonego kontekstu?â€

**Odpowiedzialna sztuczna inteligencja** â€“ [ResponsibleAIDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java)

Buduj bezpieczeÅ„stwo AI z wielowarstwowymi zabezpieczeniami. Demo pokazuje dwa poziomy ochrony wspÃ³Å‚dziaÅ‚ajÄ…ce razem:

**CzÄ™Å›Ä‡ 1: LangChain4j Input Guardrails** â€“ blokowanie niebezpiecznych promptÃ³w zanim trafiÄ… do LLM. TwÃ³rz wÅ‚asne straÅ¼nice sprawdzajÄ…ce zabronione sÅ‚owa lub wzorce. DziaÅ‚ajÄ… w twoim kodzie, wiÄ™c sÄ… szybkie i darmowe.

```java
class DangerousContentGuardrail implements InputGuardrail {
    @Override
    public InputGuardrailResult validate(UserMessage userMessage) {
        String text = userMessage.singleText().toLowerCase();
        if (text.contains("explosives")) {
            return fatal("Blocked: contains prohibited keyword");
        }
        return success();
    }
}
```
  
**CzÄ™Å›Ä‡ 2: Filtry bezpieczeÅ„stwa dostawcy** â€“ GitHub Models ma wbudowane filtry wychwytujÄ…ce to, co mogÄ… pominÄ…Ä‡ straÅ¼nice. Zobaczysz twarde blokady (bÅ‚Ä™dy HTTP 400) przy powaÅ¼nych naruszeniach oraz miÄ™kkie odmowy, gdzie AI grzecznie odmawia.

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`ResponsibleAIDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java) i zapytaj:  
> - â€Czym jest InputGuardrail i jak stworzyÄ‡ wÅ‚asnÄ…?â€  
> - â€Czym rÃ³Å¼ni siÄ™ twarda blokada od miÄ™kkiej odmowy?â€  
> - â€Dlaczego warto uÅ¼ywaÄ‡ obu: straÅ¼nic i filtrÃ³w dostawcy jednoczeÅ›nie?â€

## Kolejne kroki

**NastÄ™pny moduÅ‚:** [01-introduction - Pierwsze kroki z LangChain4j i gpt-5 na Azure](../01-introduction/README.md)

---

**Nawigacja:** [â† PowrÃ³t do gÅ‚Ã³wnej](../README.md) | [Dalej: ModuÅ‚ 01 - Wprowadzenie â†’](../01-introduction/README.md)

---

## RozwiÄ…zywanie problemÃ³w

### Pierwsze budowanie Maven

**Problem:** Pierwsze `mvn clean compile` lub `mvn package` trwa dÅ‚ugo (10-15 minut)

**Przyczyna:** Maven musi pobraÄ‡ wszystkie zaleÅ¼noÅ›ci projektu (Spring Boot, biblioteki LangChain4j, SDK Azure itp.) przy pierwszym budowaniu.

**RozwiÄ…zanie:** To normalne zachowanie. Kolejne budowania bÄ™dÄ… znacznie szybsze, gdy zaleÅ¼noÅ›ci zostanÄ… zapisane lokalnie. Czas pobierania zaleÅ¼y od szybkoÅ›ci twojego Å‚Ä…cza.

### SkÅ‚adnia poleceÅ„ Maven w PowerShell

**Problem:** Polecenia Maven koÅ„czÄ… siÄ™ bÅ‚Ä™dem `Unknown lifecycle phase ".mainClass=..."`

**Przyczyna:** PowerShell interpretuje `=` jako operator przypisania zmiennej, co psuje skÅ‚adniÄ™ wÅ‚aÅ›ciwoÅ›ci Maven.
**RozwiÄ…zanie**: UÅ¼yj operatora stop-parsing `--%` przed poleceniem Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

Operator `--%` mÃ³wi PowerShell, aby przekazaÅ‚ wszystkie pozostaÅ‚e argumenty dosÅ‚ownie do Maven bez interpretacji.

### WyÅ›wietlanie emoji w Windows PowerShell

**Problem**: Odpowiedzi AI pokazujÄ… znaki Å›mieciowe (np. `????` lub `Ã¢??`) zamiast emoji w PowerShell

**Przyczyna**: DomyÅ›lne kodowanie PowerShell nie obsÅ‚uguje emoji UTF-8

**RozwiÄ…zanie**: Uruchom to polecenie przed uruchomieniem aplikacji Java:
```cmd
chcp 65001
```

To wymusza kodowanie UTF-8 w terminalu. Alternatywnie uÅ¼yj Windows Terminal, ktÃ³ry ma lepsze wsparcie Unicode.

### Debugowanie wywoÅ‚aÅ„ API

**Problem**: BÅ‚Ä™dy uwierzytelniania, limity zapytaÅ„ lub nieoczekiwane odpowiedzi z modelu AI

**RozwiÄ…zanie**: PrzykÅ‚ady zawierajÄ… `.logRequests(true)` i `.logResponses(true)`, aby pokazaÄ‡ wywoÅ‚ania API w konsoli. Pomaga to rozwiÄ…zywaÄ‡ bÅ‚Ä™dy uwierzytelniania, limity zapytaÅ„ lub nieoczekiwane odpowiedzi. UsuÅ„ te flagi w Å›rodowisku produkcyjnym, aby zmniejszyÄ‡ haÅ‚as w logach.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**WyÅ‚Ä…czenie odpowiedzialnoÅ›ci**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… automatycznej usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do dokÅ‚adnoÅ›ci, prosimy mieÄ‡ na uwadze, Å¼e tÅ‚umaczenia automatyczne mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego oryginalnym jÄ™zyku naleÅ¼y uznaÄ‡ za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->