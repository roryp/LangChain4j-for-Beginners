<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "377b3e3e6f8d02965bf0fbbc9ccb45c5",
  "translation_date": "2025-12-13T14:53:47+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "pl"
}
-->
# Module 00: Szybki start

## Spis treÅ›ci

- [Wprowadzenie](../../../00-quick-start)
- [Czym jest LangChain4j?](../../../00-quick-start)
- [ZaleÅ¼noÅ›ci LangChain4j](../../../00-quick-start)
- [Wymagania wstÄ™pne](../../../00-quick-start)
- [Konfiguracja](../../../00-quick-start)
  - [1. Uzyskaj swÃ³j token GitHub](../../../00-quick-start)
  - [2. Ustaw swÃ³j token](../../../00-quick-start)
- [Uruchom przykÅ‚ady](../../../00-quick-start)
  - [1. Podstawowy czat](../../../00-quick-start)
  - [2. Wzorce promptÃ³w](../../../00-quick-start)
  - [3. WywoÅ‚ywanie funkcji](../../../00-quick-start)
  - [4. Pytania i odpowiedzi na dokumentach (RAG)](../../../00-quick-start)
- [Co pokazuje kaÅ¼dy przykÅ‚ad](../../../00-quick-start)
- [Kolejne kroki](../../../00-quick-start)
- [RozwiÄ…zywanie problemÃ³w](../../../00-quick-start)

## Wprowadzenie

Ten szybki start ma na celu jak najszybsze uruchomienie LangChain4j. Obejmuje absolutne podstawy budowania aplikacji AI z LangChain4j i modelami GitHub. W kolejnych moduÅ‚ach uÅ¼yjesz Azure OpenAI z LangChain4j, aby tworzyÄ‡ bardziej zaawansowane aplikacje.

## Czym jest LangChain4j?

LangChain4j to biblioteka Java, ktÃ³ra upraszcza tworzenie aplikacji zasilanych AI. Zamiast zajmowaÄ‡ siÄ™ klientami HTTP i analizÄ… JSON, pracujesz z czystymi interfejsami Java.

â€Chainâ€ w LangChain odnosi siÄ™ do Å‚Ä…czenia wielu komponentÃ³w â€“ moÅ¼esz poÅ‚Ä…czyÄ‡ prompt z modelem, a nastÄ™pnie z parserem, lub Å‚Ä…czyÄ‡ wiele wywoÅ‚aÅ„ AI, gdzie jedno wyjÅ›cie zasila kolejne wejÅ›cie. Ten szybki start skupia siÄ™ na podstawach, zanim przejdziemy do bardziej zÅ‚oÅ¼onych Å‚aÅ„cuchÃ³w.

<img src="../../../translated_images/langchain-concept.ad1fe6cf063515e1e961a13c73d45cfa305fd03d81bd11e5d34d0e36ed28a44d.pl.png" alt="LangChain4j Chaining Concept" width="800"/>

*ÅÄ…czenie komponentÃ³w w LangChain4j â€“ elementy budulcowe Å‚Ä…czÄ… siÄ™, tworzÄ…c potÄ™Å¼ne przepÅ‚ywy pracy AI*

UÅ¼yjemy trzech podstawowych komponentÃ³w:

**ChatLanguageModel** â€“ interfejs do interakcji z modelem AI. WywoÅ‚aj `model.chat("prompt")` i otrzymaj odpowiedÅº w postaci tekstu. UÅ¼ywamy `OpenAiOfficialChatModel`, ktÃ³ry dziaÅ‚a z punktami koÅ„cowymi kompatybilnymi z OpenAI, takimi jak modele GitHub.

**AiServices** â€“ tworzy typowo bezpieczne interfejsy usÅ‚ug AI. Definiujesz metody, oznaczasz je adnotacjÄ… `@Tool`, a LangChain4j zajmuje siÄ™ orkiestracjÄ…. AI automatycznie wywoÅ‚uje twoje metody Java, gdy jest to potrzebne.

**MessageWindowChatMemory** â€“ utrzymuje historiÄ™ rozmowy. Bez tego kaÅ¼de zapytanie jest niezaleÅ¼ne. Z tym komponentem AI pamiÄ™ta poprzednie wiadomoÅ›ci i utrzymuje kontekst przez wiele tur.

<img src="../../../translated_images/architecture.eedc993a1c57683951f20244f652fc7a9853f571eea835bc2b2828cf0dbf62d0.pl.png" alt="LangChain4j Architecture" width="800"/>

*Architektura LangChain4j â€“ podstawowe komponenty wspÃ³Å‚pracujÄ…ce, aby zasilaÄ‡ twoje aplikacje AI*

## ZaleÅ¼noÅ›ci LangChain4j

Ten szybki start uÅ¼ywa dwÃ³ch zaleÅ¼noÅ›ci Maven w [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

ModuÅ‚ `langchain4j-open-ai-official` dostarcza klasÄ™ `OpenAiOfficialChatModel`, ktÃ³ra Å‚Ä…czy siÄ™ z API kompatybilnym z OpenAI. Modele GitHub uÅ¼ywajÄ… tego samego formatu API, wiÄ™c nie jest potrzebny specjalny adapter â€“ wystarczy wskazaÄ‡ bazowy URL na `https://models.github.ai/inference`.

## Wymagania wstÄ™pne

**UÅ¼ywasz kontenera deweloperskiego?** Java i Maven sÄ… juÅ¼ zainstalowane. Potrzebujesz tylko tokenu dostÄ™pu osobistego GitHub.

**Lokalny rozwÃ³j:**
- Java 21+, Maven 3.9+
- Token dostÄ™pu osobistego GitHub (instrukcje poniÅ¼ej)

> **Uwaga:** Ten moduÅ‚ uÅ¼ywa `gpt-4.1-nano` z modeli GitHub. Nie zmieniaj nazwy modelu w kodzie â€“ jest skonfigurowany do pracy z dostÄ™pnymi modelami GitHub.

## Konfiguracja

### 1. Uzyskaj swÃ³j token GitHub

1. PrzejdÅº do [Ustawienia GitHub â†’ Tokeny dostÄ™pu osobistego](https://github.com/settings/personal-access-tokens)
2. Kliknij â€Generate new tokenâ€
3. Ustaw opisowÄ… nazwÄ™ (np. â€LangChain4j Demoâ€)
4. Ustaw datÄ™ wygaÅ›niÄ™cia (zalecane 7 dni)
5. W sekcji â€Uprawnienia kontaâ€ znajdÅº â€Modelsâ€ i ustaw na â€Tylko do odczytuâ€
6. Kliknij â€Generate tokenâ€
7. Skopiuj i zapisz token â€“ nie zobaczysz go ponownie

### 2. Ustaw swÃ³j token

**Opcja 1: UÅ¼ycie VS Code (zalecane)**

JeÅ›li uÅ¼ywasz VS Code, dodaj swÃ³j token do pliku `.env` w katalogu gÅ‚Ã³wnym projektu:

JeÅ›li plik `.env` nie istnieje, skopiuj `.env.example` do `.env` lub utwÃ³rz nowy plik `.env` w katalogu gÅ‚Ã³wnym projektu.

**PrzykÅ‚adowy plik `.env`:**
```bash
# W /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

NastÄ™pnie moÅ¼esz po prostu kliknÄ…Ä‡ prawym przyciskiem myszy dowolny plik demo (np. `BasicChatDemo.java`) w Eksploratorze i wybraÄ‡ **â€Run Javaâ€** lub uÅ¼yÄ‡ konfiguracji uruchamiania z panelu Run and Debug.

**Opcja 2: UÅ¼ycie terminala**

Ustaw token jako zmiennÄ… Å›rodowiskowÄ…:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## Uruchom przykÅ‚ady

**UÅ¼ywajÄ…c VS Code:** Po prostu kliknij prawym przyciskiem myszy dowolny plik demo w Eksploratorze i wybierz **â€Run Javaâ€**, lub uÅ¼yj konfiguracji uruchamiania z panelu Run and Debug (upewnij siÄ™, Å¼e najpierw dodaÅ‚eÅ› token do pliku `.env`).

**UÅ¼ywajÄ…c Maven:** Alternatywnie moÅ¼esz uruchomiÄ‡ z linii poleceÅ„:

### 1. Podstawowy czat

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Wzorce promptÃ³w

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Pokazuje zero-shot, few-shot, chain-of-thought i role-based prompting.

### 3. WywoÅ‚ywanie funkcji

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

AI automatycznie wywoÅ‚uje twoje metody Java, gdy jest to potrzebne.

### 4. Pytania i odpowiedzi na dokumentach (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Zadaj pytania dotyczÄ…ce zawartoÅ›ci `document.txt`.

## Co pokazuje kaÅ¼dy przykÅ‚ad

**Podstawowy czat** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Zacznij tutaj, aby zobaczyÄ‡ LangChain4j w najprostszej formie. Stworzysz `OpenAiOfficialChatModel`, wyÅ›lesz prompt za pomocÄ… `.chat()` i otrzymasz odpowiedÅº. To pokazuje fundamenty: jak inicjalizowaÄ‡ modele z niestandardowymi punktami koÅ„cowymi i kluczami API. Gdy zrozumiesz ten wzorzec, wszystko inne na nim bazuje.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) i zapytaj:
> - â€Jak przeÅ‚Ä…czyÄ‡ siÄ™ z modeli GitHub na Azure OpenAI w tym kodzie?â€
> - â€Jakie inne parametry mogÄ™ konfigurowaÄ‡ w OpenAiOfficialChatModel.builder()?â€
> - â€Jak dodaÄ‡ strumieniowe odpowiedzi zamiast czekaÄ‡ na peÅ‚nÄ… odpowiedÅº?â€

**InÅ¼ynieria promptÃ³w** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Teraz, gdy wiesz, jak rozmawiaÄ‡ z modelem, zobaczmy, co do niego mÃ³wisz. To demo uÅ¼ywa tego samego ustawienia modelu, ale pokazuje cztery rÃ³Å¼ne wzorce promptÃ³w. WyprÃ³buj zero-shot dla bezpoÅ›rednich instrukcji, few-shot uczÄ…ce siÄ™ na przykÅ‚adach, chain-of-thought ujawniajÄ…ce kroki rozumowania oraz role-based, ktÃ³re ustawiajÄ… kontekst. Zobaczysz, jak ten sam model daje dramatycznie rÃ³Å¼ne wyniki w zaleÅ¼noÅ›ci od sposobu formuÅ‚owania zapytania.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) i zapytaj:
> - â€Jaka jest rÃ³Å¼nica miÄ™dzy zero-shot a few-shot prompting i kiedy uÅ¼ywaÄ‡ kaÅ¼dego z nich?â€
> - â€Jak parametr temperature wpÅ‚ywa na odpowiedzi modelu?â€
> - â€Jakie sÄ… techniki zapobiegania atakom typu prompt injection w produkcji?â€
> - â€Jak tworzyÄ‡ wielokrotnego uÅ¼ytku obiekty PromptTemplate dla popularnych wzorcÃ³w?â€

**Integracja narzÄ™dzi** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Tu LangChain4j staje siÄ™ potÄ™Å¼ny. UÅ¼yjesz `AiServices`, aby stworzyÄ‡ asystenta AI, ktÃ³ry moÅ¼e wywoÅ‚ywaÄ‡ twoje metody Java. Wystarczy oznaczyÄ‡ metody adnotacjÄ… `@Tool("opis")`, a LangChain4j zajmie siÄ™ resztÄ… â€“ AI automatycznie decyduje, kiedy uÅ¼yÄ‡ ktÃ³rego narzÄ™dzia na podstawie pytaÅ„ uÅ¼ytkownika. To pokazuje wywoÅ‚ywanie funkcji, kluczowÄ… technikÄ™ budowania AI, ktÃ³re moÅ¼e podejmowaÄ‡ dziaÅ‚ania, a nie tylko odpowiadaÄ‡ na pytania.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) i zapytaj:
> - â€Jak dziaÅ‚a adnotacja @Tool i co LangChain4j robi z niÄ… w tle?â€
> - â€Czy AI moÅ¼e wywoÅ‚aÄ‡ wiele narzÄ™dzi po kolei, aby rozwiÄ…zaÄ‡ zÅ‚oÅ¼one problemy?â€
> - â€Co siÄ™ stanie, jeÅ›li narzÄ™dzie zgÅ‚osi wyjÄ…tek â€“ jak obsÅ‚ugiwaÄ‡ bÅ‚Ä™dy?â€
> - â€Jak zintegrowaÄ‡ prawdziwe API zamiast tego przykÅ‚adu kalkulatora?â€

**Pytania i odpowiedzi na dokumentach (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Tu zobaczysz podstawy RAG (retrieval-augmented generation). Zamiast polegaÄ‡ na danych treningowych modelu, Å‚adujesz zawartoÅ›Ä‡ z [`document.txt`](../../../00-quick-start/document.txt) i doÅ‚Ä…czasz jÄ… do promptu. AI odpowiada na podstawie twojego dokumentu, a nie ogÃ³lnej wiedzy. To pierwszy krok do budowania systemÃ³w, ktÃ³re mogÄ… pracowaÄ‡ z twoimi wÅ‚asnymi danymi.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Uwaga:** To proste podejÅ›cie Å‚aduje caÅ‚y dokument do promptu. Dla duÅ¼ych plikÃ³w (>10KB) przekroczysz limity kontekstu. ModuÅ‚ 03 omawia dzielenie na fragmenty i wyszukiwanie wektorowe dla produkcyjnych systemÃ³w RAG.

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) i zapytaj:
> - â€Jak RAG zapobiega halucynacjom AI w porÃ³wnaniu z uÅ¼ywaniem danych treningowych modelu?â€
> - â€Jaka jest rÃ³Å¼nica miÄ™dzy tym prostym podejÅ›ciem a uÅ¼ywaniem osadzeÅ„ wektorowych do wyszukiwania?â€
> - â€Jak skalowaÄ‡ to, aby obsÅ‚ugiwaÄ‡ wiele dokumentÃ³w lub wiÄ™ksze bazy wiedzy?â€
> - â€Jakie sÄ… najlepsze praktyki strukturyzowania promptu, aby AI uÅ¼ywaÅ‚o tylko dostarczonego kontekstu?â€

## Debugowanie

PrzykÅ‚ady zawierajÄ… `.logRequests(true)` i `.logResponses(true)`, aby pokazaÄ‡ wywoÅ‚ania API w konsoli. Pomaga to rozwiÄ…zywaÄ‡ problemy z uwierzytelnianiem, limitami lub nieoczekiwanymi odpowiedziami. UsuÅ„ te flagi w produkcji, aby zmniejszyÄ‡ haÅ‚as w logach.

## Kolejne kroki

**NastÄ™pny moduÅ‚:** [01-introduction - RozpoczÄ™cie pracy z LangChain4j i gpt-5 na Azure](../01-introduction/README.md)

---

**Nawigacja:** [â† WrÃ³Ä‡ do gÅ‚Ã³wnego](../README.md) | [Dalej: ModuÅ‚ 01 - Wprowadzenie â†’](../01-introduction/README.md)

---

## RozwiÄ…zywanie problemÃ³w

### Pierwsze budowanie Maven

**Problem:** PoczÄ…tkowe `mvn clean compile` lub `mvn package` trwa dÅ‚ugo (10-15 minut)

**Przyczyna:** Maven musi pobraÄ‡ wszystkie zaleÅ¼noÅ›ci projektu (Spring Boot, biblioteki LangChain4j, SDK Azure itp.) przy pierwszym budowaniu.

**RozwiÄ…zanie:** To normalne zachowanie. Kolejne budowania bÄ™dÄ… znacznie szybsze, poniewaÅ¼ zaleÅ¼noÅ›ci sÄ… buforowane lokalnie. Czas pobierania zaleÅ¼y od prÄ™dkoÅ›ci twojej sieci.

### SkÅ‚adnia poleceÅ„ Maven w PowerShell

**Problem:** Polecenia Maven koÅ„czÄ… siÄ™ bÅ‚Ä™dem `Unknown lifecycle phase ".mainClass=..."`

**Przyczyna:** PowerShell interpretuje `=` jako operator przypisania zmiennej, co psuje skÅ‚adniÄ™ wÅ‚aÅ›ciwoÅ›ci Maven.

**RozwiÄ…zanie:** UÅ¼yj operatora zatrzymania parsowania `--%` przed poleceniem Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

Operator `--%` mÃ³wi PowerShell, aby przekazaÅ‚ wszystkie pozostaÅ‚e argumenty dosÅ‚ownie do Mavena bez interpretacji.

### WyÅ›wietlanie emoji w Windows PowerShell

**Problem:** Odpowiedzi AI pokazujÄ… nieczytelne znaki (np. `????` lub `Ã¢??`) zamiast emoji w PowerShell

**Przyczyna:** DomyÅ›lne kodowanie PowerShell nie obsÅ‚uguje emoji UTF-8

**RozwiÄ…zanie:** Uruchom to polecenie przed uruchomieniem aplikacji Java:
```cmd
chcp 65001
```

To wymusza kodowanie UTF-8 w terminalu. Alternatywnie uÅ¼yj Windows Terminal, ktÃ³ry ma lepsze wsparcie Unicode.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ZastrzeÅ¼enie**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dokÅ‚adamy staraÅ„, aby tÅ‚umaczenie byÅ‚o jak najbardziej precyzyjne, prosimy mieÄ‡ na uwadze, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->