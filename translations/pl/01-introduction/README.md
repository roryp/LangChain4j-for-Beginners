<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c3e07ca58d0b8a3f47d3bf5728541e0a",
  "translation_date": "2025-12-13T13:33:41+00:00",
  "source_file": "01-introduction/README.md",
  "language_code": "pl"
}
-->
# ModuÅ‚ 01: RozpoczÄ™cie pracy z LangChain4j

## Spis treÅ›ci

- [Czego siÄ™ nauczysz](../../../01-introduction)
- [Wymagania wstÄ™pne](../../../01-introduction)
- [Zrozumienie podstawowego problemu](../../../01-introduction)
- [Zrozumienie tokenÃ³w](../../../01-introduction)
- [Jak dziaÅ‚a pamiÄ™Ä‡](../../../01-introduction)
- [Jak to wykorzystuje LangChain4j](../../../01-introduction)
- [WdroÅ¼enie infrastruktury Azure OpenAI](../../../01-introduction)
- [Uruchomienie aplikacji lokalnie](../../../01-introduction)
- [Korzystanie z aplikacji](../../../01-introduction)
  - [Czat bezstanowy (lewy panel)](../../../01-introduction)
  - [Czat stanowy (prawy panel)](../../../01-introduction)
- [Kolejne kroki](../../../01-introduction)

## Czego siÄ™ nauczysz

JeÅ›li ukoÅ„czyÅ‚eÅ› szybki start, widziaÅ‚eÅ›, jak wysyÅ‚aÄ‡ zapytania i otrzymywaÄ‡ odpowiedzi. To podstawa, ale prawdziwe aplikacje potrzebujÄ… wiÄ™cej. Ten moduÅ‚ nauczy CiÄ™, jak budowaÄ‡ konwersacyjne AI, ktÃ³re pamiÄ™ta kontekst i utrzymuje stan â€“ rÃ³Å¼nicÄ™ miÄ™dzy jednorazowÄ… demonstracjÄ… a aplikacjÄ… gotowÄ… do produkcji.

W caÅ‚ym przewodniku bÄ™dziemy korzystaÄ‡ z GPT-5 Azure OpenAI, poniewaÅ¼ jego zaawansowane zdolnoÅ›ci rozumowania sprawiajÄ…, Å¼e zachowanie rÃ³Å¼nych wzorcÃ³w jest bardziej widoczne. Gdy dodasz pamiÄ™Ä‡, wyraÅºnie zobaczysz rÃ³Å¼nicÄ™. To uÅ‚atwia zrozumienie, co kaÅ¼dy komponent wnosi do Twojej aplikacji.

Zbudujesz jednÄ… aplikacjÄ™, ktÃ³ra demonstruje oba wzorce:

**Czat bezstanowy** â€“ KaÅ¼de zapytanie jest niezaleÅ¼ne. Model nie pamiÄ™ta poprzednich wiadomoÅ›ci. To wzorzec, ktÃ³rego uÅ¼ywaÅ‚eÅ› w szybkim starcie.

**Konwersacja stanowa** â€“ KaÅ¼de zapytanie zawiera historiÄ™ rozmowy. Model utrzymuje kontekst przez wiele tur. To jest to, czego wymagajÄ… aplikacje produkcyjne.

## Wymagania wstÄ™pne

- Subskrypcja Azure z dostÄ™pem do Azure OpenAI
- Java 21, Maven 3.9+
- Azure CLI (https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)
- Azure Developer CLI (azd) (https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/install-azd)

> **Uwaga:** Java, Maven, Azure CLI i Azure Developer CLI (azd) sÄ… preinstalowane w dostarczonym devcontainerze.

> **Uwaga:** Ten moduÅ‚ korzysta z GPT-5 na Azure OpenAI. WdroÅ¼enie jest konfigurowane automatycznie przez `azd up` â€“ nie modyfikuj nazwy modelu w kodzie.

## Zrozumienie podstawowego problemu

Modele jÄ™zykowe sÄ… bezstanowe. KaÅ¼de wywoÅ‚anie API jest niezaleÅ¼ne. JeÅ›li wyÅ›lesz "Mam na imiÄ™ John", a potem zapytasz "Jak mam na imiÄ™?", model nie ma pojÄ™cia, Å¼e wÅ‚aÅ›nie siÄ™ przedstawiÅ‚eÅ›. Traktuje kaÅ¼de zapytanie, jakby to byÅ‚a pierwsza rozmowa, jakÄ… kiedykolwiek prowadziÅ‚eÅ›.

To jest w porzÄ…dku dla prostych pytaÅ„ i odpowiedzi, ale bezuÅ¼yteczne dla prawdziwych aplikacji. Boty obsÅ‚ugi klienta muszÄ… pamiÄ™taÄ‡, co im powiedziaÅ‚eÅ›. Asystenci osobowi potrzebujÄ… kontekstu. KaÅ¼da rozmowa wieloturnowa wymaga pamiÄ™ci.

<img src="../../../translated_images/pl/stateless-vs-stateful.cc4a4765e649c41a.webp" alt="Rozmowy bezstanowe vs stanowe" width="800"/>

*RÃ³Å¼nica miÄ™dzy rozmowami bezstanowymi (niezaleÅ¼ne wywoÅ‚ania) a stanowymi (Å›wiadome kontekstu)*

## Zrozumienie tokenÃ³w

Zanim zagÅ‚Ä™bimy siÄ™ w rozmowy, waÅ¼ne jest zrozumienie tokenÃ³w â€“ podstawowych jednostek tekstu, ktÃ³re przetwarzajÄ… modele jÄ™zykowe:

<img src="../../../translated_images/pl/token-explanation.c39760d8ec650181.webp" alt="WyjaÅ›nienie tokenÃ³w" width="800"/>

*PrzykÅ‚ad, jak tekst jest dzielony na tokeny â€“ "I love AI!" staje siÄ™ 4 oddzielnymi jednostkami przetwarzania*

Tokeny to sposÃ³b, w jaki modele AI mierzÄ… i przetwarzajÄ… tekst. SÅ‚owa, interpunkcja, a nawet spacje mogÄ… byÄ‡ tokenami. TwÃ³j model ma limit, ile tokenÃ³w moÅ¼e przetworzyÄ‡ naraz (400 000 dla GPT-5, z maksymalnie 272 000 tokenÃ³w wejÅ›ciowych i 128 000 wyjÅ›ciowych). Zrozumienie tokenÃ³w pomaga zarzÄ…dzaÄ‡ dÅ‚ugoÅ›ciÄ… rozmowy i kosztami.

## Jak dziaÅ‚a pamiÄ™Ä‡

PamiÄ™Ä‡ czatu rozwiÄ…zuje problem bezstanowoÅ›ci, utrzymujÄ…c historiÄ™ rozmowy. Przed wysÅ‚aniem zapytania do modelu, framework doÅ‚Ä…cza odpowiednie poprzednie wiadomoÅ›ci. Kiedy pytasz "Jak mam na imiÄ™?", system faktycznie wysyÅ‚a caÅ‚Ä… historiÄ™ rozmowy, pozwalajÄ…c modelowi zobaczyÄ‡, Å¼e wczeÅ›niej powiedziaÅ‚eÅ› "Mam na imiÄ™ John."

LangChain4j dostarcza implementacje pamiÄ™ci, ktÃ³re obsÅ‚ugujÄ… to automatycznie. Wybierasz, ile wiadomoÅ›ci zachowaÄ‡, a framework zarzÄ…dza oknem kontekstowym.

<img src="../../../translated_images/pl/memory-window.bbe67f597eadabb3.webp" alt="Koncepcja okna pamiÄ™ci" width="800"/>

*MessageWindowChatMemory utrzymuje przesuwne okno ostatnich wiadomoÅ›ci, automatycznie usuwajÄ…c stare*

## Jak to wykorzystuje LangChain4j

Ten moduÅ‚ rozszerza szybki start, integrujÄ…c Spring Boot i dodajÄ…c pamiÄ™Ä‡ rozmowy. Oto jak elementy wspÃ³Å‚grajÄ…:

**ZaleÅ¼noÅ›ci** â€“ Dodaj dwie biblioteki LangChain4j:

```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Model czatu** â€“ Skonfiguruj Azure OpenAI jako bean Springa ([LangChainConfig.java](../../../01-introduction/src/main/java/com/example/langchain4j/config/LangChainConfig.java)):

```java
@Bean
public OpenAiOfficialChatModel openAiOfficialChatModel() {
    return OpenAiOfficialChatModel.builder()
            .baseUrl(azureEndpoint)
            .apiKey(azureApiKey)
            .modelName(deploymentName)
            .timeout(Duration.ofMinutes(5))
            .maxRetries(3)
            .build();
}
```

Builder odczytuje poÅ›wiadczenia z zmiennych Å›rodowiskowych ustawionych przez `azd up`. Ustawienie `baseUrl` na TwÃ³j punkt koÅ„cowy Azure sprawia, Å¼e klient OpenAI dziaÅ‚a z Azure OpenAI.

**PamiÄ™Ä‡ rozmowy** â€“ ÅšledÅº historiÄ™ czatu za pomocÄ… MessageWindowChatMemory ([ConversationService.java](../../../01-introduction/src/main/java/com/example/langchain4j/service/ConversationService.java)):

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("My name is John"));
memory.add(AiMessage.from("Nice to meet you, John!"));

memory.add(UserMessage.from("What's my name?"));
AiMessage aiMessage = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage);
```

UtwÃ³rz pamiÄ™Ä‡ z `withMaxMessages(10)`, aby zachowaÄ‡ ostatnie 10 wiadomoÅ›ci. Dodawaj wiadomoÅ›ci uÅ¼ytkownika i AI za pomocÄ… typowanych wrapperÃ³w: `UserMessage.from(text)` i `AiMessage.from(text)`. Pobierz historiÄ™ przez `memory.messages()` i wyÅ›lij jÄ… do modelu. Serwis przechowuje oddzielne instancje pamiÄ™ci dla kaÅ¼dego ID rozmowy, pozwalajÄ…c wielu uÅ¼ytkownikom rozmawiaÄ‡ jednoczeÅ›nie.

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** OtwÃ³rz [`ConversationService.java`](../../../01-introduction/src/main/java/com/example/langchain4j/service/ConversationService.java) i zapytaj:
> - "Jak MessageWindowChatMemory decyduje, ktÃ³re wiadomoÅ›ci usunÄ…Ä‡, gdy okno jest peÅ‚ne?"
> - "Czy mogÄ™ zaimplementowaÄ‡ wÅ‚asne przechowywanie pamiÄ™ci uÅ¼ywajÄ…c bazy danych zamiast pamiÄ™ci w RAM?"
> - "Jak dodaÄ‡ podsumowanie, aby skompresowaÄ‡ starÄ… historiÄ™ rozmowy?"

Endpoint czatu bezstanowego pomija pamiÄ™Ä‡ caÅ‚kowicie â€“ po prostu `chatModel.chat(prompt)` jak w szybkim starcie. Endpoint stanowy dodaje wiadomoÅ›ci do pamiÄ™ci, pobiera historiÄ™ i doÅ‚Ä…cza ten kontekst do kaÅ¼dego zapytania. Ta sama konfiguracja modelu, rÃ³Å¼ne wzorce.

## WdroÅ¼enie infrastruktury Azure OpenAI

**Bash:**
```bash
cd 01-introduction
azd up  # Wybierz subskrypcjÄ™ i lokalizacjÄ™ (zalecane eastus2)
```

**PowerShell:**
```powershell
cd 01-introduction
azd up  # Wybierz subskrypcjÄ™ i lokalizacjÄ™ (zalecane eastus2)
```

> **Uwaga:** JeÅ›li napotkasz bÅ‚Ä…d timeout (`RequestConflict: Cannot modify resource ... provisioning state is not terminal`), po prostu uruchom ponownie `azd up`. Zasoby Azure mogÄ… nadal siÄ™ wdraÅ¼aÄ‡ w tle, a ponowne uruchomienie pozwala na ukoÅ„czenie wdroÅ¼enia, gdy zasoby osiÄ…gnÄ… stan koÅ„cowy.

To spowoduje:
1. WdroÅ¼enie zasobu Azure OpenAI z modelami GPT-5 i text-embedding-3-small
2. Automatyczne wygenerowanie pliku `.env` w katalogu gÅ‚Ã³wnym projektu z poÅ›wiadczeniami
3. Ustawienie wszystkich wymaganych zmiennych Å›rodowiskowych

**Masz problemy z wdroÅ¼eniem?** Zobacz [Infrastructure README](infra/README.md) dla szczegÃ³Å‚owego rozwiÄ…zywania problemÃ³w, w tym konfliktÃ³w nazw subdomen, rÄ™cznych krokÃ³w wdroÅ¼enia w Azure Portal oraz wskazÃ³wek dotyczÄ…cych konfiguracji modelu.

**SprawdÅº, czy wdroÅ¼enie siÄ™ powiodÅ‚o:**

**Bash:**
```bash
cat ../.env  # Powinno pokazywaÄ‡ AZURE_OPENAI_ENDPOINT, API_KEY itp.
```

**PowerShell:**
```powershell
Get-Content ..\.env  # Powinno pokazywaÄ‡ AZURE_OPENAI_ENDPOINT, API_KEY itp.
```

> **Uwaga:** Komenda `azd up` automatycznie generuje plik `.env`. JeÅ›li bÄ™dziesz musiaÅ‚ go pÃ³Åºniej zaktualizowaÄ‡, moÅ¼esz edytowaÄ‡ plik `.env` rÄ™cznie lub wygenerowaÄ‡ go ponownie, uruchamiajÄ…c:
>
> **Bash:**
> ```bash
> cd ..
> bash .azd-env.sh
> ```
>
> **PowerShell:**
> ```powershell
> cd ..
> .\.azd-env.ps1
> ```

## Uruchomienie aplikacji lokalnie

**SprawdÅº wdroÅ¼enie:**

Upewnij siÄ™, Å¼e plik `.env` istnieje w katalogu gÅ‚Ã³wnym z poÅ›wiadczeniami Azure:

**Bash:**
```bash
cat ../.env  # Powinno pokazywaÄ‡ AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**PowerShell:**
```powershell
Get-Content ..\.env  # Powinno pokazywaÄ‡ AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Uruchom aplikacje:**

**Opcja 1: Korzystanie z Spring Boot Dashboard (zalecane dla uÅ¼ytkownikÃ³w VS Code)**

Dev container zawiera rozszerzenie Spring Boot Dashboard, ktÃ³re zapewnia wizualny interfejs do zarzÄ…dzania wszystkimi aplikacjami Spring Boot. Znajdziesz je na pasku aktywnoÅ›ci po lewej stronie VS Code (ikona Spring Boot).

Z poziomu Spring Boot Dashboard moÅ¼esz:
- ZobaczyÄ‡ wszystkie dostÄ™pne aplikacje Spring Boot w workspace
- UruchamiaÄ‡/zatrzymywaÄ‡ aplikacje jednym klikniÄ™ciem
- PrzeglÄ…daÄ‡ logi aplikacji w czasie rzeczywistym
- MonitorowaÄ‡ status aplikacji

Po prostu kliknij przycisk play obok "introduction", aby uruchomiÄ‡ ten moduÅ‚, lub uruchom wszystkie moduÅ‚y naraz.

<img src="../../../translated_images/pl/dashboard.69c7479aef09ff6b.webp" alt="Spring Boot Dashboard" width="400"/>

**Opcja 2: Korzystanie ze skryptÃ³w shell**

Uruchom wszystkie aplikacje webowe (moduÅ‚y 01-04):

**Bash:**
```bash
cd ..  # Z katalogu gÅ‚Ã³wnego
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Z katalogu gÅ‚Ã³wnego
.\start-all.ps1
```

Lub uruchom tylko ten moduÅ‚:

**Bash:**
```bash
cd 01-introduction
./start.sh
```

**PowerShell:**
```powershell
cd 01-introduction
.\start.ps1
```

Oba skrypty automatycznie Å‚adujÄ… zmienne Å›rodowiskowe z pliku `.env` w katalogu gÅ‚Ã³wnym i zbudujÄ… pliki JAR, jeÅ›li jeszcze nie istniejÄ….

> **Uwaga:** JeÅ›li wolisz zbudowaÄ‡ wszystkie moduÅ‚y rÄ™cznie przed uruchomieniem:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

OtwÃ³rz http://localhost:8080 w przeglÄ…darce.

**Aby zatrzymaÄ‡:**

**Bash:**
```bash
./stop.sh  # Tylko ten moduÅ‚
# Lub
cd .. && ./stop-all.sh  # Wszystkie moduÅ‚y
```

**PowerShell:**
```powershell
.\stop.ps1  # Tylko ten moduÅ‚
# Lub
cd ..; .\stop-all.ps1  # Wszystkie moduÅ‚y
```

## Korzystanie z aplikacji

Aplikacja udostÄ™pnia interfejs webowy z dwoma implementacjami czatu obok siebie.

<img src="../../../translated_images/pl/home-screen.121a03206ab910c0.webp" alt="Ekran gÅ‚Ã³wny aplikacji" width="800"/>

*Panel pokazujÄ…cy zarÃ³wno prosty czat (bezstanowy), jak i konwersacyjny czat (stanowy)*

### Czat bezstanowy (lewy panel)

WyprÃ³buj najpierw to. Zapytaj "Mam na imiÄ™ John", a potem od razu "Jak mam na imiÄ™?" Model nie zapamiÄ™ta, poniewaÅ¼ kaÅ¼da wiadomoÅ›Ä‡ jest niezaleÅ¼na. To demonstruje podstawowy problem integracji modelu jÄ™zykowego â€“ brak kontekstu rozmowy.

<img src="../../../translated_images/pl/simple-chat-stateless-demo.13aeb3978eab3234.webp" alt="Demo czatu bezstanowego" width="800"/>

*AI nie pamiÄ™ta Twojego imienia z poprzedniej wiadomoÅ›ci*

### Czat stanowy (prawy panel)

Teraz sprÃ³buj tej samej sekwencji tutaj. Zapytaj "Mam na imiÄ™ John", a potem "Jak mam na imiÄ™?" Tym razem pamiÄ™ta. RÃ³Å¼nicÄ… jest MessageWindowChatMemory â€“ utrzymuje historiÄ™ rozmowy i doÅ‚Ä…cza jÄ… do kaÅ¼dego zapytania. Tak dziaÅ‚a produkcyjne AI konwersacyjne.

<img src="../../../translated_images/pl/conversational-chat-stateful-demo.e5be9822eb23ff59.webp" alt="Demo czatu stanowego" width="800"/>

*AI pamiÄ™ta Twoje imiÄ™ z wczeÅ›niejszej czÄ™Å›ci rozmowy*

Oba panele korzystajÄ… z tego samego modelu GPT-5. JedynÄ… rÃ³Å¼nicÄ… jest pamiÄ™Ä‡. To jasno pokazuje, co pamiÄ™Ä‡ wnosi do Twojej aplikacji i dlaczego jest niezbÄ™dna w rzeczywistych zastosowaniach.

## Kolejne kroki

**NastÄ™pny moduÅ‚:** [02-prompt-engineering - InÅ¼ynieria promptÃ³w z GPT-5](../02-prompt-engineering/README.md)

---

**Nawigacja:** [â† Poprzedni: ModuÅ‚ 00 - Szybki start](../00-quick-start/README.md) | [PowrÃ³t do gÅ‚Ã³wnego](../README.md) | [NastÄ™pny: ModuÅ‚ 02 - InÅ¼ynieria promptÃ³w â†’](../02-prompt-engineering/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ZastrzeÅ¼enie**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dokÅ‚adamy staraÅ„, aby tÅ‚umaczenie byÅ‚o jak najbardziej precyzyjne, prosimy mieÄ‡ na uwadze, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->