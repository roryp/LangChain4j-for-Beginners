<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8d787826cad7e92bf5cdbd116b1e6116",
  "translation_date": "2025-12-13T16:06:22+00:00",
  "source_file": "02-prompt-engineering/README.md",
  "language_code": "pl"
}
-->
# ModuÅ‚ 02: InÅ¼ynieria promptÃ³w z GPT-5

## Spis treÅ›ci

- [Czego siÄ™ nauczysz](../../../02-prompt-engineering)
- [Wymagania wstÄ™pne](../../../02-prompt-engineering)
- [Zrozumienie inÅ¼ynierii promptÃ³w](../../../02-prompt-engineering)
- [Jak to wykorzystuje LangChain4j](../../../02-prompt-engineering)
- [GÅ‚Ã³wne wzorce](../../../02-prompt-engineering)
- [Korzystanie z istniejÄ…cych zasobÃ³w Azure](../../../02-prompt-engineering)
- [Zrzuty ekranu aplikacji](../../../02-prompt-engineering)
- [Eksploracja wzorcÃ³w](../../../02-prompt-engineering)
  - [Niskie vs wysokie zaangaÅ¼owanie](../../../02-prompt-engineering)
  - [Wykonywanie zadaÅ„ (wprowadzenia do narzÄ™dzi)](../../../02-prompt-engineering)
  - [Kod z autorefleksjÄ…](../../../02-prompt-engineering)
  - [Analiza strukturalna](../../../02-prompt-engineering)
  - [Wieloturnowa rozmowa](../../../02-prompt-engineering)
  - [Rozumowanie krok po kroku](../../../02-prompt-engineering)
  - [Ograniczona odpowiedÅº](../../../02-prompt-engineering)
- [Czego naprawdÄ™ siÄ™ uczysz](../../../02-prompt-engineering)
- [Kolejne kroki](../../../02-prompt-engineering)

## Czego siÄ™ nauczysz

W poprzednim module zobaczyÅ‚eÅ›, jak pamiÄ™Ä‡ umoÅ¼liwia konwersacyjnÄ… AI i uÅ¼ywaÅ‚eÅ› modeli GitHub do podstawowych interakcji. Teraz skupimy siÄ™ na tym, jak zadajesz pytania â€“ czyli na samych promptach â€“ korzystajÄ…c z GPT-5 w Azure OpenAI. SposÃ³b, w jaki strukturyzujesz swoje prompty, dramatycznie wpÅ‚ywa na jakoÅ›Ä‡ otrzymywanych odpowiedzi.

UÅ¼yjemy GPT-5, poniewaÅ¼ wprowadza on kontrolÄ™ rozumowania â€“ moÅ¼esz powiedzieÄ‡ modelowi, ile ma myÅ›leÄ‡ przed udzieleniem odpowiedzi. To sprawia, Å¼e rÃ³Å¼ne strategie promptowania stajÄ… siÄ™ bardziej widoczne i pomaga zrozumieÄ‡, kiedy stosowaÄ‡ ktÃ³re podejÅ›cie. Skorzystamy teÅ¼ z mniejszych limitÃ³w szybkoÅ›ci w Azure dla GPT-5 w porÃ³wnaniu do modeli GitHub.

## Wymagania wstÄ™pne

- UkoÅ„czony ModuÅ‚ 01 (wdroÅ¼one zasoby Azure OpenAI)
- Plik `.env` w katalogu gÅ‚Ã³wnym z poÅ›wiadczeniami Azure (utworzony przez `azd up` w Module 01)

> **Uwaga:** JeÅ›li nie ukoÅ„czyÅ‚eÅ› ModuÅ‚u 01, najpierw wykonaj tamte instrukcje wdroÅ¼enia.

## Zrozumienie inÅ¼ynierii promptÃ³w

InÅ¼ynieria promptÃ³w polega na projektowaniu tekstu wejÅ›ciowego, ktÃ³ry konsekwentnie daje oczekiwane wyniki. To nie tylko zadawanie pytaÅ„ â€“ to strukturyzowanie prÃ³Å›b tak, aby model dokÅ‚adnie rozumiaÅ‚, czego chcesz i jak to dostarczyÄ‡.

PomyÅ›l o tym jak o dawaniu instrukcji koledze z pracy. â€Napraw bÅ‚Ä…dâ€ jest niejasne. â€Napraw wyjÄ…tek null pointer w UserService.java linia 45, dodajÄ…c sprawdzenie nullâ€ jest konkretne. Modele jÄ™zykowe dziaÅ‚ajÄ… tak samo â€“ waÅ¼na jest precyzja i struktura.

## Jak to wykorzystuje LangChain4j

Ten moduÅ‚ demonstruje zaawansowane wzorce promptowania, korzystajÄ…c z tej samej podstawy LangChain4j co poprzednie moduÅ‚y, ze szczegÃ³lnym naciskiem na strukturÄ™ promptÃ³w i kontrolÄ™ rozumowania.

<img src="../../../translated_images/langchain4j-flow.48e534666213010b.pl.png" alt="LangChain4j Flow" width="800"/>

*Jak LangChain4j Å‚Ä…czy twoje prompty z Azure OpenAI GPT-5*

**ZaleÅ¼noÅ›ci** â€“ ModuÅ‚ 02 uÅ¼ywa nastÄ™pujÄ…cych zaleÅ¼noÅ›ci langchain4j zdefiniowanych w `pom.xml`:
```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Konfiguracja OpenAiOfficialChatModel** â€“ [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java)

Model czatu jest rÄ™cznie konfigurowany jako bean Springa przy uÅ¼yciu oficjalnego klienta OpenAI, ktÃ³ry obsÅ‚uguje punkty koÅ„cowe Azure OpenAI. Kluczowa rÃ³Å¼nica w stosunku do ModuÅ‚u 01 to sposÃ³b, w jaki strukturyzujemy prompty wysyÅ‚ane do `chatModel.chat()`, a nie sama konfiguracja modelu.

**WiadomoÅ›ci systemowe i uÅ¼ytkownika** â€“ [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)

LangChain4j rozdziela typy wiadomoÅ›ci dla przejrzystoÅ›ci. `SystemMessage` ustawia zachowanie i kontekst AI (np. â€JesteÅ› recenzentem koduâ€), podczas gdy `UserMessage` zawiera faktycznÄ… proÅ›bÄ™. To rozdzielenie pozwala utrzymaÄ‡ spÃ³jne zachowanie AI przy rÃ³Å¼nych zapytaniach uÅ¼ytkownika.

```java
SystemMessage systemMsg = SystemMessage.from(
    "You are a helpful Java programming expert."
);

UserMessage userMsg = UserMessage.from(
    "Explain what a List is in Java"
);

String response = chatModel.chat(systemMsg, userMsg);
```

<img src="../../../translated_images/message-types.93e0779798a17c9d.pl.png" alt="Message Types Architecture" width="800"/>

*SystemMessage zapewnia trwaÅ‚y kontekst, a UserMessages zawierajÄ… indywidualne zapytania*

**MessageWindowChatMemory dla wieloturnowej rozmowy** â€“ Dla wzorca wieloturnowej konwersacji ponownie uÅ¼ywamy `MessageWindowChatMemory` z ModuÅ‚u 01. KaÅ¼da sesja ma wÅ‚asnÄ… instancjÄ™ pamiÄ™ci przechowywanÄ… w `Map<String, ChatMemory>`, co pozwala na wiele rÃ³wnoczesnych rozmÃ³w bez mieszania kontekstu.

**Szablony promptÃ³w** â€“ Prawdziwym celem jest inÅ¼ynieria promptÃ³w, a nie nowe API LangChain4j. KaÅ¼dy wzorzec (niskie zaangaÅ¼owanie, wysokie zaangaÅ¼owanie, wykonywanie zadaÅ„ itd.) uÅ¼ywa tej samej metody `chatModel.chat(prompt)`, ale z starannie ustrukturyzowanymi ciÄ…gami promptÃ³w. TagÃ³w XML, instrukcji i formatowania jest czÄ™Å›ciÄ… tekstu promptu, a nie funkcjami LangChain4j.

**Kontrola rozumowania** â€“ WysiÅ‚ek rozumowania GPT-5 jest kontrolowany przez instrukcje w promptach, takie jak â€maksymalnie 2 kroki rozumowaniaâ€ lub â€zbadaj dokÅ‚adnieâ€. To techniki inÅ¼ynierii promptÃ³w, a nie konfiguracje LangChain4j. Biblioteka po prostu dostarcza twoje prompty do modelu.

Kluczowa lekcja: LangChain4j zapewnia infrastrukturÄ™ (poÅ‚Ä…czenie z modelem przez [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java), pamiÄ™Ä‡, obsÅ‚ugÄ™ wiadomoÅ›ci przez [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)), a ten moduÅ‚ uczy, jak tworzyÄ‡ skuteczne prompty w ramach tej infrastruktury.

## GÅ‚Ã³wne wzorce

Nie wszystkie problemy wymagajÄ… tego samego podejÅ›cia. NiektÃ³re pytania potrzebujÄ… szybkich odpowiedzi, inne gÅ‚Ä™bokiego myÅ›lenia. NiektÃ³re wymagajÄ… widocznego rozumowania, inne tylko wynikÃ³w. Ten moduÅ‚ obejmuje osiem wzorcÃ³w promptowania â€“ kaÅ¼dy zoptymalizowany pod rÃ³Å¼ne scenariusze. Przetestujesz je wszystkie, aby nauczyÄ‡ siÄ™, kiedy ktÃ³re podejÅ›cie dziaÅ‚a najlepiej.

<img src="../../../translated_images/eight-patterns.fa1ebfdf16f71e9a.pl.png" alt="Eight Prompting Patterns" width="800"/>

*PrzeglÄ…d oÅ›miu wzorcÃ³w inÅ¼ynierii promptÃ³w i ich zastosowaÅ„*

<img src="../../../translated_images/reasoning-effort.db4a3ba5b8e392c1.pl.png" alt="Reasoning Effort Comparison" width="800"/>

*Niskie zaangaÅ¼owanie (szybkie, bezpoÅ›rednie) vs wysokie zaangaÅ¼owanie (dokÅ‚adne, eksploracyjne) podejÅ›cia do rozumowania*

**Niskie zaangaÅ¼owanie (szybkie i skupione)** â€“ Dla prostych pytaÅ„, gdzie chcesz szybkich, bezpoÅ›rednich odpowiedzi. Model wykonuje minimalne rozumowanie â€“ maksymalnie 2 kroki. UÅ¼ywaj tego do obliczeÅ„, wyszukiwaÅ„ lub prostych pytaÅ„.

```java
String prompt = """
    <reasoning_effort>low</reasoning_effort>
    <instruction>maximum 2 reasoning steps</instruction>
    
    What is 15% of 200?
    """;

String response = chatModel.chat(prompt);
```

> ğŸ’¡ **Eksploruj z GitHub Copilot:** OtwÃ³rz [`Gpt5PromptService.java`](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java) i zapytaj:
> - â€Jaka jest rÃ³Å¼nica miÄ™dzy wzorcami niskiego a wysokiego zaangaÅ¼owania?â€
> - â€Jak tagi XML w promptach pomagajÄ… strukturyzowaÄ‡ odpowiedÅº AI?â€
> - â€Kiedy powinienem uÅ¼ywaÄ‡ wzorcÃ³w autorefleksji, a kiedy bezpoÅ›rednich instrukcji?â€

**Wysokie zaangaÅ¼owanie (gÅ‚Ä™bokie i dokÅ‚adne)** â€“ Dla zÅ‚oÅ¼onych problemÃ³w, gdzie chcesz kompleksowej analizy. Model eksploruje dokÅ‚adnie i pokazuje szczegÃ³Å‚owe rozumowanie. UÅ¼ywaj tego do projektowania systemÃ³w, decyzji architektonicznych lub zÅ‚oÅ¼onych badaÅ„.

```java
String prompt = """
    <reasoning_effort>high</reasoning_effort>
    <instruction>explore thoroughly, show detailed reasoning</instruction>
    
    Design a caching strategy for a high-traffic REST API.
    """;

String response = chatModel.chat(prompt);
```

**Wykonywanie zadaÅ„ (postÄ™p krok po kroku)** â€“ Dla wieloetapowych procesÃ³w. Model przedstawia plan na poczÄ…tku, opisuje kaÅ¼dy krok podczas pracy, a na koÅ„cu podsumowuje. UÅ¼ywaj tego do migracji, implementacji lub dowolnych procesÃ³w wieloetapowych.

```java
String prompt = """
    <task>Create a REST endpoint for user registration</task>
    <preamble>Provide an upfront plan</preamble>
    <narration>Narrate each step as you work</narration>
    <summary>Summarize what was accomplished</summary>
    """;

String response = chatModel.chat(prompt);
```

Promptowanie Chain-of-Thought wyraÅºnie prosi model o pokazanie procesu rozumowania, co poprawia dokÅ‚adnoÅ›Ä‡ w zÅ‚oÅ¼onych zadaniach. Rozbicie krok po kroku pomaga zarÃ³wno ludziom, jak i AI zrozumieÄ‡ logikÄ™.

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** Zapytaj o ten wzorzec:
> - â€Jak dostosowaÄ‡ wzorzec wykonywania zadaÅ„ do operacji dÅ‚ugotrwaÅ‚ych?â€
> - â€Jakie sÄ… najlepsze praktyki strukturyzowania wprowadzeÅ„ do narzÄ™dzi w aplikacjach produkcyjnych?â€
> - â€Jak mogÄ™ przechwytywaÄ‡ i wyÅ›wietlaÄ‡ poÅ›rednie aktualizacje postÄ™pu w UI?â€

<img src="../../../translated_images/task-execution-pattern.9da3967750ab5c1e.pl.png" alt="Task Execution Pattern" width="800"/>

*Plan â†’ Wykonaj â†’ Podsumuj â€“ przepÅ‚yw pracy dla zadaÅ„ wieloetapowych*

**Kod z autorefleksjÄ…** â€“ Do generowania kodu produkcyjnej jakoÅ›ci. Model generuje kod, sprawdza go pod kÄ…tem kryteriÃ³w jakoÅ›ci i iteracyjnie poprawia. UÅ¼ywaj tego przy tworzeniu nowych funkcji lub usÅ‚ug.

```java
String prompt = """
    <task>Create an email validation service</task>
    <quality_criteria>
    - Correct logic and error handling
    - Best practices (clean code, proper naming)
    - Performance optimization
    - Security considerations
    </quality_criteria>
    <instruction>Generate code, evaluate against criteria, improve iteratively</instruction>
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/self-reflection-cycle.6f71101ca0bd28cc.pl.png" alt="Self-Reflection Cycle" width="800"/>

*PÄ™tla iteracyjnej poprawy â€“ generuj, oceniaj, identyfikuj problemy, poprawiaj, powtarzaj*

**Analiza strukturalna** â€“ Do spÃ³jnej oceny. Model przeglÄ…da kod wedÅ‚ug ustalonego schematu (poprawnoÅ›Ä‡, praktyki, wydajnoÅ›Ä‡, bezpieczeÅ„stwo). UÅ¼ywaj tego do przeglÄ…dÃ³w kodu lub ocen jakoÅ›ci.

```java
String prompt = """
    <code>
    public List getUsers() {
        return database.query("SELECT * FROM users");
    }
    </code>
    
    <framework>
    Evaluate using these categories:
    1. Correctness - Logic and functionality
    2. Best Practices - Code quality
    3. Performance - Efficiency concerns
    4. Security - Vulnerabilities
    </framework>
    """;

String response = chatModel.chat(prompt);
```

> **ğŸ¤– WyprÃ³buj z [GitHub Copilot](https://github.com/features/copilot) Chat:** Zapytaj o analizÄ™ strukturalnÄ…:
> - â€Jak dostosowaÄ‡ ramy analizy do rÃ³Å¼nych typÃ³w przeglÄ…dÃ³w kodu?â€
> - â€Jaki jest najlepszy sposÃ³b na programowe parsowanie i dziaÅ‚anie na podstawie ustrukturyzowanego wyniku?â€
> - â€Jak zapewniÄ‡ spÃ³jne poziomy waÅ¼noÅ›ci w rÃ³Å¼nych sesjach przeglÄ…du?â€

<img src="../../../translated_images/structured-analysis-pattern.0af3b690b60cf2d6.pl.png" alt="Structured Analysis Pattern" width="800"/>

*Ramowy schemat czterech kategorii do spÃ³jnych przeglÄ…dÃ³w kodu z poziomami waÅ¼noÅ›ci*

**Wieloturnowa rozmowa** â€“ Do rozmÃ³w wymagajÄ…cych kontekstu. Model pamiÄ™ta poprzednie wiadomoÅ›ci i buduje na ich podstawie. UÅ¼ywaj tego do interaktywnych sesji pomocy lub zÅ‚oÅ¼onych Q&A.

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("What is Spring Boot?"));
AiMessage aiMessage1 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage1);

memory.add(UserMessage.from("Show me an example"));
AiMessage aiMessage2 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage2);
```

<img src="../../../translated_images/context-memory.dff30ad9fa78832a.pl.png" alt="Context Memory" width="800"/>

*Jak kontekst rozmowy kumuluje siÄ™ przez wiele tur aÅ¼ do osiÄ…gniÄ™cia limitu tokenÃ³w*

**Rozumowanie krok po kroku** â€“ Do problemÃ³w wymagajÄ…cych widocznej logiki. Model pokazuje wyraÅºne rozumowanie dla kaÅ¼dego kroku. UÅ¼ywaj tego do zadaÅ„ matematycznych, Å‚amigÅ‚Ã³wek logicznych lub gdy chcesz zrozumieÄ‡ proces myÅ›lenia.

```java
String prompt = """
    <instruction>Show your reasoning step-by-step</instruction>
    
    If a train travels 120 km in 2 hours, then stops for 30 minutes,
    then travels another 90 km in 1.5 hours, what is the average speed
    for the entire journey including the stop?
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/step-by-step-pattern.a99ea4ca1c48578c.pl.png" alt="Step-by-Step Pattern" width="800"/>

*Rozbijanie problemÃ³w na wyraÅºne kroki logiczne*

**Ograniczona odpowiedÅº** â€“ Do odpowiedzi z okreÅ›lonymi wymaganiami formatowania. Model Å›ciÅ›le przestrzega reguÅ‚ formatu i dÅ‚ugoÅ›ci. UÅ¼ywaj tego do podsumowaÅ„ lub gdy potrzebujesz precyzyjnej struktury wyjÅ›cia.

```java
String prompt = """
    <constraints>
    - Exactly 100 words
    - Bullet point format
    - Technical terms only
    </constraints>
    
    Summarize the key concepts of machine learning.
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/constrained-output-pattern.0ce39a682a6795c2.pl.png" alt="Constrained Output Pattern" width="800"/>

*Wymuszanie okreÅ›lonych wymagaÅ„ dotyczÄ…cych formatu, dÅ‚ugoÅ›ci i struktury*

## Korzystanie z istniejÄ…cych zasobÃ³w Azure

**Weryfikacja wdroÅ¼enia:**

Upewnij siÄ™, Å¼e plik `.env` istnieje w katalogu gÅ‚Ã³wnym z poÅ›wiadczeniami Azure (utworzony podczas ModuÅ‚u 01):
```bash
cat ../.env  # Powinno pokazywaÄ‡ AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Uruchom aplikacjÄ™:**

> **Uwaga:** JeÅ›li juÅ¼ uruchomiÅ‚eÅ› wszystkie aplikacje za pomocÄ… `./start-all.sh` z ModuÅ‚u 01, ten moduÅ‚ dziaÅ‚a juÅ¼ na porcie 8083. MoÅ¼esz pominÄ…Ä‡ poniÅ¼sze polecenia startowe i przejÅ›Ä‡ bezpoÅ›rednio do http://localhost:8083.

**Opcja 1: Korzystanie z Spring Boot Dashboard (zalecane dla uÅ¼ytkownikÃ³w VS Code)**

Kontener deweloperski zawiera rozszerzenie Spring Boot Dashboard, ktÃ³re zapewnia wizualny interfejs do zarzÄ…dzania wszystkimi aplikacjami Spring Boot. Znajdziesz je na pasku aktywnoÅ›ci po lewej stronie VS Code (ikona Spring Boot).

Z poziomu Spring Boot Dashboard moÅ¼esz:
- ZobaczyÄ‡ wszystkie dostÄ™pne aplikacje Spring Boot w workspace
- UruchamiaÄ‡/zatrzymywaÄ‡ aplikacje jednym klikniÄ™ciem
- PrzeglÄ…daÄ‡ logi aplikacji w czasie rzeczywistym
- MonitorowaÄ‡ status aplikacji

Po prostu kliknij przycisk play obok â€prompt-engineeringâ€, aby uruchomiÄ‡ ten moduÅ‚, lub uruchom wszystkie moduÅ‚y naraz.

<img src="../../../translated_images/dashboard.da2c2130c904aaf0.pl.png" alt="Spring Boot Dashboard" width="400"/>

**Opcja 2: Korzystanie ze skryptÃ³w shell**

Uruchom wszystkie aplikacje webowe (moduÅ‚y 01-04):

**Bash:**
```bash
cd ..  # Z katalogu gÅ‚Ã³wnego
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Z katalogu gÅ‚Ã³wnego
.\start-all.ps1
```

Lub uruchom tylko ten moduÅ‚:

**Bash:**
```bash
cd 02-prompt-engineering
./start.sh
```

**PowerShell:**
```powershell
cd 02-prompt-engineering
.\start.ps1
```

Oba skrypty automatycznie Å‚adujÄ… zmienne Å›rodowiskowe z pliku `.env` w katalogu gÅ‚Ã³wnym i zbudujÄ… pliki JAR, jeÅ›li nie istniejÄ….

> **Uwaga:** JeÅ›li wolisz zbudowaÄ‡ wszystkie moduÅ‚y rÄ™cznie przed uruchomieniem:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

OtwÃ³rz http://localhost:8083 w przeglÄ…darce.

**Aby zatrzymaÄ‡:**

**Bash:**
```bash
./stop.sh  # Tylko ten moduÅ‚
# Lub
cd .. && ./stop-all.sh  # Wszystkie moduÅ‚y
```

**PowerShell:**
```powershell
.\stop.ps1  # Tylko ten moduÅ‚
# Lub
cd ..; .\stop-all.ps1  # Wszystkie moduÅ‚y
```

## Zrzuty ekranu aplikacji

<img src="../../../translated_images/dashboard-home.5444dbda4bc1f79d.pl.png" alt="Dashboard Home" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/>

*GÅ‚Ã³wny pulpit pokazujÄ…cy wszystkie 8 wzorcÃ³w inÅ¼ynierii promptÃ³w z ich cechami i zastosowaniami*

## Eksploracja wzorcÃ³w

Interfejs webowy pozwala eksperymentowaÄ‡ z rÃ³Å¼nymi strategiami promptowania. KaÅ¼dy wzorzec rozwiÄ…zuje inne problemy â€“ wyprÃ³buj je, aby zobaczyÄ‡, kiedy ktÃ³re podejÅ›cie siÄ™ sprawdza.

### Niskie vs wysokie zaangaÅ¼owanie

Zadaj proste pytanie, np. â€Ile to jest 15% z 200?â€ uÅ¼ywajÄ…c niskiego zaangaÅ¼owania. Otrzymasz natychmiastowÄ…, bezpoÅ›redniÄ… odpowiedÅº. Teraz zapytaj o coÅ› zÅ‚oÅ¼onego, np. â€Zaprojektuj strategiÄ™ cacheâ€™owania dla API o duÅ¼ym ruchuâ€ uÅ¼ywajÄ…c wysokiego zaangaÅ¼owania. Zobacz, jak model zwalnia i dostarcza szczegÃ³Å‚owe rozumowanie. Ten sam model, ta sama struktura pytania â€“ ale prompt mÃ³wi mu, ile ma myÅ›leÄ‡.

<img src="../../../translated_images/low-eagerness-demo.898894591fb23aa0.pl.png" alt="Low Eagerness Demo" width="800"/>
*Szybkie obliczenia z minimalnym rozumowaniem*

<img src="../../../translated_images/high-eagerness-demo.4ac93e7786c5a376.pl.png" alt="High Eagerness Demo" width="800"/>

*Kompleksowa strategia buforowania (2,8MB)*

### Wykonywanie zadaÅ„ (Wprowadzenia do narzÄ™dzi)

Wieloetapowe przepÅ‚ywy pracy korzystajÄ… z wczeÅ›niejszego planowania i narracji postÄ™pÃ³w. Model opisuje, co zrobi, opowiada o kaÅ¼dym kroku, a nastÄ™pnie podsumowuje wyniki.

<img src="../../../translated_images/tool-preambles-demo.3ca4881e417f2e28.pl.png" alt="Task Execution Demo" width="800"/>

*Tworzenie punktu koÅ„cowego REST z narracjÄ… krok po kroku (3,9MB)*

### SamooceniajÄ…cy siÄ™ kod

SprÃ³buj "UtwÃ³rz usÅ‚ugÄ™ walidacji e-mail". Zamiast tylko generowaÄ‡ kod i przerywaÄ‡, model generuje, ocenia wedÅ‚ug kryteriÃ³w jakoÅ›ci, identyfikuje sÅ‚aboÅ›ci i poprawia. Zobaczysz, jak iteruje, aÅ¼ kod speÅ‚ni standardy produkcyjne.

<img src="../../../translated_images/self-reflecting-code-demo.851ee05c988e743f.pl.png" alt="Self-Reflecting Code Demo" width="800"/>

*Kompletna usÅ‚uga walidacji e-mail (5,2MB)*

### Strukturalna analiza

PrzeglÄ…dy kodu wymagajÄ… spÃ³jnych ram oceny. Model analizuje kod, uÅ¼ywajÄ…c staÅ‚ych kategorii (poprawnoÅ›Ä‡, praktyki, wydajnoÅ›Ä‡, bezpieczeÅ„stwo) z poziomami nasilenia.

<img src="../../../translated_images/structured-analysis-demo.9ef892194cd23bc8.pl.png" alt="Structured Analysis Demo" width="800"/>

*PrzeglÄ…d kodu oparty na ramach*

### Wieloetapowy czat

Zapytaj "Co to jest Spring Boot?", a nastÄ™pnie od razu "PokaÅ¼ mi przykÅ‚ad". Model pamiÄ™ta twoje pierwsze pytanie i podaje konkretny przykÅ‚ad Spring Boot. Bez pamiÄ™ci drugie pytanie byÅ‚oby zbyt ogÃ³lne.

<img src="../../../translated_images/multi-turn-chat-demo.0d2d9b9a86a12b4b.pl.png" alt="Multi-Turn Chat Demo" width="800"/>

*Zachowanie kontekstu miÄ™dzy pytaniami*

### Rozumowanie krok po kroku

Wybierz zadanie matematyczne i sprÃ³buj je rozwiÄ…zaÄ‡ zarÃ³wno z Rozumowaniem krok po kroku, jak i z Niskim ZapaÅ‚em. Niski zapaÅ‚ podaje tylko odpowiedÅº â€“ szybko, ale nieprzejrzyÅ›cie. Krok po kroku pokazuje kaÅ¼dy obliczenie i decyzjÄ™.

<img src="../../../translated_images/step-by-step-reasoning-demo.12139513356faecd.pl.png" alt="Step-by-Step Reasoning Demo" width="800"/>

*Zadanie matematyczne z wyraÅºnymi krokami*

### Ograniczona odpowiedÅº

Gdy potrzebujesz konkretnych formatÃ³w lub liczby sÅ‚Ã³w, ten wzorzec wymusza Å›cisÅ‚e przestrzeganie. SprÃ³buj wygenerowaÄ‡ podsumowanie dokÅ‚adnie 100 sÅ‚Ã³w w formacie punktÃ³w.

<img src="../../../translated_images/constrained-output-demo.567cc45b75da1633.pl.png" alt="Constrained Output Demo" width="800"/>

*Podsumowanie uczenia maszynowego z kontrolÄ… formatu*

## Czego naprawdÄ™ siÄ™ uczysz

**WysiÅ‚ek rozumowania zmienia wszystko**

GPT-5 pozwala kontrolowaÄ‡ nakÅ‚ad obliczeniowy przez twoje podpowiedzi. Niski wysiÅ‚ek oznacza szybkie odpowiedzi z minimalnym badaniem. Wysoki wysiÅ‚ek oznacza, Å¼e model poÅ›wiÄ™ca czas na gÅ‚Ä™bokie myÅ›lenie. Uczysz siÄ™ dopasowywaÄ‡ wysiÅ‚ek do zÅ‚oÅ¼onoÅ›ci zadania â€“ nie marnuj czasu na proste pytania, ale teÅ¼ nie Å›piesz siÄ™ zÅ‚oÅ¼onym decyzjom.

**Struktura kieruje zachowaniem**

ZauwaÅ¼yÅ‚eÅ› tagi XML w podpowiedziach? Nie sÄ… dekoracjÄ…. Modele bardziej niezawodnie wykonujÄ… instrukcje strukturalne niÅ¼ tekst swobodny. Gdy potrzebujesz wieloetapowych procesÃ³w lub zÅ‚oÅ¼onej logiki, struktura pomaga modelowi Å›ledziÄ‡, gdzie jest i co dalej.

<img src="../../../translated_images/prompt-structure.a77763d63f4e2f89.pl.png" alt="Prompt Structure" width="800"/>

*Anatomia dobrze zorganizowanej podpowiedzi z wyraÅºnymi sekcjami i organizacjÄ… w stylu XML*

**JakoÅ›Ä‡ przez samoocenÄ™**

Wzorce samooceniajÄ…ce dziaÅ‚ajÄ…, czyniÄ…c kryteria jakoÅ›ci jawne. Zamiast mieÄ‡ nadziejÄ™, Å¼e model "zrobi to dobrze", mÃ³wisz mu dokÅ‚adnie, co znaczy "dobrze": poprawna logika, obsÅ‚uga bÅ‚Ä™dÃ³w, wydajnoÅ›Ä‡, bezpieczeÅ„stwo. Model moÅ¼e wtedy oceniÄ‡ wÅ‚asny wynik i poprawiÄ‡ go. To zmienia generowanie kodu z loterii w proces.

**Kontekst jest ograniczony**

Wieloetapowe rozmowy dziaÅ‚ajÄ… przez doÅ‚Ä…czanie historii wiadomoÅ›ci do kaÅ¼dego zapytania. Ale jest limit â€“ kaÅ¼dy model ma maksymalnÄ… liczbÄ™ tokenÃ³w. W miarÄ™ rozwoju rozmÃ³w potrzebujesz strategii, by utrzymaÄ‡ istotny kontekst bez przekraczania limitu. Ten moduÅ‚ pokazuje, jak dziaÅ‚a pamiÄ™Ä‡; pÃ³Åºniej nauczysz siÄ™, kiedy podsumowywaÄ‡, kiedy zapominaÄ‡, a kiedy przywoÅ‚ywaÄ‡.

## Kolejne kroki

**NastÄ™pny moduÅ‚:** [03-rag - RAG (Retrieval-Augmented Generation)](../03-rag/README.md)

---

**Nawigacja:** [â† Poprzedni: ModuÅ‚ 01 - Wprowadzenie](../01-introduction/README.md) | [PowrÃ³t do gÅ‚Ã³wnego](../README.md) | [NastÄ™pny: ModuÅ‚ 03 - RAG â†’](../03-rag/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ZastrzeÅ¼enie**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dokÅ‚adamy staraÅ„, aby tÅ‚umaczenie byÅ‚o jak najbardziej precyzyjne, prosimy mieÄ‡ na uwadze, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym naleÅ¼y traktowaÄ‡ jako ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->