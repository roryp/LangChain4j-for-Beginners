<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "22b5d7c8d7585325e38b37fd29eafe25",
  "translation_date": "2026-01-05T22:57:28+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "pt"
}
-->
# Module 00: In√≠cio R√°pido

## √çndice

- [Introdu√ß√£o](../../../00-quick-start)
- [O que √© LangChain4j?](../../../00-quick-start)
- [Depend√™ncias do LangChain4j](../../../00-quick-start)
- [Pr√©-requisitos](../../../00-quick-start)
- [Configura√ß√£o](../../../00-quick-start)
  - [1. Obtenha o seu Token do GitHub](../../../00-quick-start)
  - [2. Defina o seu Token](../../../00-quick-start)
- [Executar os Exemplos](../../../00-quick-start)
  - [1. Chat B√°sico](../../../00-quick-start)
  - [2. Padr√µes de Prompt](../../../00-quick-start)
  - [3. Chamada de Fun√ß√£o](../../../00-quick-start)
  - [4. Perguntas e Respostas de Documento (RAG)](../../../00-quick-start)
  - [5. IA Respons√°vel](../../../00-quick-start)
- [O que Cada Exemplo Mostra](../../../00-quick-start)
- [Pr√≥ximos Passos](../../../00-quick-start)
- [Resolu√ß√£o de Problemas](../../../00-quick-start)

## Introdu√ß√£o

Este in√≠cio r√°pido destina-se a p√¥-lo a funcionar com LangChain4j o mais rapidamente poss√≠vel. Cobre o b√°sico absoluto de construir aplica√ß√µes de IA com LangChain4j e Modelos do GitHub. Nos pr√≥ximos m√≥dulos, usar√° o Azure OpenAI com LangChain4j para construir aplica√ß√µes mais avan√ßadas.

## O que √© LangChain4j?

LangChain4j √© uma biblioteca Java que simplifica a constru√ß√£o de aplica√ß√µes alimentadas por IA. Em vez de lidar com clientes HTTP e an√°lise JSON, trabalha com APIs Java limpas.

A "cadeia" em LangChain refere-se a encadear m√∫ltiplos componentes - pode encadear um prompt a um modelo, a um parser, ou encadear m√∫ltiplas chamadas de IA onde uma sa√≠da alimenta a pr√≥xima entrada. Este in√≠cio r√°pido foca nos fundamentos antes de explorar cadeias mais complexas.

<img src="../../../translated_images/pt/langchain-concept.ad1fe6cf063515e1.webp" alt="Conceito de Cadeia LangChain4j" width="800"/>

*Encadeamento de componentes em LangChain4j - os blocos de constru√ß√£o conectam-se para criar fluxos de trabalho poderosos de IA*

Vamos usar tr√™s componentes principais:

**ChatLanguageModel** - Interface para intera√ß√µes com modelos de IA. Chame `model.chat("prompt")` e obtenha uma string de resposta. Utilizamos `OpenAiOfficialChatModel` que funciona com endpoints compat√≠veis com OpenAI, como Modelos do GitHub.

**AiServices** - Cria interfaces de servi√ßo de IA tipadas. Defina m√©todos, anote-os com `@Tool` e o LangChain4j gere a orquestra√ß√£o. A IA chama automaticamente os seus m√©todos Java quando necess√°rio.

**MessageWindowChatMemory** - Mant√©m o hist√≥rico da conversa. Sem isto, cada pedido √© independente. Com isto, a IA lembra mensagens anteriores e mant√©m contexto ao longo de m√∫ltiplas intera√ß√µes.

<img src="../../../translated_images/pt/architecture.eedc993a1c576839.webp" alt="Arquitetura LangChain4j" width="800"/>

*Arquitetura LangChain4j - componentes principais a trabalhar juntos para alimentar as suas aplica√ß√µes de IA*

## Depend√™ncias do LangChain4j

Este in√≠cio r√°pido usa duas depend√™ncias Maven no [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

O m√≥dulo `langchain4j-open-ai-official` fornece a classe `OpenAiOfficialChatModel` que conecta com APIs compat√≠veis com OpenAI. Os Modelos do GitHub usam o mesmo formato de API, por isso n√£o √© necess√°rio um adaptador especial - basta apontar a URL base para `https://models.github.ai/inference`.

## Pr√©-requisitos

**A usar o Dev Container?** Java e Maven j√° est√£o instalados. S√≥ precisa de um Token de Acesso Pessoal do GitHub.

**Desenvolvimento Local:**
- Java 21+, Maven 3.9+
- Token de Acesso Pessoal do GitHub (instru√ß√µes abaixo)

> **Nota:** Este m√≥dulo usa `gpt-4.1-nano` dos Modelos GitHub. N√£o modifique o nome do modelo no c√≥digo - est√° configurado para funcionar com os modelos dispon√≠veis do GitHub.

## Configura√ß√£o

### 1. Obtenha o seu Token do GitHub

1. V√° a [Defini√ß√µes do GitHub ‚Üí Tokens de Acesso Pessoal](https://github.com/settings/personal-access-tokens)
2. Clique em "Gerar novo token"
3. Defina um nome descritivo (ex.: "Demonstra√ß√£o LangChain4j")
4. Defina o prazo de validade (7 dias recomendado)
5. Em "Permiss√µes da Conta", encontre "Models" e defina para "S√≥ leitura"
6. Clique em "Gerar token"
7. Copie e guarde o seu token - n√£o o ver√° novamente

### 2. Defina o seu Token

**Op√ß√£o 1: Usar VS Code (Recomendado)**

Se usar VS Code, adicione o seu token no ficheiro `.env` na raiz do projeto:

Se o ficheiro `.env` n√£o existir, copie `.env.example` para `.env` ou crie um novo ficheiro `.env` na raiz do projeto.

**Exemplo de ficheiro `.env`:**
```bash
# Em /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Depois, pode simplesmente clicar com o bot√£o direito em qualquer ficheiro de demo (ex.: `BasicChatDemo.java`) no Explorador e selecionar **"Run Java"** ou usar as configura√ß√µes de lan√ßamento no painel Executar e Depurar.

**Op√ß√£o 2: Usar Terminal**

Defina o token como vari√°vel de ambiente:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## Executar os Exemplos

**Usando VS Code:** Clique com o bot√£o direito em qualquer ficheiro de demo no Explorador e selecione **"Run Java"**, ou use as configura√ß√µes de lan√ßamento no painel Executar e Depurar (certifique-se de ter adicionado o seu token ao ficheiro `.env` primeiro).

**Usando Maven:** Alternativamente, pode executar a partir da linha de comandos:

### 1. Chat B√°sico

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Padr√µes de Prompt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Mostra prompting zero-shot, few-shot, em cadeia de pensamento e baseado em pap√©is.

### 3. Chamada de Fun√ß√£o

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

A IA chama automaticamente os seus m√©todos Java quando necess√°rio.

### 4. Perguntas e Respostas de Documento (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Fa√ßa perguntas sobre o conte√∫do de `document.txt`.

### 5. IA Respons√°vel

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

Veja como os filtros de seguran√ßa IA bloqueiam conte√∫do prejudicial.

## O que Cada Exemplo Mostra

**Chat B√°sico** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Comece aqui para ver o LangChain4j na sua forma mais simples. Vai criar um `OpenAiOfficialChatModel`, enviar um prompt com `.chat()`, e receber uma resposta. Isto demonstra a base: como inicializar modelos com endpoints personalizados e chaves API. Uma vez que perceba este padr√£o, tudo o resto constr√≥i-se a partir daqui.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Experimente com [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) e pergunte:
> - "Como mudaria dos Modelos GitHub para Azure OpenAI neste c√≥digo?"
> - "Que outros par√¢metros posso configurar em OpenAiOfficialChatModel.builder()?"
> - "Como adiciono respostas em streaming em vez de esperar pela resposta completa?"

**Engenharia de Prompt** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Agora que sabe falar com um modelo, vamos explorar o que diz a ele. Esta demo usa a mesma configura√ß√£o de modelo mas mostra quatro padr√µes diferentes de prompting. Experimente zero-shot para instru√ß√µes diretas, few-shot que aprende com exemplos, cadeia de pensamento que revela passos de racioc√≠nio, e prompts baseados em pap√©is que definem contexto. Vai ver como o mesmo modelo d√° resultados dramaticamente diferentes consoante formula a sua solicita√ß√£o.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Experimente com [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) e pergunte:
> - "Qual √© a diferen√ßa entre prompting zero-shot e few-shot, e quando devo usar cada um?"
> - "Como o par√¢metro temperatura afeta as respostas do modelo?"
> - "Quais s√£o algumas t√©cnicas para prevenir ataques de inje√ß√£o de prompt em produ√ß√£o?"
> - "Como posso criar objetos PromptTemplate reutiliz√°veis para padr√µes comuns?"

**Integra√ß√£o de Ferramentas** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

√â aqui que o LangChain4j se torna poderoso. Vai usar `AiServices` para criar um assistente de IA que pode chamar os seus m√©todos Java. Basta anotar m√©todos com `@Tool("descri√ß√£o")` e o LangChain4j trata do resto - a IA decide automaticamente quando usar cada ferramenta com base no que o utilizador pede. Isto demonstra chamadas de fun√ß√£o, uma t√©cnica chave para construir IA que pode tomar a√ß√µes, n√£o apenas responder perguntas.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Experimente com [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) e pergunte:
> - "Como funciona a anota√ß√£o @Tool e o que o LangChain4j faz com ela nos bastidores?"
> - "Pode a IA chamar v√°rias ferramentas em sequ√™ncia para resolver problemas complexos?"
> - "O que acontece se uma ferramenta lan√ßar uma exce√ß√£o - como devo tratar erros?"
> - "Como integraria uma API real em vez deste exemplo da calculadora?"

**Perguntas e Respostas de Documento (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Aqui ver√° a base do RAG (gera√ß√£o aumentada por recupera√ß√£o). Em vez de depender dos dados de treino do modelo, carrega conte√∫do de [`document.txt`](../../../00-quick-start/document.txt) e inclui no prompt. A IA responde com base no seu documento, n√£o no conhecimento geral dela. Este √© o primeiro passo para construir sistemas que podem trabalhar com os seus pr√≥prios dados.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Nota:** Esta abordagem simples carrega o documento completo no prompt. Para ficheiros grandes (>10KB), ultrapassar√° os limites de contexto. O M√≥dulo 03 cobre fragmenta√ß√£o e pesquisa vetorial para sistemas RAG em produ√ß√£o.

> **ü§ñ Experimente com [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) e pergunte:
> - "Como o RAG previne alucina√ß√µes da IA comparado com usar os dados de treino do modelo?"
> - "Qual √© a diferen√ßa entre esta abordagem simples e usar embeddings vetoriais para recupera√ß√£o?"
> - "Como escalar isto para lidar com m√∫ltiplos documentos ou bases de conhecimento maiores?"
> - "Quais s√£o as melhores pr√°ticas para estruturar o prompt de modo a garantir que a IA usa apenas o contexto fornecido?"

**IA Respons√°vel** - [ResponsibleAIDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java)

Construa seguran√ßa em IA com defesa em profundidade. Esta demo mostra duas camadas de prote√ß√£o a trabalhar em conjunto:

**Parte 1: Guard Rails de Entrada LangChain4j** - Bloqueia prompts perigosos antes de chegarem √† LLM. Crie guard rails personalizados que verificam palavras-chave ou padr√µes proibidos. Estes correm no seu c√≥digo, por isso s√£o r√°pidos e gratuitos.

```java
class DangerousContentGuardrail implements InputGuardrail {
    @Override
    public InputGuardrailResult validate(UserMessage userMessage) {
        String text = userMessage.singleText().toLowerCase();
        if (text.contains("explosives")) {
            return fatal("Blocked: contains prohibited keyword");
        }
        return success();
    }
}
```

**Parte 2: Filtros de Seguran√ßa do Provedor** - Os Modelos GitHub t√™m filtros embutidos que apanham o que os seus guard rails possam falhar. Vai ver bloqueios r√≠gidos (erros HTTP 400) para viola√ß√µes graves e recusas suaves onde a IA recusa educadamente.

> **ü§ñ Experimente com [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`ResponsibleAIDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java) e pergunte:
> - "O que √© InputGuardrail e como crio o meu pr√≥prio?"
> - "Qual √© a diferen√ßa entre bloqueio r√≠gido e recusa suave?"
> - "Por que usar guard rails e filtros do provedor juntos?"

## Pr√≥ximos Passos

**Pr√≥ximo M√≥dulo:** [01-introdu√ß√£o - Come√ßar com LangChain4j e gpt-5 no Azure](../01-introduction/README.md)

---

**Navega√ß√£o:** [‚Üê Voltar ao Principal](../README.md) | [Pr√≥ximo: M√≥dulo 01 - Introdu√ß√£o ‚Üí](../01-introduction/README.md)

---

## Resolu√ß√£o de Problemas

### Primeira Build Maven

**Problema**: `mvn clean compile` ou `mvn package` inicial demora muito (10-15 minutos)

**Causa**: O Maven precisa de descarregar todas as depend√™ncias do projeto (Spring Boot, bibliotecas LangChain4j, SDKs Azure, etc.) na primeira compila√ß√£o.

**Solu√ß√£o**: √â um comportamento normal. Compila√ß√µes subsequentes ser√£o muito mais r√°pidas porque as depend√™ncias ficam em cache localmente. O tempo de descarga depende da velocidade da sua rede.

### Sintaxe do Comando Maven no PowerShell

**Problema**: Comandos Maven falham com erro `Unknown lifecycle phase ".mainClass=..."`

**Causa**: PowerShell interpreta `=` como operador de atribui√ß√£o de vari√°vel, quebrando a sintaxe da propriedade Maven
**Solu√ß√£o**: Use o operador de paragem de parsing `--%` antes do comando Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

O operador `--%` diz ao PowerShell para passar todos os argumentos restantes literalmente para o Maven sem interpreta√ß√£o.

### Exibi√ß√£o de Emojis no Windows PowerShell

**Problema**: As respostas da IA mostram caracteres estranhos (ex.: `????` ou `√¢??`) em vez de emojis no PowerShell

**Causa**: A codifica√ß√£o padr√£o do PowerShell n√£o suporta emojis UTF-8

**Solu√ß√£o**: Execute este comando antes de executar aplica√ß√µes Java:
```cmd
chcp 65001
```

Isto for√ßa a codifica√ß√£o UTF-8 no terminal. Alternativamente, use o Windows Terminal que tem melhor suporte a Unicode.

### Depura√ß√£o de Chamadas API

**Problema**: Erros de autentica√ß√£o, limites de taxa ou respostas inesperadas do modelo de IA

**Solu√ß√£o**: Os exemplos incluem `.logRequests(true)` e `.logResponses(true)` para mostrar as chamadas API na consola. Isto ajuda a resolver erros de autentica√ß√£o, limites de taxa ou respostas inesperadas. Remova estas flags na produ√ß√£o para reduzir o ru√≠do dos logs.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, por favor, tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes da utiliza√ß√£o desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->