<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "81d087662fb3dd7b7124bce1a9c9ec86",
  "translation_date": "2026-01-05T22:58:03+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "pt"
}
-->
# M√≥dulo 03: RAG (Gera√ß√£o Aumentada por Recupera√ß√£o)

## √çndice

- [O que vai aprender](../../../03-rag)
- [Pr√©-requisitos](../../../03-rag)
- [Compreender o RAG](../../../03-rag)
- [Como funciona](../../../03-rag)
  - [Processamento de documentos](../../../03-rag)
  - [Cria√ß√£o de embeddings](../../../03-rag)
  - [Pesquisa sem√¢ntica](../../../03-rag)
  - [Gera√ß√£o de respostas](../../../03-rag)
- [Executar a aplica√ß√£o](../../../03-rag)
- [Utilizar a aplica√ß√£o](../../../03-rag)
  - [Carregar um documento](../../../03-rag)
  - [Fazer perguntas](../../../03-rag)
  - [Verificar refer√™ncias de fonte](../../../03-rag)
  - [Experimentar com as perguntas](../../../03-rag)
- [Conceitos chave](../../../03-rag)
  - [Estrat√©gia de fragmenta√ß√£o](../../../03-rag)
  - [Pontua√ß√µes de similaridade](../../../03-rag)
  - [Armazenamento em mem√≥ria](../../../03-rag)
  - [Gest√£o da janela de contexto](../../../03-rag)
- [Quando o RAG importa](../../../03-rag)
- [Pr√≥ximos passos](../../../03-rag)

## O que vai aprender

Nos m√≥dulos anteriores, aprendeu como ter conversas com IA e estruturar os seus prompts de forma eficaz. Mas existe uma limita√ß√£o fundamental: os modelos de linguagem apenas sabem aquilo que aprenderam durante o treino. Eles n√£o conseguem responder a perguntas sobre as pol√≠ticas da sua empresa, a documenta√ß√£o do seu projeto ou qualquer informa√ß√£o que n√£o tenha sido usada no seu treino.

O RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) resolve este problema. Em vez de tentar ensinar o modelo com a sua informa√ß√£o (o que √© dispendioso e impratic√°vel), d√°-lhe a capacidade de pesquisar atrav√©s dos seus documentos. Quando algu√©m faz uma pergunta, o sistema encontra informa√ß√£o relevante e inclui-a no prompt. O modelo ent√£o responde com base nesse contexto recuperado.

Pense no RAG como dar ao modelo uma biblioteca de refer√™ncia. Quando fizer uma pergunta, o sistema:

1. **Pergunta do utilizador** - Voc√™ faz uma pergunta  
2. **Embedding** - Converte a sua pergunta numa representa√ß√£o vetorial  
3. **Pesquisa vetorial** - Encontra fragmentos de documento semelhantes  
4. **Montagem do contexto** - Adiciona os fragmentos relevantes ao prompt  
5. **Resposta** - O LLM gera uma resposta baseada no contexto  

Isto fundamenta as respostas do modelo nos seus dados reais, em vez de depender apenas do conhecimento do treino ou de inventar respostas.

<img src="../../../translated_images/rag-architecture.ccb53b71a6ce407f.pt.png" alt="Arquitetura RAG" width="800"/>

*Fluxo de trabalho do RAG - da pergunta do utilizador √† pesquisa sem√¢ntica at√© √† gera√ß√£o de resposta contextual*

## Pr√©-requisitos

- M√≥dulo 01 conclu√≠do (recursos Azure OpenAI implantados)  
- Ficheiro `.env` na raiz com credenciais Azure (criado pelo `azd up` no M√≥dulo 01)  

> **Nota:** Se n√£o completou o M√≥dulo 01, siga primeiro as instru√ß√µes de implanta√ß√£o desse m√≥dulo.

## Como funciona

### Processamento de documentos

[DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

Quando carrega um documento, o sistema divide-o em fragmentos ‚Äî peda√ßos mais pequenos que cabem confortavelmente na janela de contexto do modelo. Estes fragmentos sobrep√µem-se ligeiramente para n√£o perder contexto nas fronteiras.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```
  
> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) e pergunte:  
> - "Como √© que o LangChain4j divide os documentos em fragmentos e por que √© importante a sobreposi√ß√£o?"  
> - "Qual √© o tamanho ideal dos fragmentos para diferentes tipos de documentos e porqu√™?"  
> - "Como tratar documentos em v√°rias l√≠nguas ou com formata√ß√£o especial?"

### Cria√ß√£o de embeddings

[LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Cada fragmento √© convertido numa representa√ß√£o num√©rica chamada embedding ‚Äî essencialmente uma impress√£o digital matem√°tica que captura o significado do texto. Textos similares produzem embeddings similares.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```
  
<img src="../../../translated_images/vector-embeddings.2ef7bdddac79a327.pt.png" alt="Espa√ßo de Embeddings Vetoriais" width="800"/>

*Documentos representados como vetores no espa√ßo de embeddings ‚Äî conte√∫dos semelhantes agrupam-se*

### Pesquisa sem√¢ntica

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Quando faz uma pergunta, a sua pergunta tamb√©m √© convertida num embedding. O sistema compara o embedding da sua pergunta com todos os embeddings dos fragmentos dos documentos. Encontra os fragmentos com significados mais similares ‚Äî n√£o s√≥ por palavras-chave coincidentes, mas por verdadeira similaridade sem√¢ntica.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```
  
> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) e pergunte:  
> - "Como funciona a pesquisa por similaridade com embeddings e o que determina a pontua√ß√£o?"  
> - "Qual o limiar de similaridade que devo usar e como isso afeta os resultados?"  
> - "Como tratar casos em que n√£o s√£o encontrados documentos relevantes?"

### Gera√ß√£o de resposta

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Os fragmentos mais relevantes s√£o inclu√≠dos no prompt para o modelo. O modelo l√™ esses fragmentos espec√≠ficos e responde com base nessa informa√ß√£o. Isto previne alucina√ß√µes ‚Äî o modelo s√≥ pode responder ao que est√° √† sua frente.

## Executar a aplica√ß√£o

**Verificar implanta√ß√£o:**  

Certifique-se de que o ficheiro `.env` existe na raiz com as credenciais Azure (criado durante o M√≥dulo 01):  
```bash
cat ../.env  # Deve mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**Iniciar a aplica√ß√£o:**  

> **Nota:** Se j√° iniciou todas as aplica√ß√µes com `./start-all.sh` no M√≥dulo 01, este m√≥dulo j√° est√° a correr na porta 8081. Pode ignorar os comandos abaixo e ir diretamente para http://localhost:8081.

**Op√ß√£o 1: Usar Spring Boot Dashboard (Recomendado para utilizadores VS Code)**

O contentor de desenvolvimento inclui a extens√£o Spring Boot Dashboard, que fornece uma interface visual para gerir todas as aplica√ß√µes Spring Boot. Pode encontr√°-la na Barra de Atividades √† esquerda do VS Code (procure o √≠cone Spring Boot).

No Spring Boot Dashboard, pode:  
- Ver todas as aplica√ß√µes Spring Boot dispon√≠veis no workspace  
- Iniciar/parar aplica√ß√µes com um clique  
- Ver logs da aplica√ß√£o em tempo real  
- Monitorizar o estado da aplica√ß√£o

Basta clicar no bot√£o de play junto de "rag" para iniciar este m√≥dulo, ou iniciar todos os m√≥dulos de uma vez.

<img src="../../../translated_images/dashboard.fbe6e28bf4267ffe.pt.png" alt="Spring Boot Dashboard" width="400"/>

**Op√ß√£o 2: Usar scripts shell**

Iniciar todas as aplica√ß√µes web (m√≥dulos 01-04):  

**Bash:**  
```bash
cd ..  # A partir do diret√≥rio raiz
./start-all.sh
```
  
**PowerShell:**  
```powershell
cd ..  # A partir do diret√≥rio raiz
.\start-all.ps1
```
  
Ou iniciar s√≥ este m√≥dulo:  

**Bash:**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell:**  
```powershell
cd 03-rag
.\start.ps1
```
  
Ambos os scripts carregam automaticamente as vari√°veis de ambiente do ficheiro `.env` na raiz e v√£o compilar os JARs se estes n√£o existirem.

> **Nota:** Se preferir compilar todos os m√≥dulos manualmente antes de iniciar:  
>  
> **Bash:**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

> **PowerShell:**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
Abra http://localhost:8081 no seu browser.

**Para parar:**  

**Bash:**  
```bash
./stop.sh  # Apenas este m√≥dulo
# Ou
cd .. && ./stop-all.sh  # Todos os m√≥dulos
```
  
**PowerShell:**  
```powershell
.\stop.ps1  # Apenas este m√≥dulo
# Ou
cd ..; .\stop-all.ps1  # Todos os m√≥dulos
```
  
## Utilizar a aplica√ß√£o

A aplica√ß√£o oferece uma interface web para upload de documentos e fazer perguntas.

<a href="images/rag-homepage.png"><img src="../../../translated_images/rag-homepage.d90eb5ce1b3caa94.pt.png" alt="Interface da Aplica√ß√£o RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Interface da aplica√ß√£o RAG ‚Äî carregue documentos e fa√ßa perguntas*

### Carregar um documento

Comece por carregar um documento ‚Äî ficheiros TXT funcionam melhor para testes. Um ficheiro `sample-document.txt` est√° dispon√≠vel neste diret√≥rio, contendo informa√ß√µes sobre as funcionalidades do LangChain4j, implementa√ß√£o RAG e melhores pr√°ticas ‚Äî perfeito para testar o sistema.

O sistema processa o documento, divide-o em fragmentos e cria embeddings para cada fragmento. Isto acontece automaticamente ao carregar.

### Fazer perguntas

Agora fa√ßa perguntas espec√≠ficas sobre o conte√∫do do documento. Tente algo factual que esteja claramente declarado no documento. O sistema procura fragmentos relevantes, inclui-os no prompt e gera uma resposta.

### Verificar refer√™ncias de fonte

Note que cada resposta inclui refer√™ncias de fonte com pontua√ß√µes de similaridade. Estas pontua√ß√µes (de 0 a 1) mostram qu√£o relevante foi cada fragmento para a sua pergunta. Pontua√ß√µes mais altas significam melhor correspond√™ncia. Isto permite-lhe verificar a resposta com o material de origem.

<a href="images/rag-query-results.png"><img src="../../../translated_images/rag-query-results.6d69fcec5397f355.pt.png" alt="Resultados da Consulta RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Resultados da consulta mostrando resposta com refer√™ncias de fonte e pontua√ß√µes de relev√¢ncia*

### Experimentar com as perguntas

Experimente diferentes tipos de perguntas:  
- Factos espec√≠ficos: "Qual √© o tema principal?"  
- Compara√ß√µes: "Qual √© a diferen√ßa entre X e Y?"  
- Resumos: "Resuma os pontos chave sobre Z"

Veja como as pontua√ß√µes de relev√¢ncia mudam conforme a correspond√™ncia da pergunta com o conte√∫do do documento.

## Conceitos chave

### Estrat√©gia de fragmenta√ß√£o

Os documentos s√£o divididos em fragmentos de 300 tokens com 30 tokens de sobreposi√ß√£o. Este equil√≠brio assegura que cada fragmento tenha contexto suficiente para ser significativo mas continue pequeno o bastante para incluir m√∫ltiplos fragmentos num prompt.

### Pontua√ß√µes de similaridade

As pontua√ß√µes variam entre 0 e 1:  
- 0.7-1.0: Altamente relevante, correspond√™ncia exata  
- 0.5-0.7: Relevante, bom contexto  
- Abaixo de 0.5: Filtrado, demasiado dissimilar  

O sistema recupera apenas fragmentos acima do limiar m√≠nimo para garantir qualidade.

### Armazenamento em mem√≥ria

Este m√≥dulo usa armazenamento em mem√≥ria pela simplicidade. Ao reiniciar a aplica√ß√£o, os documentos carregados s√£o perdidos. Sistemas de produ√ß√£o usam bases de dados vetoriais persistentes como Qdrant ou Azure AI Search.

### Gest√£o da janela de contexto

Cada modelo tem uma janela m√°xima de contexto. N√£o pode incluir todos os fragmentos de um documento extenso. O sistema recupera os N fragmentos mais relevantes (por defeito 5) para manter-se dentro dos limites, oferecendo contexto suficiente para respostas precisas.

## Quando o RAG importa

**Use o RAG quando:**  
- Precisa responder a perguntas sobre documentos propriet√°rios  
- A informa√ß√£o muda frequentemente (pol√≠ticas, pre√ßos, especifica√ß√µes)  
- A precis√£o requer atribui√ß√£o da fonte  
- O conte√∫do √© demasiado grande para caber num √∫nico prompt  
- Precisa de respostas verific√°veis e fundamentadas

**N√£o use o RAG quando:**  
- As perguntas requerem conhecimento geral que o modelo j√° tem  
- Precisa de dados em tempo real (RAG funciona com documentos carregados)  
- O conte√∫do √© pequeno o suficiente para incluir diretamente nos prompts

## Pr√≥ximos passos

**Pr√≥ximo m√≥dulo:** [04-tools - Agentes IA com Ferramentas](../04-tools/README.md)

---

**Navega√ß√£o:** [‚Üê Anterior: M√≥dulo 02 - Engenharia de Prompt](../02-prompt-engineering/README.md) | [Voltar ao in√≠cio](../README.md) | [Seguinte: M√≥dulo 04 - Ferramentas ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos por garantir a exactid√£o, por favor esteja ciente de que as tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes da utiliza√ß√£o desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->