<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8d787826cad7e92bf5cdbd116b1e6116",
  "translation_date": "2025-12-13T16:03:42+00:00",
  "source_file": "02-prompt-engineering/README.md",
  "language_code": "pt"
}
-->
# M√≥dulo 02: Engenharia de Prompts com GPT-5

## √çndice

- [O que vai aprender](../../../02-prompt-engineering)
- [Pr√©-requisitos](../../../02-prompt-engineering)
- [Compreender a Engenharia de Prompts](../../../02-prompt-engineering)
- [Como isto usa LangChain4j](../../../02-prompt-engineering)
- [Os Padr√µes Principais](../../../02-prompt-engineering)
- [Usar Recursos Azure Existentes](../../../02-prompt-engineering)
- [Capturas de Ecr√£ da Aplica√ß√£o](../../../02-prompt-engineering)
- [Explorar os Padr√µes](../../../02-prompt-engineering)
  - [Baixa vs Alta Vontade](../../../02-prompt-engineering)
  - [Execu√ß√£o de Tarefas (Pre√¢mbulos de Ferramentas)](../../../02-prompt-engineering)
  - [C√≥digo Auto-Reflexivo](../../../02-prompt-engineering)
  - [An√°lise Estruturada](../../../02-prompt-engineering)
  - [Chat Multi-Turno](../../../02-prompt-engineering)
  - [Racioc√≠nio Passo a Passo](../../../02-prompt-engineering)
  - [Sa√≠da Constrangida](../../../02-prompt-engineering)
- [O que est√° realmente a aprender](../../../02-prompt-engineering)
- [Pr√≥ximos Passos](../../../02-prompt-engineering)

## O que vai aprender

No m√≥dulo anterior, viu como a mem√≥ria permite IA conversacional e usou os Modelos GitHub para intera√ß√µes b√°sicas. Agora vamos focar em como faz perguntas ‚Äî os pr√≥prios prompts ‚Äî usando o GPT-5 do Azure OpenAI. A forma como estrutura os seus prompts afeta dramaticamente a qualidade das respostas que obt√©m.

Vamos usar o GPT-5 porque ele introduz controlo de racioc√≠nio ‚Äî pode dizer ao modelo quanto deve pensar antes de responder. Isto torna diferentes estrat√©gias de prompting mais evidentes e ajuda a perceber quando usar cada abordagem. Tamb√©m beneficiamos dos limites de taxa mais baixos do Azure para o GPT-5 comparado com os Modelos GitHub.

## Pr√©-requisitos

- M√≥dulo 01 conclu√≠do (recursos Azure OpenAI implementados)
- Ficheiro `.env` na diretoria raiz com credenciais Azure (criado pelo `azd up` no M√≥dulo 01)

> **Nota:** Se ainda n√£o concluiu o M√≥dulo 01, siga primeiro as instru√ß√µes de implementa√ß√£o a√≠.

## Compreender a Engenharia de Prompts

Engenharia de prompts √© sobre desenhar texto de entrada que consistentemente lhe d√° os resultados que precisa. N√£o √© s√≥ fazer perguntas ‚Äî √© estruturar pedidos para que o modelo entenda exatamente o que quer e como entregar.

Pense nisso como dar instru√ß√µes a um colega. "Corrige o bug" √© vago. "Corrige a exce√ß√£o de ponteiro nulo em UserService.java linha 45 adicionando uma verifica√ß√£o de nulo" √© espec√≠fico. Os modelos de linguagem funcionam da mesma forma ‚Äî especificidade e estrutura s√£o importantes.

## Como isto usa LangChain4j

Este m√≥dulo demonstra padr√µes avan√ßados de prompting usando a mesma base LangChain4j dos m√≥dulos anteriores, com foco na estrutura do prompt e controlo de racioc√≠nio.

<img src="../../../translated_images/langchain4j-flow.48e534666213010b.pt.png" alt="LangChain4j Flow" width="800"/>

*Como o LangChain4j liga os seus prompts ao Azure OpenAI GPT-5*

**Depend√™ncias** ‚Äì O M√≥dulo 02 usa as seguintes depend√™ncias langchain4j definidas em `pom.xml`:
```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Configura√ß√£o OpenAiOfficialChatModel** ‚Äì [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java)

O modelo de chat √© configurado manualmente como um bean Spring usando o cliente oficial OpenAI, que suporta endpoints Azure OpenAI. A principal diferen√ßa do M√≥dulo 01 √© como estruturamos os prompts enviados para `chatModel.chat()`, n√£o a configura√ß√£o do modelo em si.

**Mensagens de Sistema e Utilizador** ‚Äì [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)

O LangChain4j separa os tipos de mensagem para clareza. `SystemMessage` define o comportamento e contexto da IA (como "Voc√™ √© um revisor de c√≥digo"), enquanto `UserMessage` cont√©m o pedido real. Esta separa√ß√£o permite manter comportamento consistente da IA em diferentes consultas de utilizador.

```java
SystemMessage systemMsg = SystemMessage.from(
    "You are a helpful Java programming expert."
);

UserMessage userMsg = UserMessage.from(
    "Explain what a List is in Java"
);

String response = chatModel.chat(systemMsg, userMsg);
```

<img src="../../../translated_images/message-types.93e0779798a17c9d.pt.png" alt="Message Types Architecture" width="800"/>

*SystemMessage fornece contexto persistente enquanto UserMessages cont√™m pedidos individuais*

**MessageWindowChatMemory para Multi-Turno** ‚Äì Para o padr√£o de conversa multi-turno, reutilizamos `MessageWindowChatMemory` do M√≥dulo 01. Cada sess√£o tem a sua pr√≥pria inst√¢ncia de mem√≥ria armazenada num `Map<String, ChatMemory>`, permitindo m√∫ltiplas conversas concorrentes sem mistura de contexto.

**Templates de Prompt** ‚Äì O foco real aqui √© engenharia de prompts, n√£o novas APIs LangChain4j. Cada padr√£o (baixa vontade, alta vontade, execu√ß√£o de tarefas, etc.) usa o mesmo m√©todo `chatModel.chat(prompt)` mas com strings de prompt cuidadosamente estruturadas. As tags XML, instru√ß√µes e formata√ß√£o fazem parte do texto do prompt, n√£o s√£o funcionalidades LangChain4j.

**Controlo de Racioc√≠nio** ‚Äì O esfor√ßo de racioc√≠nio do GPT-5 √© controlado atrav√©s de instru√ß√µes no prompt como "m√°ximo 2 passos de racioc√≠nio" ou "explorar minuciosamente". Estas s√£o t√©cnicas de engenharia de prompts, n√£o configura√ß√µes LangChain4j. A biblioteca simplesmente entrega os seus prompts ao modelo.

A principal conclus√£o: LangChain4j fornece a infraestrutura (liga√ß√£o ao modelo via [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java), mem√≥ria, gest√£o de mensagens via [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)), enquanto este m√≥dulo ensina como criar prompts eficazes dentro dessa infraestrutura.

## Os Padr√µes Principais

Nem todos os problemas precisam da mesma abordagem. Algumas perguntas precisam de respostas r√°pidas, outras de pensamento profundo. Algumas precisam de racioc√≠nio vis√≠vel, outras s√≥ dos resultados. Este m√≥dulo cobre oito padr√µes de prompting ‚Äî cada um otimizado para diferentes cen√°rios. Vai experimentar todos para aprender quando cada abordagem funciona melhor.

<img src="../../../translated_images/eight-patterns.fa1ebfdf16f71e9a.pt.png" alt="Eight Prompting Patterns" width="800"/>

*Vis√£o geral dos oito padr√µes de engenharia de prompts e seus casos de uso*

<img src="../../../translated_images/reasoning-effort.db4a3ba5b8e392c1.pt.png" alt="Reasoning Effort Comparison" width="800"/>

*Baixa vontade (r√°pido, direto) vs Alta vontade (minucioso, explorat√≥rio) abordagens de racioc√≠nio*

**Baixa Vontade (R√°pido & Focado)** ‚Äì Para perguntas simples onde quer respostas r√°pidas e diretas. O modelo faz racioc√≠nio m√≠nimo ‚Äî m√°ximo 2 passos. Use para c√°lculos, consultas ou perguntas diretas.

```java
String prompt = """
    <reasoning_effort>low</reasoning_effort>
    <instruction>maximum 2 reasoning steps</instruction>
    
    What is 15% of 200?
    """;

String response = chatModel.chat(prompt);
```

> üí° **Explore com GitHub Copilot:** Abra [`Gpt5PromptService.java`](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java) e pergunte:
> - "Qual √© a diferen√ßa entre os padr√µes de prompting de baixa vontade e alta vontade?"
> - "Como √© que as tags XML nos prompts ajudam a estruturar a resposta da IA?"
> - "Quando devo usar padr√µes de auto-reflex√£o vs instru√ß√£o direta?"

**Alta Vontade (Profundo & Minucioso)** ‚Äì Para problemas complexos onde quer an√°lise abrangente. O modelo explora minuciosamente e mostra racioc√≠nio detalhado. Use para design de sistemas, decis√µes de arquitetura ou pesquisa complexa.

```java
String prompt = """
    <reasoning_effort>high</reasoning_effort>
    <instruction>explore thoroughly, show detailed reasoning</instruction>
    
    Design a caching strategy for a high-traffic REST API.
    """;

String response = chatModel.chat(prompt);
```

**Execu√ß√£o de Tarefas (Progresso Passo a Passo)** ‚Äì Para fluxos de trabalho multi-etapas. O modelo fornece um plano inicial, narra cada passo enquanto trabalha, depois d√° um resumo. Use para migra√ß√µes, implementa√ß√µes ou qualquer processo multi-etapas.

```java
String prompt = """
    <task>Create a REST endpoint for user registration</task>
    <preamble>Provide an upfront plan</preamble>
    <narration>Narrate each step as you work</narration>
    <summary>Summarize what was accomplished</summary>
    """;

String response = chatModel.chat(prompt);
```

O prompting Chain-of-Thought pede explicitamente ao modelo para mostrar o seu processo de racioc√≠nio, melhorando a precis√£o para tarefas complexas. A decomposi√ß√£o passo a passo ajuda tanto humanos como IA a entender a l√≥gica.

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Pergunte sobre este padr√£o:
> - "Como adaptaria o padr√£o de execu√ß√£o de tarefas para opera√ß√µes de longa dura√ß√£o?"
> - "Quais s√£o as melhores pr√°ticas para estruturar pre√¢mbulos de ferramentas em aplica√ß√µes de produ√ß√£o?"
> - "Como posso capturar e mostrar atualiza√ß√µes de progresso interm√©dias numa interface?"

<img src="../../../translated_images/task-execution-pattern.9da3967750ab5c1e.pt.png" alt="Task Execution Pattern" width="800"/>

*Fluxo Planear ‚Üí Executar ‚Üí Resumir para tarefas multi-etapas*

**C√≥digo Auto-Reflexivo** ‚Äì Para gerar c√≥digo de qualidade de produ√ß√£o. O modelo gera c√≥digo, verifica-o contra crit√©rios de qualidade e melhora-o iterativamente. Use quando construir novas funcionalidades ou servi√ßos.

```java
String prompt = """
    <task>Create an email validation service</task>
    <quality_criteria>
    - Correct logic and error handling
    - Best practices (clean code, proper naming)
    - Performance optimization
    - Security considerations
    </quality_criteria>
    <instruction>Generate code, evaluate against criteria, improve iteratively</instruction>
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/self-reflection-cycle.6f71101ca0bd28cc.pt.png" alt="Self-Reflection Cycle" width="800"/>

*Ciclo de melhoria iterativa ‚Äì gerar, avaliar, identificar problemas, melhorar, repetir*

**An√°lise Estruturada** ‚Äì Para avalia√ß√£o consistente. O modelo rev√™ c√≥digo usando uma estrutura fixa (corre√ß√£o, pr√°ticas, desempenho, seguran√ßa). Use para revis√µes de c√≥digo ou avalia√ß√µes de qualidade.

```java
String prompt = """
    <code>
    public List getUsers() {
        return database.query("SELECT * FROM users");
    }
    </code>
    
    <framework>
    Evaluate using these categories:
    1. Correctness - Logic and functionality
    2. Best Practices - Code quality
    3. Performance - Efficiency concerns
    4. Security - Vulnerabilities
    </framework>
    """;

String response = chatModel.chat(prompt);
```

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Pergunte sobre an√°lise estruturada:
> - "Como posso personalizar a estrutura de an√°lise para diferentes tipos de revis√µes de c√≥digo?"
> - "Qual √© a melhor forma de analisar e atuar sobre sa√≠da estruturada programaticamente?"
> - "Como garantir n√≠veis de severidade consistentes em diferentes sess√µes de revis√£o?"

<img src="../../../translated_images/structured-analysis-pattern.0af3b690b60cf2d6.pt.png" alt="Structured Analysis Pattern" width="800"/>

*Estrutura de quatro categorias para revis√µes de c√≥digo consistentes com n√≠veis de severidade*

**Chat Multi-Turno** ‚Äì Para conversas que precisam de contexto. O modelo lembra mensagens anteriores e constr√≥i sobre elas. Use para sess√µes de ajuda interativas ou Q&A complexos.

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("What is Spring Boot?"));
AiMessage aiMessage1 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage1);

memory.add(UserMessage.from("Show me an example"));
AiMessage aiMessage2 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage2);
```

<img src="../../../translated_images/context-memory.dff30ad9fa78832a.pt.png" alt="Context Memory" width="800"/>

*Como o contexto da conversa se acumula ao longo de m√∫ltiplos turnos at√© atingir o limite de tokens*

**Racioc√≠nio Passo a Passo** ‚Äì Para problemas que requerem l√≥gica vis√≠vel. O modelo mostra racioc√≠nio expl√≠cito para cada passo. Use para problemas matem√°ticos, puzzles l√≥gicos ou quando precisa entender o processo de pensamento.

```java
String prompt = """
    <instruction>Show your reasoning step-by-step</instruction>
    
    If a train travels 120 km in 2 hours, then stops for 30 minutes,
    then travels another 90 km in 1.5 hours, what is the average speed
    for the entire journey including the stop?
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/step-by-step-pattern.a99ea4ca1c48578c.pt.png" alt="Step-by-Step Pattern" width="800"/>

*Decompor problemas em passos l√≥gicos expl√≠citos*

**Sa√≠da Constrangida** ‚Äì Para respostas com requisitos espec√≠ficos de formato. O modelo segue estritamente regras de formato e comprimento. Use para resumos ou quando precisa de estrutura de sa√≠da precisa.

```java
String prompt = """
    <constraints>
    - Exactly 100 words
    - Bullet point format
    - Technical terms only
    </constraints>
    
    Summarize the key concepts of machine learning.
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/constrained-output-pattern.0ce39a682a6795c2.pt.png" alt="Constrained Output Pattern" width="800"/>

*Impor requisitos espec√≠ficos de formato, comprimento e estrutura*

## Usar Recursos Azure Existentes

**Verificar implementa√ß√£o:**

Assegure que o ficheiro `.env` existe na diretoria raiz com credenciais Azure (criado durante o M√≥dulo 01):
```bash
cat ../.env  # Deve mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Iniciar a aplica√ß√£o:**

> **Nota:** Se j√° iniciou todas as aplica√ß√µes usando `./start-all.sh` do M√≥dulo 01, este m√≥dulo j√° est√° a correr na porta 8083. Pode saltar os comandos de arranque abaixo e ir diretamente para http://localhost:8083.

**Op√ß√£o 1: Usar o Spring Boot Dashboard (Recomendado para utilizadores VS Code)**

O contentor de desenvolvimento inclui a extens√£o Spring Boot Dashboard, que fornece uma interface visual para gerir todas as aplica√ß√µes Spring Boot. Pode encontr√°-la na Barra de Atividades √† esquerda do VS Code (procure o √≠cone Spring Boot).

No Spring Boot Dashboard, pode:
- Ver todas as aplica√ß√µes Spring Boot dispon√≠veis no workspace
- Iniciar/parar aplica√ß√µes com um clique
- Ver logs da aplica√ß√£o em tempo real
- Monitorizar o estado da aplica√ß√£o

Basta clicar no bot√£o de play ao lado de "prompt-engineering" para iniciar este m√≥dulo, ou iniciar todos os m√≥dulos de uma vez.

<img src="../../../translated_images/dashboard.da2c2130c904aaf0.pt.png" alt="Spring Boot Dashboard" width="400"/>

**Op√ß√£o 2: Usar scripts shell**

Inicie todas as aplica√ß√µes web (m√≥dulos 01-04):

**Bash:**
```bash
cd ..  # A partir do diret√≥rio raiz
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # A partir do diret√≥rio raiz
.\start-all.ps1
```

Ou inicie apenas este m√≥dulo:

**Bash:**
```bash
cd 02-prompt-engineering
./start.sh
```

**PowerShell:**
```powershell
cd 02-prompt-engineering
.\start.ps1
```

Ambos os scripts carregam automaticamente as vari√°veis de ambiente do ficheiro `.env` da raiz e constroem os JARs se n√£o existirem.

> **Nota:** Se preferir construir todos os m√≥dulos manualmente antes de iniciar:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

Abra http://localhost:8083 no seu navegador.

**Para parar:**

**Bash:**
```bash
./stop.sh  # Apenas este m√≥dulo
# Ou
cd .. && ./stop-all.sh  # Todos os m√≥dulos
```

**PowerShell:**
```powershell
.\stop.ps1  # Apenas este m√≥dulo
# Ou
cd ..; .\stop-all.ps1  # Todos os m√≥dulos
```

## Capturas de Ecr√£ da Aplica√ß√£o

<img src="../../../translated_images/dashboard-home.5444dbda4bc1f79d.pt.png" alt="Dashboard Home" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/>

*O dashboard principal mostrando os 8 padr√µes de engenharia de prompts com as suas caracter√≠sticas e casos de uso*

## Explorar os Padr√µes

A interface web permite experimentar diferentes estrat√©gias de prompting. Cada padr√£o resolve problemas diferentes ‚Äî experimente para ver quando cada abordagem se destaca.

### Baixa vs Alta Vontade

Fa√ßa uma pergunta simples como "Qual √© 15% de 200?" usando Baixa Vontade. Vai obter uma resposta instant√¢nea e direta. Agora pergunte algo complexo como "Desenha uma estrat√©gia de cache para uma API de alto tr√°fego" usando Alta Vontade. Veja como o modelo desacelera e fornece racioc√≠nio detalhado. Mesmo modelo, mesma estrutura de pergunta ‚Äî mas o prompt diz-lhe quanto deve pensar.

<img src="../../../translated_images/low-eagerness-demo.898894591fb23aa0.pt.png" alt="Low Eagerness Demo" width="800"/>
*C√°lculo r√°pido com racioc√≠nio m√≠nimo*

<img src="../../../translated_images/high-eagerness-demo.4ac93e7786c5a376.pt.png" alt="Demonstra√ß√£o de Alta Disposi√ß√£o" width="800"/>

*Estrat√©gia abrangente de cache (2,8MB)*

### Execu√ß√£o de Tarefas (Pre√¢mbulos de Ferramentas)

Fluxos de trabalho em m√∫ltiplas etapas beneficiam-se de planeamento pr√©vio e narra√ß√£o do progresso. O modelo descreve o que vai fazer, narra cada passo e depois resume os resultados.

<img src="../../../translated_images/tool-preambles-demo.3ca4881e417f2e28.pt.png" alt="Demonstra√ß√£o de Execu√ß√£o de Tarefas" width="800"/>

*Cria√ß√£o de um endpoint REST com narra√ß√£o passo a passo (3,9MB)*

### C√≥digo Auto-Reflexivo

Experimente "Criar um servi√ßo de valida√ß√£o de email". Em vez de apenas gerar c√≥digo e parar, o modelo gera, avalia segundo crit√©rios de qualidade, identifica fraquezas e melhora. Ver√° que itera at√© o c√≥digo cumprir os padr√µes de produ√ß√£o.

<img src="../../../translated_images/self-reflecting-code-demo.851ee05c988e743f.pt.png" alt="Demonstra√ß√£o de C√≥digo Auto-Reflexivo" width="800"/>

*Servi√ßo completo de valida√ß√£o de email (5,2MB)*

### An√°lise Estruturada

Revis√µes de c√≥digo precisam de quadros de avalia√ß√£o consistentes. O modelo analisa o c√≥digo usando categorias fixas (corre√ß√£o, pr√°ticas, desempenho, seguran√ßa) com n√≠veis de severidade.

<img src="../../../translated_images/structured-analysis-demo.9ef892194cd23bc8.pt.png" alt="Demonstra√ß√£o de An√°lise Estruturada" width="800"/>

*Revis√£o de c√≥digo baseada em framework*

### Chat Multi-Turno

Pergunte "O que √© Spring Boot?" e depois imediatamente "Mostra-me um exemplo". O modelo lembra-se da sua primeira pergunta e d√°-lhe um exemplo espec√≠fico de Spring Boot. Sem mem√≥ria, essa segunda pergunta seria demasiado vaga.

<img src="../../../translated_images/multi-turn-chat-demo.0d2d9b9a86a12b4b.pt.png" alt="Demonstra√ß√£o de Chat Multi-Turno" width="800"/>

*Preserva√ß√£o do contexto entre perguntas*

### Racioc√≠nio Passo a Passo

Escolha um problema de matem√°tica e experimente tanto com Racioc√≠nio Passo a Passo como com Baixa Disposi√ß√£o. Baixa disposi√ß√£o d√°-lhe apenas a resposta - r√°pido mas opaco. Passo a passo mostra-lhe cada c√°lculo e decis√£o.

<img src="../../../translated_images/step-by-step-reasoning-demo.12139513356faecd.pt.png" alt="Demonstra√ß√£o de Racioc√≠nio Passo a Passo" width="800"/>

*Problema matem√°tico com passos expl√≠citos*

### Sa√≠da Constrangida

Quando precisa de formatos espec√≠ficos ou contagem de palavras, este padr√£o imp√µe estrita conformidade. Experimente gerar um resumo com exatamente 100 palavras em formato de pontos.

<img src="../../../translated_images/constrained-output-demo.567cc45b75da1633.pt.png" alt="Demonstra√ß√£o de Sa√≠da Constrangida" width="800"/>

*Resumo de machine learning com controlo de formato*

## O Que Est√° Realmente a Aprender

**O Esfor√ßo de Racioc√≠nio Muda Tudo**

O GPT-5 permite controlar o esfor√ßo computacional atrav√©s dos seus prompts. Baixo esfor√ßo significa respostas r√°pidas com explora√ß√£o m√≠nima. Alto esfor√ßo significa que o modelo demora a pensar profundamente. Est√° a aprender a ajustar o esfor√ßo √† complexidade da tarefa - n√£o perca tempo com perguntas simples, mas tamb√©m n√£o apresse decis√µes complexas.

**A Estrutura Guia o Comportamento**

Reparou nas tags XML nos prompts? N√£o s√£o decorativas. Os modelos seguem instru√ß√µes estruturadas de forma mais fi√°vel do que texto livre. Quando precisa de processos em m√∫ltiplas etapas ou l√≥gica complexa, a estrutura ajuda o modelo a saber onde est√° e o que vem a seguir.

<img src="../../../translated_images/prompt-structure.a77763d63f4e2f89.pt.png" alt="Estrutura do Prompt" width="800"/>

*Anatomia de um prompt bem estruturado com sec√ß√µes claras e organiza√ß√£o ao estilo XML*

**Qualidade Atrav√©s da Autoavalia√ß√£o**

Os padr√µes auto-reflexivos funcionam ao tornar expl√≠citos os crit√©rios de qualidade. Em vez de esperar que o modelo "fa√ßa bem", diz-lhe exatamente o que "bem" significa: l√≥gica correta, tratamento de erros, desempenho, seguran√ßa. O modelo pode ent√£o avaliar a sua pr√≥pria sa√≠da e melhorar. Isto transforma a gera√ß√£o de c√≥digo de uma lotaria num processo.

**O Contexto √â Finito**

Conversas multi-turno funcionam incluindo o hist√≥rico de mensagens em cada pedido. Mas h√° um limite - cada modelo tem um m√°ximo de tokens. √Ä medida que as conversas crescem, precisar√° de estrat√©gias para manter o contexto relevante sem atingir esse limite. Este m√≥dulo mostra como a mem√≥ria funciona; mais tarde aprender√° quando resumir, quando esquecer e quando recuperar.

## Pr√≥ximos Passos

**Pr√≥ximo M√≥dulo:** [03-rag - RAG (Gera√ß√£o Aumentada por Recupera√ß√£o)](../03-rag/README.md)

---

**Navega√ß√£o:** [‚Üê Anterior: M√≥dulo 01 - Introdu√ß√£o](../01-introduction/README.md) | [Voltar ao In√≠cio](../README.md) | [Seguinte: M√≥dulo 03 - RAG ‚Üí](../03-rag/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, por favor tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->