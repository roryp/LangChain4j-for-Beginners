<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "81d087662fb3dd7b7124bce1a9c9ec86",
  "translation_date": "2026-01-05T23:45:19+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "da"
}
-->
# Modul 03: RAG (Retrieval-Augmented Generation)

## Indholdsfortegnelse

- [Hvad du vil l√¶re](../../../03-rag)
- [Foruds√¶tninger](../../../03-rag)
- [Forst√•else af RAG](../../../03-rag)
- [S√•dan fungerer det](../../../03-rag)
  - [Dokumentbehandling](../../../03-rag)
  - [Oprettelse af embeddings](../../../03-rag)
  - [Semantisk s√∏gning](../../../03-rag)
  - [Svar generering](../../../03-rag)
- [K√∏r applikationen](../../../03-rag)
- [Brug af applikationen](../../../03-rag)
  - [Upload et dokument](../../../03-rag)
  - [Stil sp√∏rgsm√•l](../../../03-rag)
  - [Tjek kildehenvisninger](../../../03-rag)
  - [Eksperiment√©r med sp√∏rgsm√•l](../../../03-rag)
- [N√∏glebegreber](../../../03-rag)
  - [Chunking strategi](../../../03-rag)
  - [Lighedsscores](../../../03-rag)
  - [In-memory lagring](../../../03-rag)
  - [H√•ndtering af kontekstvindue](../../../03-rag)
- [Hvorn√•r RAG er relevant](../../../03-rag)
- [N√¶ste skridt](../../../03-rag)

## Hvad du vil l√¶re

I de tidligere moduler har du l√¶rt, hvordan man f√∏rer samtaler med AI og strukturerer dine prompts effektivt. Men der er en grundl√¶ggende begr√¶nsning: sprogmodeller ved kun det, de l√¶rte under tr√¶ningen. De kan ikke besvare sp√∏rgsm√•l om din virksomheds politikker, din projekt-dokumentation eller nogen information, de ikke blev tr√¶net i.

RAG (Retrieval-Augmented Generation) l√∏ser dette problem. I stedet for at fors√∏ge at l√¶re modellen din information (hvilket er dyrt og upraktisk), giver du den mulighed for at s√∏ge i dine dokumenter. N√•r nogen stiller et sp√∏rgsm√•l, finder systemet relevant information og inkluderer det i prompten. Modellen svarer derefter baseret p√• den hentede kontekst.

T√¶nk p√• RAG som at give modellen et referencel√∏b. N√•r du stiller et sp√∏rgsm√•l, g√∏r systemet:

1. **Brugerforesp√∏rgsel** - Du stiller et sp√∏rgsm√•l  
2. **Embedding** - Konverterer dit sp√∏rgsm√•l til en vektor  
3. **Vektors√∏gning** - Finder lignende dokument-chunks  
4. **Kontekstsammenstilling** - Tilf√∏jer relevante chunks til prompten  
5. **Svar** - LLM genererer et svar baseret p√• konteksten  

Dette forankrer modellens svar i dine faktiske data i stedet for at stole p√• tr√¶ningsviden eller at finde p√• svar.

<img src="../../../translated_images/da/rag-architecture.ccb53b71a6ce407f.png" alt="RAG Architecture" width="800"/>

*RAG arbejdsproces - fra brugerforesp√∏rgsel til semantisk s√∏gning til kontekstuel svar-generering*

## Foruds√¶tninger

- Gennemf√∏rt Modul 01 (Azure OpenAI-ressourcer deployeret)  
- `.env` fil i rodmappen med Azure legitimationsoplysninger (oprettet af `azd up` i Modul 01)  

> **Note:** Hvis du ikke har gennemf√∏rt Modul 01, f√∏lg f√∏rst deployeringsvejledningen der.  

## S√•dan fungerer det

### Dokumentbehandling

[DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

N√•r du uploader et dokument, deler systemet det op i chunks ‚Äì mindre stykker, der passer komfortabelt i modellens kontekstvindue. Disse chunks overlapper lidt, s√• du ikke mister kontekst ved gr√¶nserne.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```
  
> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) og sp√∏rg:  
> - "Hvordan splitter LangChain4j dokumenter op i chunks, og hvorfor er overlap vigtigt?"  
> - "Hvad er den optimale chunk-st√∏rrelse for forskellige dokumenttyper, og hvorfor?"  
> - "Hvordan h√•ndterer jeg dokumenter p√• flere sprog eller med s√¶rlig formatering?"  

### Oprettelse af embeddings

[LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Hver chunk konverteres til en numerisk repr√¶sentation kaldet en embedding ‚Äì i praksis et matematisk fingeraftryk, der fanger tekstens betydning. Lignende tekst giver lignende embeddings.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```
  
<img src="../../../translated_images/da/vector-embeddings.2ef7bdddac79a327.png" alt="Vector Embeddings Space" width="800"/>

*Dokumenter repr√¶senteret som vektorer i embeddings-rum ‚Äì lignende indhold grupperes*

### Semantisk s√∏gning

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

N√•r du stiller et sp√∏rgsm√•l, bliver dit sp√∏rgsm√•l ogs√• til en embedding. Systemet sammenligner dit sp√∏rgsm√•l embedding med alle dokument-chunks embeddings. Det finder de chunks, der har den mest lignende betydning ‚Äì ikke bare matchende n√∏gleord, men reel semantisk lighed.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```
  
> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) og sp√∏rg:  
> - "Hvordan virker lighedss√∏gning med embeddings, og hvad bestemmer scoren?"  
> - "Hvilken lighedsterskel b√∏r jeg bruge, og hvordan p√•virker det resultater?"  
> - "Hvordan h√•ndterer jeg tilf√¶lde, hvor der ikke findes relevante dokumenter?"  

### Svar generering

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

De mest relevante chunks inkluderes i prompten til modellen. Modellen l√¶ser disse specifikke chunks og svarer p√• dit sp√∏rgsm√•l baseret p√• den information. Dette forhindrer hallucination ‚Äì modellen kan kun svare ud fra det, der er foran den.

## K√∏r applikationen

**Bekr√¶ft deployment:**

S√∏rg for at `.env` filen eksisterer i rodmappen med Azure-legitimationsoplysninger (oprettet under Modul 01):  
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**Start applikationen:**

> **Note:** Hvis du allerede har startet alle applikationer med `./start-all.sh` fra Modul 01, k√∏rer dette modul allerede p√• port 8081. Du kan springe startkommandoerne over nedenfor og g√• direkte til http://localhost:8081.

**Valgmulighed 1: Brug Spring Boot Dashboard (anbefalet til VS Code-brugere)**

Dev containeren inkluderer Spring Boot Dashboard-udvidelsen, som giver en visuel gr√¶nseflade til at styre alle Spring Boot-applikationer. Du finder den i aktivitetslinjen til venstre i VS Code (se efter Spring Boot-ikonet).

Fra Spring Boot Dashboard kan du:  
- Se alle tilg√¶ngelige Spring Boot-applikationer i workspace  
- Starte/stoppe applikationer med et enkelt klik  
- Se applikationslogfiler i realtid  
- Overv√•ge applikationens status  

Klik blot p√• play-knappen ved siden af "rag" for at starte dette modul, eller start alle moduler p√• en gang.

<img src="../../../translated_images/da/dashboard.fbe6e28bf4267ffe.png" alt="Spring Boot Dashboard" width="400"/>

**Valgmulighed 2: Brug shell-scripts**

Start alle webapplikationer (moduler 01-04):

**Bash:**  
```bash
cd ..  # Fra roddirectory
./start-all.sh
```
  
**PowerShell:**  
```powershell
cd ..  # Fra rodkatalog
.\start-all.ps1
```
  
Eller start kun dette modul:

**Bash:**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell:**  
```powershell
cd 03-rag
.\start.ps1
```
  
Begge scripts l√¶ser automatisk milj√∏variabler fra rodfilen `.env` og bygger JAR-filerne, hvis de ikke findes.

> **Note:** Hvis du foretr√¶kker at bygge alle moduler manuelt inden start:
>  
> **Bash:**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
> **PowerShell:**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
√Öbn http://localhost:8081 i din browser.

**For at stoppe:**

**Bash:**  
```bash
./stop.sh  # Kun denne modul
# Eller
cd .. && ./stop-all.sh  # Alle moduler
```
  
**PowerShell:**  
```powershell
.\stop.ps1  # Kun denne modul
# Eller
cd ..; .\stop-all.ps1  # Alle moduler
```


## Brug af applikationen

Applikationen tilbyder en webgr√¶nseflade til dokumentupload og sp√∏rgsm√•l.

<a href="images/rag-homepage.png"><img src="../../../translated_images/da/rag-homepage.d90eb5ce1b3caa94.png" alt="RAG Application Interface" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*RAG applikationsgr√¶nseflade ‚Äì upload dokumenter og stil sp√∏rgsm√•l*

### Upload et dokument

Start med at uploade et dokument ‚Äì TXT-filer fungerer bedst til test. En `sample-document.txt` er tilg√¶ngelig i denne mappe, som indeholder information om LangChain4j-funktioner, RAG-implementering og best practices ‚Äì perfekt til at teste systemet.

Systemet behandler dit dokument, opdeler det i chunks og opretter embeddings for hver chunk. Dette sker automatisk ved upload.

### Stil sp√∏rgsm√•l

Stil nu specifikke sp√∏rgsm√•l om dokumentets indhold. Pr√∏v noget faktuelt, som tydeligt st√•r i dokumentet. Systemet s√∏ger efter relevante chunks, inkluderer dem i prompten og genererer et svar.

### Tjek kildehenvisninger

Bem√¶rk, at hvert svar indeholder kildehenvisninger med lighedsscores. Disse scores (0 til 1) viser, hvor relevant hver chunk var for dit sp√∏rgsm√•l. H√∏jere scorer betyder bedre match. Det giver dig mulighed for at verificere svaret mod kildematerialet.

<a href="images/rag-query-results.png"><img src="../../../translated_images/da/rag-query-results.6d69fcec5397f355.png" alt="RAG Query Results" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Sp√∏rgeresultater der viser svar med kildehenvisninger og relevansscores*

### Eksperiment√©r med sp√∏rgsm√•l

Pr√∏v forskellige typer sp√∏rgsm√•l:  
- Specifikke fakta: "Hvad er hovedemnet?"  
- Sammenligninger: "Hvad er forskellen mellem X og Y?"  
- Opsummeringer: "Opsummer n√∏glepunkterne om Z"  

Se hvordan relevansscorerne √¶ndrer sig baseret p√•, hvor godt dit sp√∏rgsm√•l matcher dokumentindholdet.

## N√∏glebegreber

### Chunking strategi

Dokumenter deles op i 300-token chunks med 30 tokens overlap. Denne balance sikrer, at hver chunk har nok kontekst til at v√¶re meningsfuld, samtidig med at den er lille nok til at inkludere flere chunks i en prompt.

### Lighedsscores

Scores varierer fra 0 til 1:  
- 0.7-1.0: Meget relevant, pr√¶cist match  
- 0.5-0.7: Relevant, god kontekst  
- Under 0.5: Filtreret fra, for forskellig  

Systemet henter kun chunks over minimumstersklen for at sikre kvalitet.

### In-memory lagring

Dette modul bruger in-memory lagring for enkelhedens skyld. N√•r du genstarter applikationen, mistes uploadede dokumenter. Produktionssystemer bruger peristente vektordatabaser som Qdrant eller Azure AI Search.

### H√•ndtering af kontekstvindue

Hver model har et maksimalt kontekstvindue. Du kan ikke inkludere alle chunks fra et stort dokument. Systemet henter de top N mest relevante chunks (standard 5) for at holde sig inden for gr√¶nserne, samtidig med at der gives nok kontekst til pr√¶cise svar.

## Hvorn√•r RAG er relevant

**Brug RAG n√•r:**  
- Du skal svare p√• sp√∏rgsm√•l om propriet√¶re dokumenter  
- Information √¶ndrer sig ofte (politikker, priser, specifikationer)  
- N√∏jagtighed kr√¶ver kildehenvisning  
- Indholdet er for stort til at passe i √©n enkelt prompt  
- Du har brug for verificerbare, forankrede svar  

**Brug ikke RAG n√•r:**  
- Sp√∏rgsm√•l kr√¶ver generel viden, som modellen allerede har  
- Real-time data er n√∏dvendig (RAG arbejder p√• uploadede dokumenter)  
- Indholdet er lille nok til direkte inklusion i prompts  

## N√¶ste skridt

**N√¶ste modul:** [04-tools - AI Agenter med v√¶rkt√∏jer](../04-tools/README.md)

---

**Navigation:** [‚Üê Forrige: Modul 02 - Prompt Engineering](../02-prompt-engineering/README.md) | [Tilbage til Hoved](../README.md) | [N√¶ste: Modul 04 - V√¶rkt√∏jer ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritiske oplysninger anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for eventuelle misforst√•elser eller fejltolkninger som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->