<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "22b5d7c8d7585325e38b37fd29eafe25",
  "translation_date": "2026-01-05T23:43:55+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "da"
}
-->
# Modul 00: Kom godt i gang

## Indholdsfortegnelse

- [Introduktion](../../../00-quick-start)
- [Hvad er LangChain4j?](../../../00-quick-start)
- [LangChain4j-afh√¶ngigheder](../../../00-quick-start)
- [Foruds√¶tninger](../../../00-quick-start)
- [Ops√¶tning](../../../00-quick-start)
  - [1. Hent dit GitHub-token](../../../00-quick-start)
  - [2. Angiv dit token](../../../00-quick-start)
- [K√∏r eksemplerne](../../../00-quick-start)
  - [1. Grundl√¶ggende chat](../../../00-quick-start)
  - [2. Prompt-m√∏nstre](../../../00-quick-start)
  - [3. Funktionskald](../../../00-quick-start)
  - [4. Dokument Q&A (RAG)](../../../00-quick-start)
  - [5. Ansvarlig AI](../../../00-quick-start)
- [Hvad hvert eksempel viser](../../../00-quick-start)
- [N√¶ste skridt](../../../00-quick-start)
- [Fejlfinding](../../../00-quick-start)

## Introduktion

Denne hurtigstart er designet til at f√• dig i gang med LangChain4j s√• hurtigt som muligt. Den d√¶kker det absolutte grundlag for at bygge AI-applikationer med LangChain4j og GitHub Models. I de n√¶ste moduler vil du bruge Azure OpenAI med LangChain4j til at bygge mere avancerede applikationer.

## Hvad er LangChain4j?

LangChain4j er et Java-bibliotek, der forenkler opbygningen af AI-drevne applikationer. I stedet for at h√•ndtere HTTP-klienter og JSON-parsing arbejder du med rene Java-API'er.

"Chain" i LangChain refererer til at k√¶de flere komponenter sammen - du kan k√¶de et prompt til en model til en parser, eller k√¶de flere AI-kald sammen, hvor et output f√∏der n√¶ste input. Denne hurtigstart fokuserer p√• det fundamentale f√∏r man udforsker mere komplekse k√¶der.

<img src="../../../translated_images/da/langchain-concept.ad1fe6cf063515e1.webp" alt="LangChain4j Chaining Concept" width="800"/>

*K√¶dning af komponenter i LangChain4j - byggeklodser forbindes for at skabe kraftfulde AI-arbejdsgange*

Vi bruger tre kernekomponenter:

**ChatLanguageModel** - Interfacet for AI-model-interaktioner. Kald `model.chat("prompt")` og f√• en respons som tekststreng. Vi bruger `OpenAiOfficialChatModel` som virker med OpenAI-kompatible endpoints som GitHub Models.

**AiServices** - Opretter typesikre AI-serviceinterfaces. Definer metoder, annoter dem med `@Tool` og LangChain4j h√•ndterer orkestreringen. AI kalder automatisk dine Java-metoder n√•r det er n√∏dvendigt.

**MessageWindowChatMemory** - Vedligeholder samtalehistorik. Uden denne er hver anmodning uafh√¶ngig. Med den husker AI tidligere beskeder og opretholder kontekst over flere runder.

<img src="../../../translated_images/da/architecture.eedc993a1c576839.webp" alt="LangChain4j Architecture" width="800"/>

*LangChain4j arkitektur - kernekomponenter samarbejder for at drive dine AI-applikationer*

## LangChain4j-afh√¶ngigheder

Denne hurtigstart bruger to Maven-afh√¶ngigheder i [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

`langchain4j-open-ai-official` modulet leverer `OpenAiOfficialChatModel` klassen, der forbinder til OpenAI-kompatible API'er. GitHub Models bruger samme API-format, s√• ingen speciel adapter er n√∏dvendig - peg blot base URL til `https://models.github.ai/inference`.

## Foruds√¶tninger

**Bruger du Dev Container?** Java og Maven er allerede installeret. Du beh√∏ver kun et GitHub Personal Access Token.

**Lokal udvikling:**
- Java 21+, Maven 3.9+
- GitHub Personal Access Token (instruktioner nedenfor)

> **Bem√¶rk:** Dette modul bruger `gpt-4.1-nano` fra GitHub Models. √Ündr ikke modelnavnet i koden - det er konfigureret til at arbejde med GitHubs tilg√¶ngelige modeller.

## Ops√¶tning

### 1. Hent dit GitHub-token

1. G√• til [GitHub Settings ‚Üí Personal Access Tokens](https://github.com/settings/personal-access-tokens)
2. Klik "Generate new token"
3. S√¶t et beskrivende navn (fx "LangChain4j Demo")
4. S√¶t udl√∏bstid (7 dage anbefalet)
5. Under "Account permissions", find "Models" og s√¶t til "Read-only"
6. Klik "Generate token"
7. Kopi√©r og gem dit token - du f√•r det ikke vist igen

### 2. Angiv dit token

**Valgmulighed 1: Brug af VS Code (anbefalet)**

Hvis du bruger VS Code, tilf√∏j dit token til `.env`-filen i projektets rodmappe:

Hvis `.env`-filen ikke findes, kopier `.env.example` til `.env` eller opret en ny `.env`-fil i projektets rodmappe.

**Eksempel p√• `.env` fil:**
```bash
# I /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Herefter kan du blot h√∏jreklikke p√• en demofil (fx `BasicChatDemo.java`) i Explorer og v√¶lge **"Run Java"** eller bruge launch-ops√¶tningerne fra Run and Debug-panelet.

**Valgmulighed 2: Brug terminal**

Indstil token som en milj√∏variabel:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## K√∏r eksemplerne

**Brug af VS Code:** H√∏jreklik blot p√• en demofil i Explorer og v√¶lg **"Run Java"**, eller brug launch-ops√¶tningerne fra Run and Debug-panelet (husk at have tilf√∏jet dit token til `.env` f√∏rst).

**Brug af Maven:** Alternativt kan du k√∏re fra kommandolinjen:

### 1. Grundl√¶ggende chat

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Prompt-m√∏nstre

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Viser zero-shot, few-shot, chain-of-thought og rollebaseret prompting.

### 3. Funktionskald

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

AI kalder automatisk dine Java-metoder n√•r det er n√∏dvendigt.

### 4. Dokument Q&A (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Stil sp√∏rgsm√•l om indholdet i `document.txt`.

### 5. Ansvarlig AI

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

Se hvordan AI-sikkerhedsfiltre blokerer skadeligt indhold.

## Hvad hvert eksempel viser

**Grundl√¶ggende chat** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Start her for at se LangChain4j i sin enkleste form. Du opretter en `OpenAiOfficialChatModel`, sender et prompt med `.chat()`, og f√•r et svar tilbage. Dette demonstrerer fundamentet: hvordan man initialiserer modeller med brugerdefinerede endpoints og API-n√∏gler. N√•r du forst√•r dette m√∏nster, bygger resten videre p√• det.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) og sp√∏rg:
> - "Hvordan skifter jeg fra GitHub Models til Azure OpenAI i denne kode?"
> - "Hvilke andre parametre kan jeg konfigurere i OpenAiOfficialChatModel.builder()?"
> - "Hvordan tilf√∏jer jeg streaming-respons i stedet for at vente p√• den komplette respons?"

**Prompt Engineering** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Nu hvor du ved, hvordan man taler med en model, lad os udforske hvad du siger til den. Denne demo bruger samme modelsetup, men viser fire forskellige prompt-m√∏nstre. Pr√∏v zero-shot prompts for direkte instruktioner, few-shot prompts som l√¶rer fra eksempler, chain-of-thought prompts som afsl√∏rer r√¶sonneringsskridt, og rollebaserede prompts som s√¶tter kontekst. Du vil se, hvordan den samme model giver dramatiske forskellige resultater baseret p√•, hvordan du formulerer din foresp√∏rgsel.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) og sp√∏rg:
> - "Hvad er forskellen p√• zero-shot og few-shot prompting, og hvorn√•r skal jeg bruge hver?"
> - "Hvordan p√•virker temperaturparameteren modellens svar?"
> - "Hvilke teknikker er der for at forhindre prompt-injektionsangreb i produktion?"
> - "Hvordan kan jeg lave genanvendelige PromptTemplate-objekter til almindelige m√∏nstre?"

**Integration af v√¶rkt√∏jer** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Her bliver LangChain4j kraftfuldt. Du bruger `AiServices` til at skabe en AI-assistent, der kan kalde dine Java-metoder. Annoter blot metoder med `@Tool("beskrivelse")` og LangChain4j h√•ndterer resten - AI beslutter automatisk hvorn√•r hvert v√¶rkt√∏j skal bruges baseret p√• brugerens foresp√∏rgsel. Dette demonstrerer funktionskald, en n√∏glemetode til at bygge AI der kan tage handlinger, ikke blot svare p√• sp√∏rgsm√•l.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) og sp√∏rg:
> - "Hvordan fungerer @Tool-annoteringen og hvad g√∏r LangChain4j med den bag scenen?"
> - "Kan AI kalde flere v√¶rkt√∏jer i r√¶kkef√∏lge for at l√∏se komplekse problemer?"
> - "Hvad sker der hvis et v√¶rkt√∏j kaster en undtagelse - hvordan h√•ndterer jeg fejl?"
> - "Hvordan integrerer jeg en rigtig API i stedet for dette lommeregner-eksempel?"

**Dokument Q&A (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Her ser du fundamentet for RAG (retrieval-augmented generation). I stedet for at stole p√• modellens tr√¶ningsdata, loader du indhold fra [`document.txt`](../../../00-quick-start/document.txt) og inkluderer det i prompten. AI svarer baseret p√• dit dokument, ikke p√• sin generelle viden. Dette er f√∏rste skridt til at bygge systemer, der kan arbejde med dine egne data.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Bem√¶rk:** Denne simple tilgang loader hele dokumentet ind i prompten. For store filer (>10KB) overskrides kontekstgr√¶nser. Modul 03 d√¶kker chunking og vektors√∏gning til produktions-RAG-systemer.

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) og sp√∏rg:
> - "Hvordan forhindrer RAG AI-hallucinationer sammenlignet med at bruge modellens tr√¶ningsdata?"
> - "Hvad er forskellen p√• denne simple tilgang og brug af vektor-embedding til opslag?"
> - "Hvordan skalerer jeg dette til at h√•ndtere flere dokumenter eller st√∏rre vidensbaser?"
> - "Hvad er bedste praksis for at strukturere prompten s√• AI kun bruger den givne kontekst?"

**Ansvarlig AI** - [ResponsibleAIDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java)

Byg AI-sikkerhed med forsvar i dybden. Denne demo viser to lag af beskyttelse, der arbejder sammen:

**Del 1: LangChain4j Input Guardrails** - Bloker farlige prompts f√∏r de n√•r LLM. Opret brugerdefinerede guardrails, der tjekker for forbudte n√∏gleord eller m√∏nstre. De k√∏rer i din kode, s√• de er hurtige og gratis.

```java
class DangerousContentGuardrail implements InputGuardrail {
    @Override
    public InputGuardrailResult validate(UserMessage userMessage) {
        String text = userMessage.singleText().toLowerCase();
        if (text.contains("explosives")) {
            return fatal("Blocked: contains prohibited keyword");
        }
        return success();
    }
}
```

**Del 2: Udbydersikkerhedsfiltre** - GitHub Models har indbyggede filtre, der fanger det dine guardrails m√•ske missede. Du vil se h√•rde blokeringer (HTTP 400-fejl) for alvorlige overtr√¶delser og bl√∏de afvisninger, hvor AI h√∏fligt declining.

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`ResponsibleAIDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java) og sp√∏rg:
> - "Hvad er InputGuardrail og hvordan laver jeg mine egne?"
> - "Hvad er forskellen p√• en h√•rd blokering og en bl√∏d afvisning?"
> - "Hvorfor bruge b√•de guardrails og udbyderfiltre sammen?"

## N√¶ste skridt

**N√¶ste modul:** [01-introduction - Kom godt i gang med LangChain4j og gpt-5 p√• Azure](../01-introduction/README.md)

---

**Navigation:** [‚Üê Tilbage til hoved](../README.md) | [N√¶ste: Modul 01 - Introduktion ‚Üí](../01-introduction/README.md)

---

## Fejlfinding

### F√∏rste gang Maven bygger

**Problem**: F√∏rste `mvn clean compile` eller `mvn package` tager lang tid (10-15 minutter)

**√Örsag**: Maven skal hente alle projektets afh√¶ngigheder (Spring Boot, LangChain4j-biblioteker, Azure SDK'er osv.) ved den f√∏rste build.

**L√∏sning**: Dette er normal adf√¶rd. Efterf√∏lgende builds bliver meget hurtigere, da afh√¶ngigheder caches lokalt. Download-tiden afh√¶nger af din netv√¶rkshastighed.

### PowerShell Maven-kommando syntaks

**Problem**: Maven-kommandoer fejler med fejl `Unknown lifecycle phase ".mainClass=..."`

**√Örsag**: PowerShell tolker `=` som en variabel-tildelingsoperator, hvilket bryder Maven property-syntaksen.
**L√∏sning**: Brug stop-parsing operatoren `--%` f√∏r Maven-kommandoen:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

`--%` operatoren fort√¶ller PowerShell at videregive alle resterende argumenter bogstaveligt til Maven uden fortolkning.

### Windows PowerShell Emoji-visning

**Problem**: AI-svar viser uforst√•elige tegn (f.eks. `????` eller `√¢??`) i stedet for emojis i PowerShell

**√Örsag**: PowerShells standardkodning underst√∏tter ikke UTF-8 emojis

**L√∏sning**: K√∏r denne kommando f√∏r du k√∏rer Java-applikationer:
```cmd
chcp 65001
```

Dette tvinger UTF-8 kodning i terminalen. Alternativt kan du bruge Windows Terminal, som har bedre Unicode-underst√∏ttelse.

### Fejlfinding af API-kald

**Problem**: Autentificeringsfejl, ratebegr√¶nsninger eller uventede svar fra AI-modellen

**L√∏sning**: Eksemplerne inkluderer `.logRequests(true)` og `.logResponses(true)` for at vise API-kald i konsollen. Dette hj√¶lper med at fejlfinde autentificeringsfejl, ratebegr√¶nsninger eller uventede svar. Fjern disse flags i produktion for at reducere log-st√∏j.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritiske oplysninger anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for eventuelle misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->