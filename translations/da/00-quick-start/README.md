<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "377b3e3e6f8d02965bf0fbbc9ccb45c5",
  "translation_date": "2025-12-13T14:59:58+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "da"
}
-->
# Module 00: Hurtig start

## Indholdsfortegnelse

- [Introduktion](../../../00-quick-start)
- [Hvad er LangChain4j?](../../../00-quick-start)
- [LangChain4j-afh√¶ngigheder](../../../00-quick-start)
- [Foruds√¶tninger](../../../00-quick-start)
- [Ops√¶tning](../../../00-quick-start)
  - [1. F√• dit GitHub-token](../../../00-quick-start)
  - [2. Indstil dit token](../../../00-quick-start)
- [K√∏r eksemplerne](../../../00-quick-start)
  - [1. Grundl√¶ggende chat](../../../00-quick-start)
  - [2. Prompt-m√∏nstre](../../../00-quick-start)
  - [3. Funktionskald](../../../00-quick-start)
  - [4. Dokument Q&A (RAG)](../../../00-quick-start)
- [Hvad hvert eksempel viser](../../../00-quick-start)
- [N√¶ste skridt](../../../00-quick-start)
- [Fejlfinding](../../../00-quick-start)

## Introduktion

Denne hurtigstart er designet til at f√• dig i gang med LangChain4j s√• hurtigt som muligt. Den d√¶kker det absolutte grundlag for at bygge AI-applikationer med LangChain4j og GitHub Models. I de n√¶ste moduler vil du bruge Azure OpenAI med LangChain4j til at bygge mere avancerede applikationer.

## Hvad er LangChain4j?

LangChain4j er et Java-bibliotek, der forenkler opbygningen af AI-drevne applikationer. I stedet for at h√•ndtere HTTP-klienter og JSON-parsing arbejder du med rene Java-API'er.

"Chain" i LangChain refererer til at k√¶de flere komponenter sammen ‚Äì du kan k√¶de en prompt til en model til en parser, eller k√¶de flere AI-kald sammen, hvor output fra det ene bliver input til det n√¶ste. Denne hurtigstart fokuserer p√• det grundl√¶ggende, f√∏r vi udforsker mere komplekse k√¶der.

<img src="../../../translated_images/langchain-concept.ad1fe6cf063515e1.da.png" alt="LangChain4j Chaining Concept" width="800"/>

*K√¶dning af komponenter i LangChain4j ‚Äì byggeklodser forbinder for at skabe kraftfulde AI-arbejdsgange*

Vi bruger tre kernekomponenter:

**ChatLanguageModel** ‚Äì Interfacet til AI-modelinteraktioner. Kald `model.chat("prompt")` og f√• en svarstreng. Vi bruger `OpenAiOfficialChatModel`, som fungerer med OpenAI-kompatible endpoints som GitHub Models.

**AiServices** ‚Äì Opretter typesikre AI-serviceinterfaces. Definer metoder, annoter dem med `@Tool`, og LangChain4j h√•ndterer orkestreringen. AI'en kalder automatisk dine Java-metoder, n√•r det er n√∏dvendigt.

**MessageWindowChatMemory** ‚Äì Vedligeholder samtalehistorik. Uden dette er hver foresp√∏rgsel uafh√¶ngig. Med det husker AI tidligere beskeder og bevarer kontekst over flere runder.

<img src="../../../translated_images/architecture.eedc993a1c576839.da.png" alt="LangChain4j Architecture" width="800"/>

*LangChain4j-arkitektur ‚Äì kernekomponenter arbejder sammen for at drive dine AI-applikationer*

## LangChain4j-afh√¶ngigheder

Denne hurtigstart bruger to Maven-afh√¶ngigheder i [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

Modulet `langchain4j-open-ai-official` leverer klassen `OpenAiOfficialChatModel`, som forbinder til OpenAI-kompatible API'er. GitHub Models bruger samme API-format, s√• der er ikke behov for en s√¶rlig adapter ‚Äì bare peg base-URL'en til `https://models.github.ai/inference`.

## Foruds√¶tninger

**Bruger du Dev Container?** Java og Maven er allerede installeret. Du skal kun bruge et GitHub Personal Access Token.

**Lokal udvikling:**
- Java 21+, Maven 3.9+
- GitHub Personal Access Token (instruktioner nedenfor)

> **Bem√¶rk:** Dette modul bruger `gpt-4.1-nano` fra GitHub Models. √Ündr ikke modelnavnet i koden ‚Äì det er konfigureret til at fungere med GitHubs tilg√¶ngelige modeller.

## Ops√¶tning

### 1. F√• dit GitHub-token

1. G√• til [GitHub Settings ‚Üí Personal Access Tokens](https://github.com/settings/personal-access-tokens)
2. Klik p√• "Generate new token"
3. S√¶t et beskrivende navn (f.eks. "LangChain4j Demo")
4. S√¶t udl√∏bstid (7 dage anbefales)
5. Under "Account permissions", find "Models" og s√¶t til "Read-only"
6. Klik p√• "Generate token"
7. Kopi√©r og gem dit token ‚Äì du f√•r det ikke vist igen

### 2. Indstil dit token

**Mulighed 1: Brug VS Code (anbefalet)**

Hvis du bruger VS Code, tilf√∏j dit token til `.env`-filen i projektets rodmappe:

Hvis `.env`-filen ikke findes, kopier `.env.example` til `.env` eller opret en ny `.env`-fil i projektets rodmappe.

**Eksempel p√• `.env`-fil:**
```bash
# I /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

S√• kan du blot h√∏jreklikke p√• en hvilken som helst demo-fil (f.eks. `BasicChatDemo.java`) i Explorer og v√¶lge **"Run Java"** eller bruge launch-konfigurationerne fra Run and Debug-panelet.

**Mulighed 2: Brug terminal**

S√¶t token som en milj√∏variabel:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## K√∏r eksemplerne

**Bruger du VS Code:** H√∏jreklik blot p√• en demo-fil i Explorer og v√¶lg **"Run Java"**, eller brug launch-konfigurationerne fra Run and Debug-panelet (s√∏rg for at have tilf√∏jet dit token til `.env`-filen f√∏rst).

**Bruger du Maven:** Alternativt kan du k√∏re fra kommandolinjen:

### 1. Grundl√¶ggende chat

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Prompt-m√∏nstre

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Viser zero-shot, few-shot, chain-of-thought og rollebaseret prompting.

### 3. Funktionskald

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

AI kalder automatisk dine Java-metoder, n√•r det er n√∏dvendigt.

### 4. Dokument Q&A (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Stil sp√∏rgsm√•l om indholdet i `document.txt`.

## Hvad hvert eksempel viser

**Grundl√¶ggende chat** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Start her for at se LangChain4j i sin enkleste form. Du opretter en `OpenAiOfficialChatModel`, sender en prompt med `.chat()`, og f√•r et svar tilbage. Dette demonstrerer fundamentet: hvordan man initialiserer modeller med brugerdefinerede endpoints og API-n√∏gler. N√•r du forst√•r dette m√∏nster, bygger alt andet videre p√• det.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) og sp√∏rg:
> - "Hvordan skifter jeg fra GitHub Models til Azure OpenAI i denne kode?"
> - "Hvilke andre parametre kan jeg konfigurere i OpenAiOfficialChatModel.builder()?"
> - "Hvordan tilf√∏jer jeg streaming-svar i stedet for at vente p√• det komplette svar?"

**Prompt Engineering** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Nu hvor du ved, hvordan du taler til en model, lad os udforske, hvad du siger til den. Denne demo bruger samme modelops√¶tning, men viser fire forskellige prompt-m√∏nstre. Pr√∏v zero-shot prompts for direkte instruktioner, few-shot prompts der l√¶rer fra eksempler, chain-of-thought prompts der afsl√∏rer r√¶sonneringstrin, og rollebaserede prompts der s√¶tter kontekst. Du vil se, hvordan den samme model giver dramatisk forskellige resultater baseret p√•, hvordan du formulerer din anmodning.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) og sp√∏rg:
> - "Hvad er forskellen mellem zero-shot og few-shot prompting, og hvorn√•r skal jeg bruge hver?"
> - "Hvordan p√•virker temperatur-parameteren modellens svar?"
> - "Hvilke teknikker findes der for at forhindre prompt injection-angreb i produktion?"
> - "Hvordan kan jeg oprette genanvendelige PromptTemplate-objekter til almindelige m√∏nstre?"

**Tool Integration** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Her bliver LangChain4j kraftfuld. Du bruger `AiServices` til at skabe en AI-assistent, der kan kalde dine Java-metoder. Bare annoter metoder med `@Tool("beskrivelse")`, og LangChain4j h√•ndterer resten ‚Äì AI'en beslutter automatisk, hvorn√•r den skal bruge hvert v√¶rkt√∏j baseret p√•, hvad brugeren sp√∏rger om. Dette demonstrerer funktionskald, en n√∏glemetode til at bygge AI, der kan handle, ikke bare svare p√• sp√∏rgsm√•l.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) og sp√∏rg:
> - "Hvordan fungerer @Tool-annotationen, og hvad g√∏r LangChain4j med den bag scenen?"
> - "Kan AI kalde flere v√¶rkt√∏jer i r√¶kkef√∏lge for at l√∏se komplekse problemer?"
> - "Hvad sker der, hvis et v√¶rkt√∏j kaster en undtagelse ‚Äì hvordan h√•ndterer jeg fejl?"
> - "Hvordan integrerer jeg en rigtig API i stedet for dette regneeksempel?"

**Dokument Q&A (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Her ser du fundamentet for RAG (retrieval-augmented generation). I stedet for at stole p√• modellens tr√¶ningsdata, indl√¶ser du indhold fra [`document.txt`](../../../00-quick-start/document.txt) og inkluderer det i prompten. AI svarer baseret p√• dit dokument, ikke sin generelle viden. Dette er det f√∏rste skridt mod at bygge systemer, der kan arbejde med dine egne data.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Bem√¶rk:** Denne simple tilgang indl√¶ser hele dokumentet i prompten. For store filer (>10KB) overskrider du kontekstgr√¶nser. Modul 03 d√¶kker chunking og vektors√∏gning til produktions-RAG-systemer.

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) og sp√∏rg:
> - "Hvordan forhindrer RAG AI-hallucinationer sammenlignet med at bruge modellens tr√¶ningsdata?"
> - "Hvad er forskellen mellem denne simple tilgang og brug af vektorindlejringer til opslag?"
> - "Hvordan skalerer jeg dette til at h√•ndtere flere dokumenter eller st√∏rre vidensbaser?"
> - "Hvad er bedste praksis for at strukturere prompten, s√• AI kun bruger den givne kontekst?"

## Fejlfinding

Eksemplerne inkluderer `.logRequests(true)` og `.logResponses(true)` for at vise API-kald i konsollen. Dette hj√¶lper med at fejlfinde autentificeringsfejl, ratebegr√¶nsninger eller uventede svar. Fjern disse flag i produktion for at reducere logst√∏j.

## N√¶ste skridt

**N√¶ste modul:** [01-introduction - Kom godt i gang med LangChain4j og gpt-5 p√• Azure](../01-introduction/README.md)

---

**Navigation:** [‚Üê Tilbage til hoved](../README.md) | [N√¶ste: Module 01 - Introduktion ‚Üí](../01-introduction/README.md)

---

## Fejlfinding

### F√∏rste Maven-build

**Problem:** F√∏rste `mvn clean compile` eller `mvn package` tager lang tid (10-15 minutter)

**√Örsag:** Maven skal downloade alle projektets afh√¶ngigheder (Spring Boot, LangChain4j-biblioteker, Azure SDK'er osv.) ved f√∏rste build.

**L√∏sning:** Dette er normal opf√∏rsel. Efterf√∏lgende builds bliver meget hurtigere, da afh√¶ngigheder caches lokalt. Download-tiden afh√¶nger af din netv√¶rkshastighed.

### PowerShell Maven-kommando-syntaks

**Problem:** Maven-kommandoer fejler med fejl `Unknown lifecycle phase ".mainClass=..."`

**√Örsag:** PowerShell fortolker `=` som en variabeltildelingsoperator, hvilket bryder Maven-egenskabssyntaksen.

**L√∏sning:** Brug stop-parsing-operatoren `--%` f√∏r Maven-kommandoen:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

`--%`-operatoren fort√¶ller PowerShell at sende alle resterende argumenter bogstaveligt til Maven uden fortolkning.

### Windows PowerShell Emoji-visning

**Problem:** AI-svar viser skraldetegn (f.eks. `????` eller `√¢??`) i stedet for emojis i PowerShell

**√Örsag:** PowerShells standardkodning underst√∏tter ikke UTF-8-emojis

**L√∏sning:** K√∏r denne kommando f√∏r du k√∏rer Java-applikationer:
```cmd
chcp 65001
```

Dette tvinger UTF-8-kodning i terminalen. Alternativt kan du bruge Windows Terminal, som har bedre Unicode-underst√∏ttelse.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets modersm√•l b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->