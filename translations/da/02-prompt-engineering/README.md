<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8d787826cad7e92bf5cdbd116b1e6116",
  "translation_date": "2025-12-13T16:11:50+00:00",
  "source_file": "02-prompt-engineering/README.md",
  "language_code": "da"
}
-->
# Modul 02: Prompt Engineering med GPT-5

## Indholdsfortegnelse

- [Hvad du vil l√¶re](../../../02-prompt-engineering)
- [Foruds√¶tninger](../../../02-prompt-engineering)
- [Forst√•else af Prompt Engineering](../../../02-prompt-engineering)
- [Hvordan dette bruger LangChain4j](../../../02-prompt-engineering)
- [Kerne-m√∏nstrene](../../../02-prompt-engineering)
- [Brug af eksisterende Azure-ressourcer](../../../02-prompt-engineering)
- [Applikationssk√¶rmbilleder](../../../02-prompt-engineering)
- [Udforskning af m√∏nstrene](../../../02-prompt-engineering)
  - [Lav vs H√∏j Iver](../../../02-prompt-engineering)
  - [Opgaveudf√∏relse (Tool Preambles)](../../../02-prompt-engineering)
  - [Selvreflekterende kode](../../../02-prompt-engineering)
  - [Struktureret analyse](../../../02-prompt-engineering)
  - [Multi-Turn Chat](../../../02-prompt-engineering)
  - [Trin-for-trin r√¶sonnering](../../../02-prompt-engineering)
  - [Begr√¶nset output](../../../02-prompt-engineering)
- [Hvad du virkelig l√¶rer](../../../02-prompt-engineering)
- [N√¶ste skridt](../../../02-prompt-engineering)

## Hvad du vil l√¶re

I det forrige modul s√• du, hvordan hukommelse muligg√∏r konversationel AI og brugte GitHub Models til grundl√¶ggende interaktioner. Nu vil vi fokusere p√•, hvordan du stiller sp√∏rgsm√•l ‚Äì selve prompts ‚Äì ved brug af Azure OpenAI's GPT-5. Den m√•de, du strukturerer dine prompts p√•, p√•virker dramatisk kvaliteten af de svar, du f√•r.

Vi bruger GPT-5, fordi det introducerer kontrol over r√¶sonnering ‚Äì du kan fort√¶lle modellen, hvor meget den skal t√¶nke, f√∏r den svarer. Det g√∏r forskellige prompting-strategier mere tydelige og hj√¶lper dig med at forst√•, hvorn√•r du skal bruge hver tilgang. Vi f√•r ogs√• fordel af Azures f√¶rre ratebegr√¶nsninger for GPT-5 sammenlignet med GitHub Models.

## Foruds√¶tninger

- Fuldf√∏rt Modul 01 (Azure OpenAI-ressourcer implementeret)
- `.env`-fil i rodmappen med Azure-legitimationsoplysninger (oprettet af `azd up` i Modul 01)

> **Bem√¶rk:** Hvis du ikke har fuldf√∏rt Modul 01, f√∏lg f√∏rst implementeringsinstruktionerne der.

## Forst√•else af Prompt Engineering

Prompt engineering handler om at designe inputtekst, der konsekvent giver dig de resultater, du har brug for. Det handler ikke kun om at stille sp√∏rgsm√•l ‚Äì det handler om at strukturere foresp√∏rgsler, s√• modellen pr√¶cist forst√•r, hvad du vil have, og hvordan det skal leveres.

T√¶nk p√• det som at give instruktioner til en kollega. "Fix fejlen" er vagt. "Fix null pointer exception i UserService.java linje 45 ved at tilf√∏je en null-check" er specifikt. Sprogmodeller fungerer p√• samme m√•de ‚Äì specificitet og struktur betyder noget.

## Hvordan dette bruger LangChain4j

Dette modul demonstrerer avancerede prompting-m√∏nstre ved brug af samme LangChain4j fundament som i tidligere moduler, med fokus p√• promptstruktur og r√¶sonneringskontrol.

<img src="../../../translated_images/da/langchain4j-flow.48e534666213010b.png" alt="LangChain4j Flow" width="800"/>

*Hvordan LangChain4j forbinder dine prompts til Azure OpenAI GPT-5*

**Afh√¶ngigheder** ‚Äì Modul 02 bruger f√∏lgende langchain4j-afh√¶ngigheder defineret i `pom.xml`:
```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**OpenAiOfficialChatModel Konfiguration** ‚Äì [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java)

Chatmodellen konfigureres manuelt som en Spring bean ved brug af OpenAI Official klienten, som underst√∏tter Azure OpenAI endpoints. Den v√¶sentlige forskel fra Modul 01 er, hvordan vi strukturerer de prompts, der sendes til `chatModel.chat()`, ikke selve modelops√¶tningen.

**System- og Brugermeddelelser** ‚Äì [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)

LangChain4j adskiller meddelelsestyper for klarhed. `SystemMessage` s√¶tter AI‚Äôens adf√¶rd og kontekst (som "Du er en kodeanmelder"), mens `UserMessage` indeholder den faktiske foresp√∏rgsel. Denne adskillelse lader dig opretholde konsistent AI-adf√¶rd p√• tv√¶rs af forskellige brugerforesp√∏rgsler.

```java
SystemMessage systemMsg = SystemMessage.from(
    "You are a helpful Java programming expert."
);

UserMessage userMsg = UserMessage.from(
    "Explain what a List is in Java"
);

String response = chatModel.chat(systemMsg, userMsg);
```

<img src="../../../translated_images/da/message-types.93e0779798a17c9d.png" alt="Message Types Architecture" width="800"/>

*SystemMessage giver vedvarende kontekst, mens UserMessages indeholder individuelle foresp√∏rgsler*

**MessageWindowChatMemory til Multi-Turn** ‚Äì Til multi-turn samtalem√∏nsteret genbruger vi `MessageWindowChatMemory` fra Modul 01. Hver session f√•r sin egen hukommelsesinstans gemt i et `Map<String, ChatMemory>`, hvilket tillader flere samtidige samtaler uden kontekstblanding.

**Promptskabeloner** ‚Äì Det egentlige fokus her er prompt engineering, ikke nye LangChain4j API‚Äôer. Hvert m√∏nster (lav iver, h√∏j iver, opgaveudf√∏relse osv.) bruger samme `chatModel.chat(prompt)` metode, men med omhyggeligt strukturerede promptstrenge. XML-tags, instruktioner og formatering er alle en del af promptteksten, ikke LangChain4j-funktioner.

**R√¶sonneringskontrol** ‚Äì GPT-5‚Äôs r√¶sonneringsindsats styres gennem promptinstruktioner som "maksimalt 2 r√¶sonneringstrin" eller "unders√∏g grundigt". Dette er prompt engineering-teknikker, ikke LangChain4j-konfigurationer. Biblioteket leverer blot dine prompts til modellen.

Det vigtigste: LangChain4j leverer infrastrukturen (modelforbindelse via [LangChainConfig.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/config/LangChainConfig.java), hukommelse, meddelelsesh√•ndtering via [Gpt5PromptService.java](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java)), mens dette modul l√¶rer dig, hvordan du udformer effektive prompts inden for denne infrastruktur.

## Kerne-m√∏nstrene

Ikke alle problemer kr√¶ver samme tilgang. Nogle sp√∏rgsm√•l har brug for hurtige svar, andre dyb t√¶nkning. Nogle har brug for synlig r√¶sonnering, andre kun resultater. Dette modul d√¶kker otte prompting-m√∏nstre ‚Äì hver optimeret til forskellige scenarier. Du vil eksperimentere med dem alle for at l√¶re, hvorn√•r hver tilgang fungerer bedst.

<img src="../../../translated_images/da/eight-patterns.fa1ebfdf16f71e9a.png" alt="Eight Prompting Patterns" width="800"/>

*Oversigt over de otte prompt engineering-m√∏nstre og deres anvendelsestilf√¶lde*

<img src="../../../translated_images/da/reasoning-effort.db4a3ba5b8e392c1.png" alt="Reasoning Effort Comparison" width="800"/>

*Lav iver (hurtig, direkte) vs H√∏j iver (grundig, udforskende) r√¶sonneringsmetoder*

**Lav Iver (Hurtig & Fokuseret)** ‚Äì Til simple sp√∏rgsm√•l, hvor du √∏nsker hurtige, direkte svar. Modellen laver minimal r√¶sonnering ‚Äì maksimalt 2 trin. Brug dette til beregninger, opslag eller ligetil sp√∏rgsm√•l.

```java
String prompt = """
    <reasoning_effort>low</reasoning_effort>
    <instruction>maximum 2 reasoning steps</instruction>
    
    What is 15% of 200?
    """;

String response = chatModel.chat(prompt);
```

> üí° **Udforsk med GitHub Copilot:** √Öbn [`Gpt5PromptService.java`](../../../02-prompt-engineering/src/main/java/com/example/langchain4j/prompts/service/Gpt5PromptService.java) og sp√∏rg:
> - "Hvad er forskellen mellem lav iver og h√∏j iver prompting-m√∏nstre?"
> - "Hvordan hj√¶lper XML-tags i prompts med at strukturere AI‚Äôens svar?"
> - "Hvorn√•r skal jeg bruge selvrefleksionsm√∏nstre vs direkte instruktion?"

**H√∏j Iver (Dyb & Grundig)** ‚Äì Til komplekse problemer, hvor du √∏nsker omfattende analyse. Modellen unders√∏ger grundigt og viser detaljeret r√¶sonnering. Brug dette til systemdesign, arkitekturvalg eller kompleks forskning.

```java
String prompt = """
    <reasoning_effort>high</reasoning_effort>
    <instruction>explore thoroughly, show detailed reasoning</instruction>
    
    Design a caching strategy for a high-traffic REST API.
    """;

String response = chatModel.chat(prompt);
```

**Opgaveudf√∏relse (Trin-for-trin fremgang)** ‚Äì Til arbejdsprocesser med flere trin. Modellen giver en plan p√• forh√•nd, fort√¶ller om hvert trin undervejs og giver derefter et resum√©. Brug dette til migrationer, implementeringer eller enhver flertrinsproces.

```java
String prompt = """
    <task>Create a REST endpoint for user registration</task>
    <preamble>Provide an upfront plan</preamble>
    <narration>Narrate each step as you work</narration>
    <summary>Summarize what was accomplished</summary>
    """;

String response = chatModel.chat(prompt);
```

Chain-of-Thought prompting beder eksplicit modellen om at vise sin r√¶sonneringsproces, hvilket forbedrer n√∏jagtigheden for komplekse opgaver. Trin-for-trin opdelingen hj√¶lper b√•de mennesker og AI med at forst√• logikken.

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** Sp√∏rg om dette m√∏nster:
> - "Hvordan tilpasser jeg opgaveudf√∏relsesm√∏nstret til langvarige operationer?"
> - "Hvad er bedste praksis for at strukturere tool preambles i produktionsapplikationer?"
> - "Hvordan kan jeg fange og vise mellemliggende fremdriftsopdateringer i en UI?"

<img src="../../../translated_images/da/task-execution-pattern.9da3967750ab5c1e.png" alt="Task Execution Pattern" width="800"/>

*Plan ‚Üí Udf√∏r ‚Üí Opsummer arbejdsproces til flertrinsopgaver*

**Selvreflekterende kode** ‚Äì Til generering af produktionsklar kode. Modellen genererer kode, tjekker den mod kvalitetskriterier og forbedrer den iterativt. Brug dette, n√•r du bygger nye funktioner eller services.

```java
String prompt = """
    <task>Create an email validation service</task>
    <quality_criteria>
    - Correct logic and error handling
    - Best practices (clean code, proper naming)
    - Performance optimization
    - Security considerations
    </quality_criteria>
    <instruction>Generate code, evaluate against criteria, improve iteratively</instruction>
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/da/self-reflection-cycle.6f71101ca0bd28cc.png" alt="Self-Reflection Cycle" width="800"/>

*Iterativ forbedringscyklus ‚Äì generer, evaluer, identificer problemer, forbedr, gentag*

**Struktureret analyse** ‚Äì Til konsistent evaluering. Modellen gennemg√•r kode ved hj√¶lp af en fast ramme (korrekthed, praksis, ydeevne, sikkerhed). Brug dette til kodegennemgange eller kvalitetsvurderinger.

```java
String prompt = """
    <code>
    public List getUsers() {
        return database.query("SELECT * FROM users");
    }
    </code>
    
    <framework>
    Evaluate using these categories:
    1. Correctness - Logic and functionality
    2. Best Practices - Code quality
    3. Performance - Efficiency concerns
    4. Security - Vulnerabilities
    </framework>
    """;

String response = chatModel.chat(prompt);
```

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** Sp√∏rg om struktureret analyse:
> - "Hvordan kan jeg tilpasse analyse-rammen til forskellige typer kodegennemgange?"
> - "Hvad er den bedste m√•de at parse og handle p√• struktureret output programmatisk?"
> - "Hvordan sikrer jeg konsistente alvorlighedsniveauer p√• tv√¶rs af forskellige gennemgangssessioner?"

<img src="../../../translated_images/da/structured-analysis-pattern.0af3b690b60cf2d6.png" alt="Structured Analysis Pattern" width="800"/>

*Fire-kategori rammev√¶rk til konsistente kodegennemgange med alvorlighedsniveauer*

**Multi-Turn Chat** ‚Äì Til samtaler, der kr√¶ver kontekst. Modellen husker tidligere beskeder og bygger videre p√• dem. Brug dette til interaktive hj√¶lpesessioner eller komplekse Q&A.

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("What is Spring Boot?"));
AiMessage aiMessage1 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage1);

memory.add(UserMessage.from("Show me an example"));
AiMessage aiMessage2 = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage2);
```

<img src="../../../translated_images/da/context-memory.dff30ad9fa78832a.png" alt="Context Memory" width="800"/>

*Hvordan samtalekontekst akkumuleres over flere omgange indtil token-gr√¶nsen n√•s*

**Trin-for-trin r√¶sonnering** ‚Äì Til problemer, der kr√¶ver synlig logik. Modellen viser eksplicit r√¶sonnering for hvert trin. Brug dette til matematikopgaver, logikpuslespil eller n√•r du skal forst√• t√¶nkeprocessen.

```java
String prompt = """
    <instruction>Show your reasoning step-by-step</instruction>
    
    If a train travels 120 km in 2 hours, then stops for 30 minutes,
    then travels another 90 km in 1.5 hours, what is the average speed
    for the entire journey including the stop?
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/da/step-by-step-pattern.a99ea4ca1c48578c.png" alt="Step-by-Step Pattern" width="800"/>

*Nedbrydning af problemer i eksplicitte logiske trin*

**Begr√¶nset output** ‚Äì Til svar med specifikke formatkrav. Modellen f√∏lger strengt format- og l√¶ngderegler. Brug dette til resum√©er eller n√•r du har brug for pr√¶cis outputstruktur.

```java
String prompt = """
    <constraints>
    - Exactly 100 words
    - Bullet point format
    - Technical terms only
    </constraints>
    
    Summarize the key concepts of machine learning.
    """;

String response = chatModel.chat(prompt);
```

<img src="../../../translated_images/da/constrained-output-pattern.0ce39a682a6795c2.png" alt="Constrained Output Pattern" width="800"/>

*H√•ndh√¶velse af specifikke format-, l√¶ngde- og strukturkrav*

## Brug af eksisterende Azure-ressourcer

**Bekr√¶ft implementering:**

S√∏rg for, at `.env`-filen findes i rodmappen med Azure-legitimationsoplysninger (oprettet under Modul 01):
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Start applikationen:**

> **Bem√¶rk:** Hvis du allerede har startet alle applikationer med `./start-all.sh` fra Modul 01, k√∏rer dette modul allerede p√• port 8083. Du kan springe startkommandoerne over nedenfor og g√• direkte til http://localhost:8083.

**Mulighed 1: Brug af Spring Boot Dashboard (anbefalet til VS Code-brugere)**

Dev-containeren inkluderer Spring Boot Dashboard-udvidelsen, som giver en visuel gr√¶nseflade til at administrere alle Spring Boot-applikationer. Du finder den i aktivitetsbj√¶lken til venstre i VS Code (se efter Spring Boot-ikonet).

Fra Spring Boot Dashboard kan du:
- Se alle tilg√¶ngelige Spring Boot-applikationer i arbejdsomr√•det
- Starte/stoppe applikationer med et enkelt klik
- Se applikationslogs i realtid
- Overv√•ge applikationsstatus

Klik blot p√• play-knappen ved siden af "prompt-engineering" for at starte dette modul, eller start alle moduler p√• √©n gang.

<img src="../../../translated_images/da/dashboard.da2c2130c904aaf0.png" alt="Spring Boot Dashboard" width="400"/>

**Mulighed 2: Brug af shell-scripts**

Start alle webapplikationer (moduler 01-04):

**Bash:**
```bash
cd ..  # Fra roddirectory
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Fra roddirectory
.\start-all.ps1
```

Eller start kun dette modul:

**Bash:**
```bash
cd 02-prompt-engineering
./start.sh
```

**PowerShell:**
```powershell
cd 02-prompt-engineering
.\start.ps1
```

Begge scripts indl√¶ser automatisk milj√∏variabler fra rodens `.env`-fil og bygger JAR-filerne, hvis de ikke findes.

> **Bem√¶rk:** Hvis du foretr√¶kker at bygge alle moduler manuelt f√∏r start:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

√Öbn http://localhost:8083 i din browser.

**For at stoppe:**

**Bash:**
```bash
./stop.sh  # Kun denne modul
# Eller
cd .. && ./stop-all.sh  # Alle moduler
```

**PowerShell:**
```powershell
.\stop.ps1  # Kun denne modul
# Eller
cd ..; .\stop-all.ps1  # Alle moduler
```

## Applikationssk√¶rmbilleder

<img src="../../../translated_images/da/dashboard-home.5444dbda4bc1f79d.png" alt="Dashboard Home" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/>

*Hoveddashboard, der viser alle 8 prompt engineering-m√∏nstre med deres karakteristika og anvendelsestilf√¶lde*

## Udforskning af m√∏nstrene

Webgr√¶nsefladen lader dig eksperimentere med forskellige prompting-strategier. Hvert m√∏nster l√∏ser forskellige problemer ‚Äì pr√∏v dem for at se, hvorn√•r hver tilgang fungerer bedst.

### Lav vs H√∏j Iver

Stil et simpelt sp√∏rgsm√•l som "Hvad er 15% af 200?" med Lav Iver. Du f√•r et √∏jeblikkeligt, direkte svar. Stil nu noget komplekst som "Design en caching-strategi for en h√∏jtrafikeret API" med H√∏j Iver. Se, hvordan modellen s√¶nker tempoet og giver detaljeret r√¶sonnering. Samme model, samme sp√∏rgsm√•lstruktur ‚Äì men prompten fort√¶ller, hvor meget den skal t√¶nke.

<img src="../../../translated_images/da/low-eagerness-demo.898894591fb23aa0.png" alt="Low Eagerness Demo" width="800"/>
*Hurtig beregning med minimal r√¶sonnering*

<img src="../../../translated_images/da/high-eagerness-demo.4ac93e7786c5a376.png" alt="High Eagerness Demo" width="800"/>

*Omfattende caching-strategi (2.8MB)*

### Opgaveudf√∏relse (V√¶rkt√∏jsintroduktioner)

Workflow med flere trin drager fordel af forudg√•ende planl√¶gning og l√∏bende fort√¶lling. Modellen skitserer, hvad den vil g√∏re, fort√¶ller om hvert trin og opsummerer derefter resultaterne.

<img src="../../../translated_images/da/tool-preambles-demo.3ca4881e417f2e28.png" alt="Task Execution Demo" width="800"/>

*Oprettelse af en REST-endpoint med trin-for-trin fort√¶lling (3.9MB)*

### Selvreflekterende kode

Pr√∏v "Opret en e-mail valideringstjeneste". I stedet for bare at generere kode og stoppe, genererer modellen, evaluerer mod kvalitetskriterier, identificerer svagheder og forbedrer. Du vil se den iterere, indtil koden opfylder produktionsstandarder.

<img src="../../../translated_images/da/self-reflecting-code-demo.851ee05c988e743f.png" alt="Self-Reflecting Code Demo" width="800"/>

*F√¶rdig e-mail valideringstjeneste (5.2MB)*

### Struktureret analyse

Kodegennemgange kr√¶ver konsistente evalueringsrammer. Modellen analyserer kode ved hj√¶lp af faste kategorier (korrekthed, praksis, ydeevne, sikkerhed) med alvorlighedsniveauer.

<img src="../../../translated_images/da/structured-analysis-demo.9ef892194cd23bc8.png" alt="Structured Analysis Demo" width="800"/>

*Framework-baseret kodegennemgang*

### Multi-turn chat

Sp√∏rg "Hvad er Spring Boot?" og f√∏lg straks op med "Vis mig et eksempel". Modellen husker dit f√∏rste sp√∏rgsm√•l og giver dig et specifikt Spring Boot-eksempel. Uden hukommelse ville det andet sp√∏rgsm√•l v√¶re for vagt.

<img src="../../../translated_images/da/multi-turn-chat-demo.0d2d9b9a86a12b4b.png" alt="Multi-Turn Chat Demo" width="800"/>

*Bevarelse af kontekst p√• tv√¶rs af sp√∏rgsm√•l*

### Trin-for-trin r√¶sonnering

V√¶lg et matematikproblem og pr√∏v det med b√•de Trin-for-trin r√¶sonnering og Lav iver. Lav iver giver dig bare svaret - hurtigt men uigennemsigtigt. Trin-for-trin viser dig hver beregning og beslutning.

<img src="../../../translated_images/da/step-by-step-reasoning-demo.12139513356faecd.png" alt="Step-by-Step Reasoning Demo" width="800"/>

*Matematikproblem med eksplicitte trin*

### Begr√¶nset output

N√•r du har brug for specifikke formater eller ordantal, h√•ndh√¶ver dette m√∏nster streng overholdelse. Pr√∏v at generere et resum√© med pr√¶cis 100 ord i punktform.

<img src="../../../translated_images/da/constrained-output-demo.567cc45b75da1633.png" alt="Constrained Output Demo" width="800"/>

*Maskinl√¶ringsresum√© med formatkontrol*

## Hvad du virkelig l√¶rer

**R√¶sonneringsindsats √¶ndrer alt**

GPT-5 lader dig styre beregningsindsatsen gennem dine prompts. Lav indsats betyder hurtige svar med minimal udforskning. H√∏j indsats betyder, at modellen tager sig tid til at t√¶nke dybt. Du l√¶rer at matche indsats med opgavens kompleksitet - spild ikke tid p√• simple sp√∏rgsm√•l, men skynd dig heller ikke med komplekse beslutninger.

**Struktur styrer adf√¶rd**

L√¶g m√¶rke til XML-tags i prompts? De er ikke dekorative. Modeller f√∏lger strukturerede instruktioner mere p√•lideligt end frit tekst. N√•r du har brug for flertrinsprocesser eller kompleks logik, hj√¶lper struktur modellen med at holde styr p√•, hvor den er, og hvad der kommer n√¶ste.

<img src="../../../translated_images/da/prompt-structure.a77763d63f4e2f89.png" alt="Prompt Structure" width="800"/>

*Anatomi af en velstruktureret prompt med klare sektioner og XML-stil organisering*

**Kvalitet gennem selvevaluering**

De selvreflekterende m√∏nstre fungerer ved at g√∏re kvalitetskriterier eksplicitte. I stedet for at h√•be, at modellen "g√∏r det rigtigt", fort√¶ller du den pr√¶cis, hvad "rigtigt" betyder: korrekt logik, fejlh√•ndtering, ydeevne, sikkerhed. Modellen kan s√• evaluere sit eget output og forbedre sig. Det forvandler kodegenerering fra et lotteri til en proces.

**Kontekst er begr√¶nset**

Multi-turn samtaler fungerer ved at inkludere beskedhistorik med hver anmodning. Men der er en gr√¶nse - hver model har et maksimalt tokenantal. Efterh√•nden som samtaler vokser, f√•r du brug for strategier til at bevare relevant kontekst uden at ramme loftet. Dette modul viser dig, hvordan hukommelse fungerer; senere l√¶rer du, hvorn√•r du skal opsummere, hvorn√•r du skal glemme, og hvorn√•r du skal hente.

## N√¶ste skridt

**N√¶ste modul:** [03-rag - RAG (Retrieval-Augmented Generation)](../03-rag/README.md)

---

**Navigation:** [‚Üê Forrige: Modul 01 - Introduktion](../01-introduction/README.md) | [Tilbage til hovedmenu](../README.md) | [N√¶ste: Modul 03 - RAG ‚Üí](../03-rag/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets modersm√•l b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->