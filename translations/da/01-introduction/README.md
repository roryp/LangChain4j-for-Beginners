<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c3e07ca58d0b8a3f47d3bf5728541e0a",
  "translation_date": "2025-12-13T13:41:24+00:00",
  "source_file": "01-introduction/README.md",
  "language_code": "da"
}
-->
# Modul 01: Kom godt i gang med LangChain4j

## Indholdsfortegnelse

- [Hvad du vil l√¶re](../../../01-introduction)
- [Foruds√¶tninger](../../../01-introduction)
- [Forst√•else af kerneproblemet](../../../01-introduction)
- [Forst√•else af tokens](../../../01-introduction)
- [Hvordan hukommelse fungerer](../../../01-introduction)
- [Hvordan dette bruger LangChain4j](../../../01-introduction)
- [Deploy Azure OpenAI-infrastruktur](../../../01-introduction)
- [K√∏r applikationen lokalt](../../../01-introduction)
- [Brug af applikationen](../../../01-introduction)
  - [Stateless chat (venstre panel)](../../../01-introduction)
  - [Stateful chat (h√∏jre panel)](../../../01-introduction)
- [N√¶ste skridt](../../../01-introduction)

## Hvad du vil l√¶re

Hvis du gennemf√∏rte quick start, s√• du, hvordan man sender prompts og f√•r svar. Det er fundamentet, men rigtige applikationer kr√¶ver mere. Dette modul l√¶rer dig, hvordan du bygger konverserende AI, der husker kontekst og opretholder tilstand ‚Äì forskellen mellem en engangs-demo og en produktionsklar applikation.

Vi bruger Azure OpenAI's GPT-5 gennem hele denne guide, fordi dens avancerede r√¶sonneringsevner g√∏r adf√¶rden af forskellige m√∏nstre mere tydelig. N√•r du tilf√∏jer hukommelse, vil du klart kunne se forskellen. Det g√∏r det nemmere at forst√•, hvad hver komponent bidrager med til din applikation.

Du vil bygge √©n applikation, der demonstrerer begge m√∏nstre:

**Stateless Chat** ‚Äì Hver foresp√∏rgsel er uafh√¶ngig. Modellen har ingen hukommelse om tidligere beskeder. Dette er det m√∏nster, du brugte i quick start.

**Stateful Conversation** ‚Äì Hver foresp√∏rgsel inkluderer samtalehistorik. Modellen opretholder kontekst over flere runder. Dette er, hvad produktionsapplikationer kr√¶ver.

## Foruds√¶tninger

- Azure-abonnement med adgang til Azure OpenAI
- Java 21, Maven 3.9+
- Azure CLI (https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)
- Azure Developer CLI (azd) (https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/install-azd)

> **Note:** Java, Maven, Azure CLI og Azure Developer CLI (azd) er forudinstalleret i den medf√∏lgende devcontainer.

> **Note:** Dette modul bruger GPT-5 p√• Azure OpenAI. Deployeringen konfigureres automatisk via `azd up` ‚Äì √¶ndr ikke modelnavnet i koden.

## Forst√•else af kerneproblemet

Sproglige modeller er stateless. Hver API-kald er uafh√¶ngigt. Hvis du sender "Mit navn er John" og derefter sp√∏rger "Hvad er mit navn?", har modellen ingen id√© om, at du lige har pr√¶senteret dig. Den behandler hver foresp√∏rgsel, som om det er den f√∏rste samtale, du nogensinde har haft.

Det er fint til simple Q&A, men ubrugeligt til rigtige applikationer. Kundeservicebots skal huske, hvad du har fortalt dem. Personlige assistenter har brug for kontekst. Enhver samtale med flere runder kr√¶ver hukommelse.

<img src="../../../translated_images/stateless-vs-stateful.cc4a4765e649c41a.da.png" alt="Stateless vs Stateful Conversations" width="800"/>

*Forskellen mellem stateless (uafh√¶ngige kald) og stateful (kontekstbevidste) samtaler*

## Forst√•else af tokens

F√∏r vi dykker ned i samtaler, er det vigtigt at forst√• tokens ‚Äì de grundl√¶ggende tekst-enheder, som sproglige modeller behandler:

<img src="../../../translated_images/token-explanation.c39760d8ec650181.da.png" alt="Token Explanation" width="800"/>

*Eksempel p√•, hvordan tekst opdeles i tokens ‚Äì "I love AI!" bliver til 4 separate behandlingsenheder*

Tokens er, hvordan AI-modeller m√•ler og behandler tekst. Ord, tegns√¶tning og endda mellemrum kan v√¶re tokens. Din model har en gr√¶nse for, hvor mange tokens den kan behandle p√• √©n gang (400.000 for GPT-5, med op til 272.000 input-tokens og 128.000 output-tokens). At forst√• tokens hj√¶lper dig med at styre samtalens l√¶ngde og omkostninger.

## Hvordan hukommelse fungerer

Chat-hukommelse l√∏ser det stateless problem ved at opretholde samtalehistorik. F√∏r du sender din foresp√∏rgsel til modellen, tilf√∏jer frameworket relevante tidligere beskeder foran. N√•r du sp√∏rger "Hvad er mit navn?", sender systemet faktisk hele samtalehistorikken, s√• modellen kan se, at du tidligere sagde "Mit navn er John."

LangChain4j leverer hukommelsesimplementeringer, der h√•ndterer dette automatisk. Du v√¶lger, hvor mange beskeder der skal gemmes, og frameworket styrer kontekstvinduet.

<img src="../../../translated_images/memory-window.bbe67f597eadabb3.da.png" alt="Memory Window Concept" width="800"/>

*MessageWindowChatMemory opretholder et glidende vindue af nylige beskeder og fjerner automatisk gamle*

## Hvordan dette bruger LangChain4j

Dette modul udvider quick start ved at integrere Spring Boot og tilf√∏je samtalehukommelse. S√•dan passer delene sammen:

**Afh√¶ngigheder** ‚Äì Tilf√∏j to LangChain4j-biblioteker:

```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Chat Model** ‚Äì Konfigurer Azure OpenAI som en Spring bean ([LangChainConfig.java](../../../01-introduction/src/main/java/com/example/langchain4j/config/LangChainConfig.java)):

```java
@Bean
public OpenAiOfficialChatModel openAiOfficialChatModel() {
    return OpenAiOfficialChatModel.builder()
            .baseUrl(azureEndpoint)
            .apiKey(azureApiKey)
            .modelName(deploymentName)
            .timeout(Duration.ofMinutes(5))
            .maxRetries(3)
            .build();
}
```

Builderen l√¶ser legitimationsoplysninger fra milj√∏variabler sat af `azd up`. At s√¶tte `baseUrl` til din Azure-endpoint f√•r OpenAI-klienten til at fungere med Azure OpenAI.

**Samtalehukommelse** ‚Äì Spor chat-historik med MessageWindowChatMemory ([ConversationService.java](../../../01-introduction/src/main/java/com/example/langchain4j/service/ConversationService.java)):

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("My name is John"));
memory.add(AiMessage.from("Nice to meet you, John!"));

memory.add(UserMessage.from("What's my name?"));
AiMessage aiMessage = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage);
```

Opret hukommelse med `withMaxMessages(10)` for at beholde de sidste 10 beskeder. Tilf√∏j bruger- og AI-beskeder med typede wrappers: `UserMessage.from(text)` og `AiMessage.from(text)`. Hent historik med `memory.messages()` og send den til modellen. Servicen gemmer separate hukommelsesinstanser pr. samtale-ID, s√• flere brugere kan chatte samtidig.

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öbn [`ConversationService.java`](../../../01-introduction/src/main/java/com/example/langchain4j/service/ConversationService.java) og sp√∏rg:
> - "Hvordan beslutter MessageWindowChatMemory, hvilke beskeder der skal droppes, n√•r vinduet er fuldt?"
> - "Kan jeg implementere brugerdefineret hukommelseslagring ved hj√¶lp af en database i stedet for in-memory?"
> - "Hvordan tilf√∏jer jeg opsummering for at komprimere gammel samtalehistorik?"

Den stateless chat-endpoint springer hukommelse helt over ‚Äì bare `chatModel.chat(prompt)` som i quick start. Den stateful endpoint tilf√∏jer beskeder til hukommelsen, henter historik og inkluderer den kontekst med hver foresp√∏rgsel. Samme modelkonfiguration, forskellige m√∏nstre.

## Deploy Azure OpenAI-infrastruktur

**Bash:**
```bash
cd 01-introduction
azd up  # V√¶lg abonnement og placering (eastus2 anbefales)
```

**PowerShell:**
```powershell
cd 01-introduction
azd up  # V√¶lg abonnement og placering (eastus2 anbefales)
```

> **Note:** Hvis du st√∏der p√• en timeout-fejl (`RequestConflict: Cannot modify resource ... provisioning state is not terminal`), s√• k√∏r blot `azd up` igen. Azure-ressourcer kan stadig v√¶re under provisionering i baggrunden, og et nyt fors√∏g tillader deployeringen at fuldf√∏res, n√•r ressourcerne n√•r en terminal tilstand.

Dette vil:
1. Deploye Azure OpenAI-ressource med GPT-5 og text-embedding-3-small modeller
2. Automatisk generere `.env`-fil i projektroden med legitimationsoplysninger
3. S√¶tte alle n√∏dvendige milj√∏variabler op

**Har du problemer med deployeringen?** Se [Infrastructure README](infra/README.md) for detaljeret fejlfinding, herunder subdom√¶nenavn-konflikter, manuelle Azure Portal deploy-trin og vejledning til modelkonfiguration.

**Bekr√¶ft at deployeringen lykkedes:**

**Bash:**
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY osv.
```

**PowerShell:**
```powershell
Get-Content ..\.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY osv.
```

> **Note:** `azd up`-kommandoen genererer automatisk `.env`-filen. Hvis du senere skal opdatere den, kan du enten redigere `.env`-filen manuelt eller regenerere den ved at k√∏re:
>
> **Bash:**
> ```bash
> cd ..
> bash .azd-env.sh
> ```
>
> **PowerShell:**
> ```powershell
> cd ..
> .\.azd-env.ps1
> ```

## K√∏r applikationen lokalt

**Bekr√¶ft deployering:**

S√∏rg for, at `.env`-filen findes i roddirektoriet med Azure-legitimationsoplysninger:

**Bash:**
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**PowerShell:**
```powershell
Get-Content ..\.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Start applikationerne:**

**Mulighed 1: Brug Spring Boot Dashboard (anbefalet til VS Code-brugere)**

Dev containeren inkluderer Spring Boot Dashboard-udvidelsen, som giver en visuel gr√¶nseflade til at styre alle Spring Boot-applikationer. Du finder den i aktivitetsbj√¶lken til venstre i VS Code (se efter Spring Boot-ikonet).

Fra Spring Boot Dashboard kan du:
- Se alle tilg√¶ngelige Spring Boot-applikationer i workspace
- Starte/stoppe applikationer med et enkelt klik
- Se applikationslogs i realtid
- Overv√•ge applikationsstatus

Klik blot p√• play-knappen ved siden af "introduction" for at starte dette modul, eller start alle moduler p√• √©n gang.

<img src="../../../translated_images/dashboard.69c7479aef09ff6b.da.png" alt="Spring Boot Dashboard" width="400"/>

**Mulighed 2: Brug shell-scripts**

Start alle webapplikationer (moduler 01-04):

**Bash:**
```bash
cd ..  # Fra roddirectory
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Fra roddirectory
.\start-all.ps1
```

Eller start kun dette modul:

**Bash:**
```bash
cd 01-introduction
./start.sh
```

**PowerShell:**
```powershell
cd 01-introduction
.\start.ps1
```

Begge scripts indl√¶ser automatisk milj√∏variabler fra roden `.env`-filen og bygger JAR-filerne, hvis de ikke findes.

> **Note:** Hvis du foretr√¶kker at bygge alle moduler manuelt f√∏r start:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

√Öbn http://localhost:8080 i din browser.

**For at stoppe:**

**Bash:**
```bash
./stop.sh  # Kun denne modul
# Eller
cd .. && ./stop-all.sh  # Alle moduler
```

**PowerShell:**
```powershell
.\stop.ps1  # Kun denne modul
# Eller
cd ..; .\stop-all.ps1  # Alle moduler
```

## Brug af applikationen

Applikationen tilbyder en webgr√¶nseflade med to chat-implementeringer side om side.

<img src="../../../translated_images/home-screen.121a03206ab910c0.da.png" alt="Application Home Screen" width="800"/>

*Dashboard, der viser b√•de Simple Chat (stateless) og Conversational Chat (stateful) muligheder*

### Stateless chat (venstre panel)

Pr√∏v denne f√∏rst. Sp√∏rg "Mit navn er John" og sp√∏rg s√• straks "Hvad er mit navn?" Modellen vil ikke huske, fordi hver besked er uafh√¶ngig. Dette demonstrerer kerneproblemet med basal integration af sproglige modeller ‚Äì ingen samtalekontekst.

<img src="../../../translated_images/simple-chat-stateless-demo.13aeb3978eab3234.da.png" alt="Stateless Chat Demo" width="800"/>

*AI husker ikke dit navn fra den forrige besked*

### Stateful chat (h√∏jre panel)

Pr√∏v nu samme sekvens her. Sp√∏rg "Mit navn er John" og s√• "Hvad er mit navn?" Denne gang husker den. Forskellen er MessageWindowChatMemory ‚Äì den opretholder samtalehistorik og inkluderer den med hver foresp√∏rgsel. S√•dan fungerer produktionsklar konverserende AI.

<img src="../../../translated_images/conversational-chat-stateful-demo.e5be9822eb23ff59.da.png" alt="Stateful Chat Demo" width="800"/>

*AI husker dit navn fra tidligere i samtalen*

Begge paneler bruger samme GPT-5-model. Den eneste forskel er hukommelse. Det g√∏r det klart, hvad hukommelse tilf√∏rer din applikation, og hvorfor det er essentielt for reelle brugsscenarier.

## N√¶ste skridt

**N√¶ste modul:** [02-prompt-engineering - Prompt Engineering med GPT-5](../02-prompt-engineering/README.md)

---

**Navigation:** [‚Üê Forrige: Modul 00 - Quick Start](../00-quick-start/README.md) | [Tilbage til hoved](../README.md) | [N√¶ste: Modul 02 - Prompt Engineering ‚Üí](../02-prompt-engineering/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets modersm√•l b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->