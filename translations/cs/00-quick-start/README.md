<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "377b3e3e6f8d02965bf0fbbc9ccb45c5",
  "translation_date": "2025-12-13T15:13:38+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "cs"
}
-->
# Modul 00: RychlÃ½ start

## Obsah

- [Ãšvod](../../../00-quick-start)
- [Co je LangChain4j?](../../../00-quick-start)
- [ZÃ¡vislosti LangChain4j](../../../00-quick-start)
- [PoÅ¾adavky](../../../00-quick-start)
- [NastavenÃ­](../../../00-quick-start)
  - [1. ZÃ­skejte svÅ¯j GitHub token](../../../00-quick-start)
  - [2. Nastavte svÅ¯j token](../../../00-quick-start)
- [SpuÅ¡tÄ›nÃ­ pÅ™Ã­kladÅ¯](../../../00-quick-start)
  - [1. ZÃ¡kladnÃ­ chat](../../../00-quick-start)
  - [2. Vzory promptÅ¯](../../../00-quick-start)
  - [3. VolÃ¡nÃ­ funkcÃ­](../../../00-quick-start)
  - [4. OtÃ¡zky a odpovÄ›di k dokumentu (RAG)](../../../00-quick-start)
- [Co kaÅ¾dÃ½ pÅ™Ã­klad ukazuje](../../../00-quick-start)
- [DalÅ¡Ã­ kroky](../../../00-quick-start)
- [Å˜eÅ¡enÃ­ problÃ©mÅ¯](../../../00-quick-start)

## Ãšvod

Tento rychlÃ½ start je urÄen k tomu, abyste co nejrychleji zaÄali pracovat s LangChain4j. PokrÃ½vÃ¡ naprostÃ© zÃ¡klady tvorby AI aplikacÃ­ s LangChain4j a GitHub Models. V dalÅ¡Ã­ch modulech pouÅ¾ijete Azure OpenAI s LangChain4j k vytvÃ¡Å™enÃ­ pokroÄilejÅ¡Ã­ch aplikacÃ­.

## Co je LangChain4j?

LangChain4j je Java knihovna, kterÃ¡ zjednoduÅ¡uje tvorbu aplikacÃ­ pohÃ¡nÄ›nÃ½ch AI. MÃ­sto prÃ¡ce s HTTP klienty a parsovÃ¡nÃ­m JSON pracujete s ÄistÃ½mi Java API.

â€Chainâ€œ v LangChain znamenÃ¡ Å™etÄ›zenÃ­ vÃ­ce komponent â€“ mÅ¯Å¾ete napÅ™Ã­klad spojit prompt s modelem a parserem, nebo Å™etÄ›zit vÃ­ce AI volÃ¡nÃ­, kde vÃ½stup jednoho je vstupem dalÅ¡Ã­ho. Tento rychlÃ½ start se zamÄ›Å™uje na zÃ¡klady pÅ™ed tÃ­m, neÅ¾ prozkoumÃ¡te sloÅ¾itÄ›jÅ¡Ã­ Å™etÄ›zce.

<img src="../../../translated_images/langchain-concept.ad1fe6cf063515e1e961a13c73d45cfa305fd03d81bd11e5d34d0e36ed28a44d.cs.png" alt="LangChain4j Chaining Concept" width="800"/>

*Å˜etÄ›zenÃ­ komponent v LangChain4j â€“ stavebnÃ­ bloky se spojujÃ­ k vytvoÅ™enÃ­ vÃ½konnÃ½ch AI pracovnÃ­ch tokÅ¯*

PouÅ¾ijeme tÅ™i zÃ¡kladnÃ­ komponenty:

**ChatLanguageModel** â€“ rozhranÃ­ pro interakce s AI modelem. ZavolÃ¡te `model.chat("prompt")` a zÃ­skÃ¡te odpovÄ›Ä jako Å™etÄ›zec. PouÅ¾Ã­vÃ¡me `OpenAiOfficialChatModel`, kterÃ½ funguje s OpenAI-kompatibilnÃ­mi endpointy jako GitHub Models.

**AiServices** â€“ vytvÃ¡Å™Ã­ typovÄ› bezpeÄnÃ¡ rozhranÃ­ AI sluÅ¾eb. Definujete metody, oznaÄÃ­te je anotacÃ­ `@Tool` a LangChain4j se postarÃ¡ o orchestraci. AI automaticky volÃ¡ vaÅ¡e Java metody, kdyÅ¾ je to potÅ™eba.

**MessageWindowChatMemory** â€“ udrÅ¾uje historii konverzace. Bez toho je kaÅ¾dÃ¡ Å¾Ã¡dost nezÃ¡vislÃ¡. S tÃ­mto si AI pamatuje pÅ™edchozÃ­ zprÃ¡vy a udrÅ¾uje kontext pÅ™es vÃ­ce kol.

<img src="../../../translated_images/architecture.eedc993a1c57683951f20244f652fc7a9853f571eea835bc2b2828cf0dbf62d0.cs.png" alt="LangChain4j Architecture" width="800"/>

*Architektura LangChain4j â€“ zÃ¡kladnÃ­ komponenty spolupracujÃ­ na pohÃ¡nÄ›nÃ­ vaÅ¡ich AI aplikacÃ­*

## ZÃ¡vislosti LangChain4j

Tento rychlÃ½ start pouÅ¾Ã­vÃ¡ dvÄ› Maven zÃ¡vislosti v [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

Modul `langchain4j-open-ai-official` poskytuje tÅ™Ã­du `OpenAiOfficialChatModel`, kterÃ¡ se pÅ™ipojuje k OpenAI-kompatibilnÃ­m API. GitHub Models pouÅ¾Ã­vÃ¡ stejnÃ½ formÃ¡t API, takÅ¾e nenÃ­ potÅ™eba Å¾Ã¡dnÃ½ speciÃ¡lnÃ­ adaptÃ©r â€“ staÄÃ­ nastavit zÃ¡kladnÃ­ URL na `https://models.github.ai/inference`.

## PoÅ¾adavky

**PouÅ¾Ã­vÃ¡te Dev Container?** Java a Maven jsou jiÅ¾ nainstalovÃ¡ny. PotÅ™ebujete pouze GitHub Personal Access Token.

**LokÃ¡lnÃ­ vÃ½voj:**
- Java 21+, Maven 3.9+
- GitHub Personal Access Token (nÃ¡vod nÃ­Å¾e)

> **PoznÃ¡mka:** Tento modul pouÅ¾Ã­vÃ¡ `gpt-4.1-nano` z GitHub Models. NemÄ›Åˆte nÃ¡zev modelu v kÃ³du â€“ je nakonfigurovÃ¡n pro prÃ¡ci s dostupnÃ½mi modely GitHubu.

## NastavenÃ­

### 1. ZÃ­skejte svÅ¯j GitHub token

1. PÅ™ejdÄ›te na [GitHub NastavenÃ­ â†’ Personal Access Tokens](https://github.com/settings/personal-access-tokens)
2. KliknÄ›te na â€Generate new tokenâ€œ
3. Nastavte popisnÃ½ nÃ¡zev (napÅ™. â€LangChain4j Demoâ€œ)
4. Nastavte expiraci (doporuÄeno 7 dnÃ­)
5. V sekci â€Account permissionsâ€œ najdÄ›te â€Modelsâ€œ a nastavte na â€Read-onlyâ€œ
6. KliknÄ›te na â€Generate tokenâ€œ
7. ZkopÃ­rujte a uloÅ¾te token â€“ uÅ¾ ho neuvidÃ­te

### 2. Nastavte svÅ¯j token

**MoÅ¾nost 1: PouÅ¾itÃ­ VS Code (doporuÄeno)**

Pokud pouÅ¾Ã­vÃ¡te VS Code, pÅ™idejte svÅ¯j token do souboru `.env` v koÅ™enovÃ©m adresÃ¡Å™i projektu:

Pokud soubor `.env` neexistuje, zkopÃ­rujte `.env.example` do `.env` nebo vytvoÅ™te novÃ½ `.env` soubor v koÅ™enovÃ©m adresÃ¡Å™i.

**PÅ™Ã­klad souboru `.env`:**
```bash
# V /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Pak mÅ¯Å¾ete jednoduÅ¡e kliknout pravÃ½m tlaÄÃ­tkem na jakÃ½koli demo soubor (napÅ™. `BasicChatDemo.java`) v PrÅ¯zkumnÃ­ku a vybrat **â€Run Javaâ€œ** nebo pouÅ¾Ã­t spouÅ¡tÄ›cÃ­ konfigurace z panelu Run and Debug.

**MoÅ¾nost 2: PouÅ¾itÃ­ terminÃ¡lu**

Nastavte token jako promÄ›nnou prostÅ™edÃ­:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## SpuÅ¡tÄ›nÃ­ pÅ™Ã­kladÅ¯

**PouÅ¾itÃ­ VS Code:** JednoduÅ¡e kliknÄ›te pravÃ½m tlaÄÃ­tkem na jakÃ½koli demo soubor v PrÅ¯zkumnÃ­ku a vyberte **â€Run Javaâ€œ**, nebo pouÅ¾ijte spouÅ¡tÄ›cÃ­ konfigurace z panelu Run and Debug (ujistÄ›te se, Å¾e jste nejdÅ™Ã­ve pÅ™idali token do `.env`).

**PouÅ¾itÃ­ Maven:** AlternativnÄ› mÅ¯Å¾ete spustit z pÅ™Ã­kazovÃ© Å™Ã¡dky:

### 1. ZÃ¡kladnÃ­ chat

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Vzory promptÅ¯

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Ukazuje zero-shot, few-shot, chain-of-thought a role-based prompting.

### 3. VolÃ¡nÃ­ funkcÃ­

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

AI automaticky volÃ¡ vaÅ¡e Java metody, kdyÅ¾ je to potÅ™eba.

### 4. OtÃ¡zky a odpovÄ›di k dokumentu (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Ptejte se na obsah v `document.txt`.

## Co kaÅ¾dÃ½ pÅ™Ã­klad ukazuje

**ZÃ¡kladnÃ­ chat** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

ZaÄnÄ›te zde, abyste vidÄ›li LangChain4j v jeho nejjednoduÅ¡Å¡Ã­ podobÄ›. VytvoÅ™Ã­te `OpenAiOfficialChatModel`, poÅ¡lete prompt pomocÃ­ `.chat()` a zÃ­skÃ¡te odpovÄ›Ä. Ukazuje to zÃ¡klady: jak inicializovat modely s vlastnÃ­mi endpointy a API klÃ­Äi. Jakmile tento vzor pochopÃ­te, vÅ¡e ostatnÃ­ na nÄ›m stavÃ­.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ğŸ¤– VyzkouÅ¡ejte s [GitHub Copilot](https://github.com/features/copilot) Chat:** OtevÅ™ete [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) a zeptejte se:
> - â€Jak pÅ™epnout z GitHub Models na Azure OpenAI v tomto kÃ³du?â€œ
> - â€JakÃ© dalÅ¡Ã­ parametry mohu konfigurovat v OpenAiOfficialChatModel.builder()?â€œ
> - â€Jak pÅ™idÃ¡m streamovÃ¡nÃ­ odpovÄ›dÃ­ mÃ­sto ÄekÃ¡nÃ­ na kompletnÃ­ odpovÄ›Ä?â€œ

**Prompt Engineering** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

NynÃ­, kdyÅ¾ vÃ­te, jak mluvit s modelem, pojÄme prozkoumat, co mu Å™Ã­kÃ¡te. Toto demo pouÅ¾Ã­vÃ¡ stejnou konfiguraci modelu, ale ukazuje ÄtyÅ™i rÅ¯znÃ© vzory promptÅ¯. VyzkouÅ¡ejte zero-shot prompt pro pÅ™Ã­mÃ© instrukce, few-shot prompt, kterÃ½ se uÄÃ­ z pÅ™Ã­kladÅ¯, chain-of-thought prompt, kterÃ½ odhaluje kroky uvaÅ¾ovÃ¡nÃ­, a role-based prompt, kterÃ½ nastavuje kontext. UvidÃ­te, jak stejnÃ½ model dÃ¡vÃ¡ dramaticky odliÅ¡nÃ© vÃ½sledky podle toho, jak formulujete svou Å¾Ã¡dost.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ğŸ¤– VyzkouÅ¡ejte s [GitHub Copilot](https://github.com/features/copilot) Chat:** OtevÅ™ete [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) a zeptejte se:
> - â€JakÃ½ je rozdÃ­l mezi zero-shot a few-shot promptingem a kdy kterÃ½ pouÅ¾Ã­t?â€œ
> - â€Jak parametr temperature ovlivÅˆuje odpovÄ›di modelu?â€œ
> - â€JakÃ© jsou techniky pro prevenci prompt injection ÃºtokÅ¯ v produkci?â€œ
> - â€Jak vytvoÅ™it znovupouÅ¾itelnÃ© objekty PromptTemplate pro bÄ›Å¾nÃ© vzory?â€œ

**Integrace nÃ¡strojÅ¯** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Tady LangChain4j zÃ­skÃ¡vÃ¡ sÃ­lu. PouÅ¾ijete `AiServices` k vytvoÅ™enÃ­ AI asistenta, kterÃ½ mÅ¯Å¾e volat vaÅ¡e Java metody. StaÄÃ­ oznaÄit metody anotacÃ­ `@Tool("popis")` a LangChain4j se postarÃ¡ o zbytek â€“ AI automaticky rozhoduje, kdy kterÃ½ nÃ¡stroj pouÅ¾Ã­t podle toho, co uÅ¾ivatel poÅ¾aduje. Ukazuje to volÃ¡nÃ­ funkcÃ­, klÃ­Äovou techniku pro tvorbu AI, kterÃ¡ mÅ¯Å¾e vykonÃ¡vat akce, nejen odpovÃ­dat na otÃ¡zky.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ğŸ¤– VyzkouÅ¡ejte s [GitHub Copilot](https://github.com/features/copilot) Chat:** OtevÅ™ete [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) a zeptejte se:
> - â€Jak funguje anotace @Tool a co s nÃ­ LangChain4j dÄ›lÃ¡ na pozadÃ­?â€œ
> - â€MÅ¯Å¾e AI volat vÃ­ce nÃ¡strojÅ¯ za sebou k Å™eÅ¡enÃ­ sloÅ¾itÃ½ch problÃ©mÅ¯?â€œ
> - â€Co se stane, kdyÅ¾ nÃ¡stroj vyhodÃ­ vÃ½jimku â€“ jak mÃ¡m Å™eÅ¡it chyby?â€œ
> - â€Jak bych integroval skuteÄnÃ© API mÃ­sto tohoto pÅ™Ã­kladu kalkulaÄky?â€œ

**OtÃ¡zky a odpovÄ›di k dokumentu (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Zde uvidÃ­te zÃ¡klady RAG (retrieval-augmented generation). MÃ­sto spolÃ©hÃ¡nÃ­ se na trÃ©ninkovÃ¡ data modelu naÄtete obsah z [`document.txt`](../../../00-quick-start/document.txt) a zahrnete ho do promptu. AI odpovÃ­dÃ¡ na zÃ¡kladÄ› vaÅ¡eho dokumentu, ne obecnÃ© znalosti. To je prvnÃ­ krok k tvorbÄ› systÃ©mÅ¯, kterÃ© mohou pracovat s vaÅ¡imi vlastnÃ­mi daty.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **PoznÃ¡mka:** Tento jednoduchÃ½ pÅ™Ã­stup naÄÃ­tÃ¡ celÃ½ dokument do promptu. U velkÃ½ch souborÅ¯ (>10KB) pÅ™ekroÄÃ­te limity kontextu. Modul 03 pokrÃ½vÃ¡ dÄ›lenÃ­ na ÄÃ¡sti a vektorovÃ© vyhledÃ¡vÃ¡nÃ­ pro produkÄnÃ­ RAG systÃ©my.

> **ğŸ¤– VyzkouÅ¡ejte s [GitHub Copilot](https://github.com/features/copilot) Chat:** OtevÅ™ete [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) a zeptejte se:
> - â€Jak RAG zabraÅˆuje halucinacÃ­m AI ve srovnÃ¡nÃ­ s pouÅ¾itÃ­m trÃ©ninkovÃ½ch dat modelu?â€œ
> - â€JakÃ½ je rozdÃ­l mezi tÃ­mto jednoduchÃ½m pÅ™Ã­stupem a pouÅ¾itÃ­m vektorovÃ½ch embeddingÅ¯ pro vyhledÃ¡vÃ¡nÃ­?â€œ
> - â€Jak bych to Å¡kÃ¡loval pro vÃ­ce dokumentÅ¯ nebo vÄ›tÅ¡Ã­ znalostnÃ­ bÃ¡ze?â€œ
> - â€JakÃ© jsou nejlepÅ¡Ã­ praktiky pro strukturovÃ¡nÃ­ promptu, aby AI pouÅ¾Ã­vala pouze poskytnutÃ½ kontext?â€œ

## LadÄ›nÃ­

PÅ™Ã­klady obsahujÃ­ `.logRequests(true)` a `.logResponses(true)`, aby zobrazily API volÃ¡nÃ­ v konzoli. To pomÃ¡hÃ¡ Å™eÅ¡it chyby autentizace, limity rychlosti nebo neoÄekÃ¡vanÃ© odpovÄ›di. V produkci tyto pÅ™Ã­znaky odstraÅˆte, abyste snÃ­Å¾ili Å¡um v logu.

## DalÅ¡Ã­ kroky

**DalÅ¡Ã­ modul:** [01-introduction - ZaÄÃ­nÃ¡me s LangChain4j a gpt-5 na Azure](../01-introduction/README.md)

---

**Navigace:** [â† ZpÄ›t na hlavnÃ­](../README.md) | [DalÅ¡Ã­: Modul 01 - Ãšvod â†’](../01-introduction/README.md)

---

## Å˜eÅ¡enÃ­ problÃ©mÅ¯

### PrvnÃ­ sestavenÃ­ Maven

**ProblÃ©m:** PrvnÃ­ `mvn clean compile` nebo `mvn package` trvÃ¡ dlouho (10-15 minut)

**PÅ™Ã­Äina:** Maven musÃ­ pÅ™i prvnÃ­m sestavenÃ­ stÃ¡hnout vÅ¡echny zÃ¡vislosti projektu (Spring Boot, LangChain4j knihovny, Azure SDK atd.).

**Å˜eÅ¡enÃ­:** Toto je normÃ¡lnÃ­ chovÃ¡nÃ­. NÃ¡sledujÃ­cÃ­ sestavenÃ­ budou mnohem rychlejÅ¡Ã­, protoÅ¾e zÃ¡vislosti jsou uloÅ¾eny v cache lokÃ¡lnÄ›. Doba stahovÃ¡nÃ­ zÃ¡visÃ­ na rychlosti vaÅ¡Ã­ sÃ­tÄ›.

### Syntaxe Maven pÅ™Ã­kazÅ¯ v PowerShell

**ProblÃ©m:** Maven pÅ™Ã­kazy selhÃ¡vajÃ­ s chybou `Unknown lifecycle phase ".mainClass=..."`

**PÅ™Ã­Äina:** PowerShell interpretuje `=` jako operÃ¡tor pÅ™iÅ™azenÃ­ promÄ›nnÃ©, coÅ¾ naruÅ¡uje syntaxi Maven vlastnostÃ­.

**Å˜eÅ¡enÃ­:** PouÅ¾ijte operÃ¡tor zastavenÃ­ parsovÃ¡nÃ­ `--%` pÅ™ed Maven pÅ™Ã­kazem:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

OperÃ¡tor `--%` Å™Ã­kÃ¡ PowerShellu, aby vÅ¡echny zbÃ½vajÃ­cÃ­ argumenty pÅ™edal doslovnÄ› Maven bez interpretace.

### ZobrazenÃ­ emoji ve Windows PowerShell

**ProblÃ©m:** AI odpovÄ›di zobrazujÃ­ nesmyslnÃ© znaky (napÅ™. `????` nebo `Ã¢??`) mÃ­sto emoji v PowerShellu

**PÅ™Ã­Äina:** VÃ½chozÃ­ kÃ³dovÃ¡nÃ­ PowerShellu nepodporuje UTF-8 emoji

**Å˜eÅ¡enÃ­:** SpusÅ¥te tento pÅ™Ã­kaz pÅ™ed spuÅ¡tÄ›nÃ­m Java aplikacÃ­:
```cmd
chcp 65001
```

TÃ­m se v terminÃ¡lu vynutÃ­ kÃ³dovÃ¡nÃ­ UTF-8. AlternativnÄ› pouÅ¾ijte Windows Terminal, kterÃ½ mÃ¡ lepÅ¡Ã­ podporu Unicode.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ProhlÃ¡Å¡enÃ­ o vylouÄenÃ­ odpovÄ›dnosti**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). PÅ™estoÅ¾e usilujeme o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatizovanÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho mateÅ™skÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro kritickÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme odpovÄ›dnÃ­ za jakÃ©koliv nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© vÃ½klady vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->