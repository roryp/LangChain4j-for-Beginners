<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "377b3e3e6f8d02965bf0fbbc9ccb45c5",
  "translation_date": "2025-12-13T14:51:24+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "br"
}
-->
# M√≥dulo 00: In√≠cio R√°pido

## √çndice

- [Introdu√ß√£o](../../../00-quick-start)
- [O que √© LangChain4j?](../../../00-quick-start)
- [Depend√™ncias do LangChain4j](../../../00-quick-start)
- [Pr√©-requisitos](../../../00-quick-start)
- [Configura√ß√£o](../../../00-quick-start)
  - [1. Obtenha seu Token do GitHub](../../../00-quick-start)
  - [2. Defina seu Token](../../../00-quick-start)
- [Execute os Exemplos](../../../00-quick-start)
  - [1. Chat B√°sico](../../../00-quick-start)
  - [2. Padr√µes de Prompt](../../../00-quick-start)
  - [3. Chamada de Fun√ß√£o](../../../00-quick-start)
  - [4. Perguntas e Respostas de Documentos (RAG)](../../../00-quick-start)
- [O que Cada Exemplo Mostra](../../../00-quick-start)
- [Pr√≥ximos Passos](../../../00-quick-start)
- [Solu√ß√£o de Problemas](../../../00-quick-start)

## Introdu√ß√£o

Este in√≠cio r√°pido tem como objetivo coloc√°-lo em funcionamento com LangChain4j o mais r√°pido poss√≠vel. Ele cobre o b√°sico absoluto de como construir aplica√ß√µes de IA com LangChain4j e GitHub Models. Nos pr√≥ximos m√≥dulos, voc√™ usar√° Azure OpenAI com LangChain4j para construir aplica√ß√µes mais avan√ßadas.

## O que √© LangChain4j?

LangChain4j √© uma biblioteca Java que simplifica a constru√ß√£o de aplica√ß√µes alimentadas por IA. Em vez de lidar com clientes HTTP e parsing de JSON, voc√™ trabalha com APIs Java limpas.

A "chain" em LangChain refere-se a encadear m√∫ltiplos componentes - voc√™ pode encadear um prompt a um modelo, a um parser, ou encadear m√∫ltiplas chamadas de IA onde uma sa√≠da alimenta a pr√≥xima entrada. Este in√≠cio r√°pido foca nos fundamentos antes de explorar cadeias mais complexas.

<img src="../../../translated_images/langchain-concept.ad1fe6cf063515e1e961a13c73d45cfa305fd03d81bd11e5d34d0e36ed28a44d.br.png" alt="Conceito de Encadeamento do LangChain4j" width="800"/>

*Encadeando componentes no LangChain4j - blocos de constru√ß√£o conectam-se para criar fluxos de trabalho poderosos de IA*

Usaremos tr√™s componentes principais:

**ChatLanguageModel** - A interface para intera√ß√µes com modelos de IA. Chame `model.chat("prompt")` e obtenha uma string de resposta. Usamos `OpenAiOfficialChatModel` que funciona com endpoints compat√≠veis com OpenAI, como GitHub Models.

**AiServices** - Cria interfaces de servi√ßo de IA com tipagem segura. Defina m√©todos, anote-os com `@Tool`, e LangChain4j cuida da orquestra√ß√£o. A IA chama automaticamente seus m√©todos Java quando necess√°rio.

**MessageWindowChatMemory** - Mant√©m o hist√≥rico da conversa. Sem isso, cada requisi√ß√£o √© independente. Com isso, a IA lembra mensagens anteriores e mant√©m o contexto em m√∫ltiplas intera√ß√µes.

<img src="../../../translated_images/architecture.eedc993a1c57683951f20244f652fc7a9853f571eea835bc2b2828cf0dbf62d0.br.png" alt="Arquitetura do LangChain4j" width="800"/>

*Arquitetura do LangChain4j - componentes principais trabalhando juntos para alimentar suas aplica√ß√µes de IA*

## Depend√™ncias do LangChain4j

Este in√≠cio r√°pido usa duas depend√™ncias Maven no [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

O m√≥dulo `langchain4j-open-ai-official` fornece a classe `OpenAiOfficialChatModel` que conecta a APIs compat√≠veis com OpenAI. GitHub Models usa o mesmo formato de API, ent√£o n√£o √© necess√°rio adaptador especial - basta apontar a URL base para `https://models.github.ai/inference`.

## Pr√©-requisitos

**Usando o Dev Container?** Java e Maven j√° est√£o instalados. Voc√™ s√≥ precisa de um Token de Acesso Pessoal do GitHub.

**Desenvolvimento Local:**
- Java 21+, Maven 3.9+
- Token de Acesso Pessoal do GitHub (instru√ß√µes abaixo)

> **Nota:** Este m√≥dulo usa `gpt-4.1-nano` do GitHub Models. N√£o modifique o nome do modelo no c√≥digo - ele est√° configurado para funcionar com os modelos dispon√≠veis do GitHub.

## Configura√ß√£o

### 1. Obtenha seu Token do GitHub

1. V√° para [Configura√ß√µes do GitHub ‚Üí Tokens de Acesso Pessoal](https://github.com/settings/personal-access-tokens)
2. Clique em "Generate new token"
3. Defina um nome descritivo (ex.: "LangChain4j Demo")
4. Defina a expira√ß√£o (7 dias recomendado)
5. Em "Permiss√µes da conta", encontre "Models" e defina como "Somente leitura"
6. Clique em "Generate token"
7. Copie e salve seu token - voc√™ n√£o ver√° ele novamente

### 2. Defina seu Token

**Op√ß√£o 1: Usando VS Code (Recomendado)**

Se estiver usando VS Code, adicione seu token no arquivo `.env` na raiz do projeto:

Se o arquivo `.env` n√£o existir, copie `.env.example` para `.env` ou crie um novo arquivo `.env` na raiz do projeto.

**Exemplo de arquivo `.env`:**
```bash
# Em /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Ent√£o voc√™ pode simplesmente clicar com o bot√£o direito em qualquer arquivo de demonstra√ß√£o (ex.: `BasicChatDemo.java`) no Explorer e selecionar **"Run Java"** ou usar as configura√ß√µes de execu√ß√£o no painel Run and Debug.

**Op√ß√£o 2: Usando Terminal**

Defina o token como vari√°vel de ambiente:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## Execute os Exemplos

**Usando VS Code:** Basta clicar com o bot√£o direito em qualquer arquivo de demonstra√ß√£o no Explorer e selecionar **"Run Java"**, ou usar as configura√ß√µes de execu√ß√£o no painel Run and Debug (certifique-se de ter adicionado seu token no arquivo `.env` primeiro).

**Usando Maven:** Alternativamente, voc√™ pode executar pelo terminal:

### 1. Chat B√°sico

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Padr√µes de Prompt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Mostra zero-shot, few-shot, chain-of-thought e prompting baseado em pap√©is.

### 3. Chamada de Fun√ß√£o

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

A IA chama automaticamente seus m√©todos Java quando necess√°rio.

### 4. Perguntas e Respostas de Documentos (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Fa√ßa perguntas sobre o conte√∫do em `document.txt`.

## O que Cada Exemplo Mostra

**Chat B√°sico** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Comece aqui para ver o LangChain4j em sua forma mais simples. Voc√™ criar√° um `OpenAiOfficialChatModel`, enviar√° um prompt com `.chat()`, e receber√° uma resposta. Isso demonstra a base: como inicializar modelos com endpoints personalizados e chaves de API. Uma vez que voc√™ entenda esse padr√£o, todo o resto se baseia nele.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Abra [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) e pergunte:
> - "Como eu mudaria de GitHub Models para Azure OpenAI neste c√≥digo?"
> - "Quais outros par√¢metros posso configurar em OpenAiOfficialChatModel.builder()?"
> - "Como adiciono respostas em streaming em vez de esperar pela resposta completa?"

**Engenharia de Prompt** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Agora que voc√™ sabe como falar com um modelo, vamos explorar o que voc√™ diz a ele. Esta demo usa a mesma configura√ß√£o de modelo, mas mostra quatro padr√µes diferentes de prompting. Experimente prompts zero-shot para instru√ß√µes diretas, few-shot que aprendem com exemplos, chain-of-thought que revelam passos de racioc√≠nio, e prompts baseados em pap√©is que definem contexto. Voc√™ ver√° como o mesmo modelo d√° resultados dramaticamente diferentes dependendo de como voc√™ enquadra sua solicita√ß√£o.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Abra [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) e pergunte:
> - "Qual a diferen√ßa entre zero-shot e few-shot prompting, e quando devo usar cada um?"
> - "Como o par√¢metro temperature afeta as respostas do modelo?"
> - "Quais s√£o algumas t√©cnicas para prevenir ataques de inje√ß√£o de prompt em produ√ß√£o?"
> - "Como posso criar objetos PromptTemplate reutiliz√°veis para padr√µes comuns?"

**Integra√ß√£o de Ferramentas** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Aqui √© onde o LangChain4j fica poderoso. Voc√™ usar√° `AiServices` para criar um assistente de IA que pode chamar seus m√©todos Java. Basta anotar m√©todos com `@Tool("descri√ß√£o")` e LangChain4j cuida do resto - a IA decide automaticamente quando usar cada ferramenta com base no que o usu√°rio pergunta. Isso demonstra chamada de fun√ß√£o, uma t√©cnica chave para construir IA que pode tomar a√ß√µes, n√£o apenas responder perguntas.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Abra [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) e pergunte:
> - "Como funciona a anota√ß√£o @Tool e o que o LangChain4j faz com ela nos bastidores?"
> - "A IA pode chamar m√∫ltiplas ferramentas em sequ√™ncia para resolver problemas complexos?"
> - "O que acontece se uma ferramenta lan√ßar uma exce√ß√£o - como devo tratar erros?"
> - "Como eu integraria uma API real em vez deste exemplo de calculadora?"

**Perguntas e Respostas de Documentos (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Aqui voc√™ ver√° a base do RAG (gera√ß√£o aumentada por recupera√ß√£o). Em vez de depender dos dados de treinamento do modelo, voc√™ carrega conte√∫do de [`document.txt`](../../../00-quick-start/document.txt) e o inclui no prompt. A IA responde com base no seu documento, n√£o no conhecimento geral dela. Este √© o primeiro passo para construir sistemas que podem trabalhar com seus pr√≥prios dados.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Nota:** Esta abordagem simples carrega o documento inteiro no prompt. Para arquivos grandes (>10KB), voc√™ ultrapassar√° os limites de contexto. O M√≥dulo 03 cobre chunking e busca vetorial para sistemas RAG em produ√ß√£o.

> **ü§ñ Experimente com o Chat do [GitHub Copilot](https://github.com/features/copilot):** Abra [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) e pergunte:
> - "Como o RAG previne alucina√ß√µes da IA comparado ao uso dos dados de treinamento do modelo?"
> - "Qual a diferen√ßa entre esta abordagem simples e o uso de embeddings vetoriais para recupera√ß√£o?"
> - "Como eu escalaria isso para lidar com m√∫ltiplos documentos ou bases de conhecimento maiores?"
> - "Quais s√£o as melhores pr√°ticas para estruturar o prompt para garantir que a IA use apenas o contexto fornecido?"

## Depura√ß√£o

Os exemplos incluem `.logRequests(true)` e `.logResponses(true)` para mostrar chamadas de API no console. Isso ajuda a solucionar erros de autentica√ß√£o, limites de taxa ou respostas inesperadas. Remova essas flags em produ√ß√£o para reduzir o ru√≠do nos logs.

## Pr√≥ximos Passos

**Pr√≥ximo M√≥dulo:** [01-introduction - Come√ßando com LangChain4j e gpt-5 no Azure](../01-introduction/README.md)

---

**Navega√ß√£o:** [‚Üê Voltar ao Principal](../README.md) | [Pr√≥ximo: M√≥dulo 01 - Introdu√ß√£o ‚Üí](../01-introduction/README.md)

---

## Solu√ß√£o de Problemas

### Primeira Compila√ß√£o Maven

**Problema**: O comando inicial `mvn clean compile` ou `mvn package` demora muito (10-15 minutos)

**Causa**: O Maven precisa baixar todas as depend√™ncias do projeto (Spring Boot, bibliotecas LangChain4j, SDKs Azure, etc.) na primeira compila√ß√£o.

**Solu√ß√£o**: Este √© um comportamento normal. Compila√ß√µes subsequentes ser√£o muito mais r√°pidas pois as depend√™ncias ficam em cache localmente. O tempo de download depende da velocidade da sua rede.

### Sintaxe do Comando Maven no PowerShell

**Problema**: Comandos Maven falham com erro `Unknown lifecycle phase ".mainClass=..."`

**Causa**: PowerShell interpreta `=` como operador de atribui√ß√£o de vari√°vel, quebrando a sintaxe de propriedades do Maven

**Solu√ß√£o**: Use o operador de parada de parsing `--%` antes do comando Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

O operador `--%` instrui o PowerShell a passar todos os argumentos restantes literalmente para o Maven sem interpreta√ß√£o.

### Exibi√ß√£o de Emojis no PowerShell do Windows

**Problema**: Respostas da IA mostram caracteres estranhos (ex.: `????` ou `√¢??`) em vez de emojis no PowerShell

**Causa**: A codifica√ß√£o padr√£o do PowerShell n√£o suporta emojis UTF-8

**Solu√ß√£o**: Execute este comando antes de rodar aplica√ß√µes Java:
```cmd
chcp 65001
```

Isso for√ßa a codifica√ß√£o UTF-8 no terminal. Alternativamente, use o Windows Terminal que tem melhor suporte a Unicode.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->