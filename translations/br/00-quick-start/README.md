<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "22b5d7c8d7585325e38b37fd29eafe25",
  "translation_date": "2026-01-05T23:02:05+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "br"
}
-->
# M√≥dulo 00: In√≠cio R√°pido

## √çndice

- [Introdu√ß√£o](../../../00-quick-start)
- [O que √© LangChain4j?](../../../00-quick-start)
- [Depend√™ncias LangChain4j](../../../00-quick-start)
- [Pr√©-requisitos](../../../00-quick-start)
- [Configura√ß√£o](../../../00-quick-start)
  - [1. Obtenha seu Token do GitHub](../../../00-quick-start)
  - [2. Configure seu Token](../../../00-quick-start)
- [Execute os Exemplos](../../../00-quick-start)
  - [1. Chat B√°sico](../../../00-quick-start)
  - [2. Padr√µes de Prompt](../../../00-quick-start)
  - [3. Chamada de Fun√ß√£o](../../../00-quick-start)
  - [4. Perguntas e Respostas de Documentos (RAG)](../../../00-quick-start)
  - [5. IA Respons√°vel](../../../00-quick-start)
- [O Que Cada Exemplo Mostra](../../../00-quick-start)
- [Pr√≥ximos Passos](../../../00-quick-start)
- [Resolu√ß√£o de Problemas](../../../00-quick-start)

## Introdu√ß√£o

Este in√≠cio r√°pido tem o objetivo de coloc√°-lo em funcionamento com LangChain4j o mais r√°pido poss√≠vel. Ele cobre o b√°sico absoluto de construir aplica√ß√µes de IA com LangChain4j e GitHub Models. Nos pr√≥ximos m√≥dulos, voc√™ usar√° Azure OpenAI com LangChain4j para construir aplica√ß√µes mais avan√ßadas.

## O que √© LangChain4j?

LangChain4j √© uma biblioteca Java que simplifica a constru√ß√£o de aplica√ß√µes com IA. Em vez de lidar com clientes HTTP e parsing de JSON, voc√™ trabalha com APIs Java limpas.

A "chain" em LangChain refere-se a encadear m√∫ltiplos componentes ‚Äì voc√™ pode encadear um prompt a um modelo, a um parser, ou encadear m√∫ltiplas chamadas de IA onde uma sa√≠da alimenta a pr√≥xima entrada. Este in√≠cio r√°pido enfoca os fundamentos antes de explorar cadeias mais complexas.

<img src="../../../translated_images/br/langchain-concept.ad1fe6cf063515e1.webp" alt="Conceito de Encadeamento do LangChain4j" width="800"/>

*Componentes encadeados no LangChain4j - blocos de constru√ß√£o conectados para criar fluxos de trabalho de IA poderosos*

Usaremos tr√™s componentes principais:

**ChatLanguageModel** - A interface para intera√ß√µes com modelos de IA. Chame `model.chat("prompt")` e obtenha uma string de resposta. Usamos `OpenAiOfficialChatModel` que funciona com endpoints compat√≠veis com OpenAI, como GitHub Models.

**AiServices** - Cria interfaces de servi√ßo de IA com tipagem segura. Defina m√©todos, anote-os com `@Tool`, e o LangChain4j gerencia a orquestra√ß√£o. A IA chama automaticamente seus m√©todos Java quando necess√°rio.

**MessageWindowChatMemory** - Mant√©m o hist√≥rico da conversa. Sem isso, cada requisi√ß√£o √© independente. Com ele, a IA lembra mensagens anteriores e mant√©m contexto por m√∫ltiplas intera√ß√µes.

<img src="../../../translated_images/br/architecture.eedc993a1c576839.webp" alt="Arquitetura LangChain4j" width="800"/>

*Arquitetura LangChain4j - componentes principais trabalhando juntos para potencializar suas aplica√ß√µes de IA*

## Depend√™ncias LangChain4j

Este in√≠cio r√°pido usa duas depend√™ncias Maven no [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

O m√≥dulo `langchain4j-open-ai-official` fornece a classe `OpenAiOfficialChatModel` que conecta a APIs compat√≠veis com OpenAI. GitHub Models usa o mesmo formato de API, ent√£o nenhum adaptador especial √© necess√°rio - apenas aponte a URL base para `https://models.github.ai/inference`.

## Pr√©-requisitos

**Usando o Container de Desenvolvimento?** Java e Maven j√° est√£o instalados. Voc√™ s√≥ precisa de um Token de Acesso Pessoal do GitHub.

**Desenvolvimento Local:**
- Java 21+, Maven 3.9+
- Token de Acesso Pessoal do GitHub (instru√ß√µes abaixo)

> **Nota:** Este m√≥dulo usa `gpt-4.1-nano` do GitHub Models. N√£o modifique o nome do modelo no c√≥digo - ele est√° configurado para funcionar com os modelos dispon√≠veis no GitHub.

## Configura√ß√£o

### 1. Obtenha seu Token do GitHub

1. V√° para [Configura√ß√µes do GitHub ‚Üí Tokens de Acesso Pessoal](https://github.com/settings/personal-access-tokens)
2. Clique em "Gerar novo token"
3. Defina um nome descritivo (ex.: "Demonstra√ß√£o LangChain4j")
4. Defina a expira√ß√£o (7 dias recomendados)
5. Em "Permiss√µes da conta", encontre "Models" e defina como "Somente leitura"
6. Clique em "Gerar token"
7. Copie e salve seu token - voc√™ n√£o ver√° ele novamente

### 2. Configure seu Token

**Op√ß√£o 1: Usando VS Code (Recomendado)**

Se estiver usando VS Code, adicione seu token ao arquivo `.env` na raiz do projeto:

Se o arquivo `.env` n√£o existir, copie `.env.example` para `.env` ou crie um novo arquivo `.env` na raiz do projeto.

**Exemplo de arquivo `.env`:**
```bash
# Em /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Ent√£o voc√™ pode simplesmente clicar com o bot√£o direito em qualquer arquivo de demonstra√ß√£o (ex.: `BasicChatDemo.java`) no Explorer e selecionar **"Run Java"** ou usar as configura√ß√µes de execu√ß√£o no painel Executar e Depurar.

**Op√ß√£o 2: Usando Terminal**

Configure o token como vari√°vel de ambiente:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## Execute os Exemplos

**Usando VS Code:** Basta clicar com o bot√£o direito em qualquer arquivo de demonstra√ß√£o no Explorer e selecionar **"Run Java"**, ou usar as configura√ß√µes de execu√ß√£o no painel Executar e Depurar (certifique-se de ter adicionado seu token ao arquivo `.env` antes).

**Usando Maven:** Alternativamente, voc√™ pode executar pela linha de comando:

### 1. Chat B√°sico

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Padr√µes de Prompt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Mostra prompt zero-shot, few-shot, chain-of-thought, e baseados em pap√©is.

### 3. Chamada de Fun√ß√£o

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

A IA chama automaticamente seus m√©todos Java quando necess√°rio.

### 4. Perguntas e Respostas de Documentos (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

Fa√ßa perguntas sobre o conte√∫do em `document.txt`.

### 5. IA Respons√°vel

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

Veja como filtros de seguran√ßa da IA bloqueiam conte√∫do prejudicial.

## O Que Cada Exemplo Mostra

**Chat B√°sico** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

Comece aqui para ver o LangChain4j na sua forma mais simples. Voc√™ criar√° um `OpenAiOfficialChatModel`, enviar√° um prompt com `.chat()`, e receber√° uma resposta. Isso demonstra a base: como inicializar modelos com endpoints customizados e chaves de API. Uma vez que voc√™ entenda esse padr√£o, tudo o mais √© constru√≠do a partir dele.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) e pergunte:
> - "Como eu mudaria dos GitHub Models para Azure OpenAI neste c√≥digo?"
> - "Quais outros par√¢metros posso configurar no OpenAiOfficialChatModel.builder()?"
> - "Como adiciono respostas em streaming em vez de esperar pela resposta completa?"

**Engenharia de Prompt** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Agora que voc√™ sabe como conversar com um modelo, vamos explorar o que voc√™ diz a ele. Esta demo usa a mesma configura√ß√£o de modelo, mas mostra quatro padr√µes diferentes de prompting. Experimente prompts zero-shot para instru√ß√µes diretas, few-shot que aprendem com exemplos, chain-of-thought que revelam passos de racioc√≠nio, e prompts baseados em pap√©is que estabelecem contexto. Voc√™ ver√° como o mesmo modelo d√° resultados dramaticamente diferentes dependendo de como voc√™ enquadra seu pedido.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) e pergunte:
> - "Qual √© a diferen√ßa entre prompt zero-shot e few-shot, e quando devo usar cada um?"
> - "Como o par√¢metro temperature afeta as respostas do modelo?"
> - "Quais s√£o algumas t√©cnicas para prevenir ataques de inje√ß√£o de prompt em produ√ß√£o?"
> - "Como posso criar objetos PromptTemplate reutiliz√°veis para padr√µes comuns?"

**Integra√ß√£o de Ferramentas** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

Aqui √© onde o LangChain4j fica poderoso. Voc√™ usar√° `AiServices` para criar um assistente de IA que pode chamar seus m√©todos Java. Basta anotar m√©todos com `@Tool("descri√ß√£o")` e o LangChain4j faz o resto - a IA decide automaticamente quando usar cada ferramenta baseado no que o usu√°rio pede. Isso demonstra chamada de fun√ß√£o, uma t√©cnica chave para construir IA que pode agir, n√£o apenas responder perguntas.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) e pergunte:
> - "Como funciona a anota√ß√£o @Tool e o que o LangChain4j faz com ela por tr√°s dos panos?"
> - "A IA pode chamar m√∫ltiplas ferramentas em sequ√™ncia para resolver problemas complexos?"
> - "O que acontece se uma ferramenta lan√ßa uma exce√ß√£o - como devo tratar erros?"
> - "Como eu integraria uma API real em vez deste exemplo de calculadora?"

**Perguntas e Respostas de Documentos (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

Aqui voc√™ ver√° a base do RAG (recupera√ß√£o aumentada por gera√ß√£o). Em vez de depender dos dados de treinamento do modelo, voc√™ carrega o conte√∫do do [`document.txt`](../../../00-quick-start/document.txt) e o inclui no prompt. A IA responde com base no seu documento, n√£o no conhecimento geral dela. Este √© o primeiro passo para construir sistemas que trabalham com seus pr√≥prios dados.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Nota:** Esta abordagem simples carrega o documento inteiro no prompt. Para arquivos grandes (>10KB), voc√™ ultrapassar√° os limites de contexto. O M√≥dulo 03 cobre segmenta√ß√£o e busca vetorial para sistemas RAG em produ√ß√£o.

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) e pergunte:
> - "Como o RAG previne alucina√ß√µes da IA comparado ao uso dos dados de treinamento do modelo?"
> - "Qual a diferen√ßa entre esta abordagem simples e usar embeddings vetoriais para recupera√ß√£o?"
> - "Como eu escalaria isso para lidar com m√∫ltiplos documentos ou bases de conhecimento maiores?"
> - "Quais s√£o as melhores pr√°ticas para estruturar o prompt para garantir que a IA use somente o contexto fornecido?"

**IA Respons√°vel** - [ResponsibleAIDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java)

Construa seguran√ßa em IA com defesa em profundidade. Esta demo mostra duas camadas de prote√ß√£o trabalhando juntas:

**Parte 1: LangChain4j Input Guardrails** - Bloqueia prompts perigosos antes de chegarem ao LLM. Crie guardrails customizados que verificam por palavras-chave ou padr√µes proibidos. Eles rodam no seu c√≥digo, ent√£o s√£o r√°pidos e gratuitos.

```java
class DangerousContentGuardrail implements InputGuardrail {
    @Override
    public InputGuardrailResult validate(UserMessage userMessage) {
        String text = userMessage.singleText().toLowerCase();
        if (text.contains("explosives")) {
            return fatal("Blocked: contains prohibited keyword");
        }
        return success();
    }
}
```

**Parte 2: Filtros de Seguran√ßa do Provedor** - GitHub Models tem filtros embutidos que pegam o que seus guardrails podem perder. Voc√™ ver√° bloqueios r√≠gidos (erros HTTP 400) para viola√ß√µes graves e recusas suaves onde a IA recusa educadamente.

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`ResponsibleAIDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java) e pergunte:
> - "O que √© InputGuardrail e como eu crio o meu pr√≥prio?"
> - "Qual √© a diferen√ßa entre bloqueio r√≠gido e recusa suave?"
> - "Por que usar guardrails e filtros do provedor juntos?"

## Pr√≥ximos Passos

**Pr√≥ximo M√≥dulo:** [01-introduction - Come√ßando com LangChain4j e gpt-5 na Azure](../01-introduction/README.md)

---

**Navega√ß√£o:** [‚Üê Voltar ao In√≠cio](../README.md) | [Pr√≥ximo: M√≥dulo 01 - Introdu√ß√£o ‚Üí](../01-introduction/README.md)

---

## Resolu√ß√£o de Problemas

### Primeira Build Maven

**Problema:** `mvn clean compile` ou `mvn package` iniciais demoram muito (10-15 minutos)

**Causa:** Maven precisa baixar todas as depend√™ncias do projeto (Spring Boot, bibliotecas LangChain4j, SDKs Azure, etc.) na primeira build.

**Solu√ß√£o:** Isso √© comportamento normal. Builds subsequentes ser√£o muito mais r√°pidas pois as depend√™ncias ficam em cache localmente. O tempo de download depende da velocidade da sua rede.

### Sintaxe de Comando Maven no PowerShell

**Problema:** Comandos Maven falham com erro `Unknown lifecycle phase ".mainClass=..."`

**Causa:** PowerShell interpreta `=` como operador de atribui√ß√£o de vari√°vel, quebrando a sintaxe de propriedade do Maven
**Solu√ß√£o**: Use o operador de parada de an√°lise `--%` antes do comando Maven:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

O operador `--%` diz ao PowerShell para passar todos os argumentos restantes literalmente para o Maven sem interpreta√ß√£o.

### Exibi√ß√£o de Emojis no Windows PowerShell

**Problema**: Respostas da IA mostram caracteres ileg√≠veis (ex.: `????` ou `√¢??`) em vez de emojis no PowerShell

**Causa**: A codifica√ß√£o padr√£o do PowerShell n√£o suporta emojis UTF-8

**Solu√ß√£o**: Execute este comando antes de executar aplica√ß√µes Java:
```cmd
chcp 65001
```

Isso for√ßa a codifica√ß√£o UTF-8 no terminal. Alternativamente, use o Windows Terminal que possui melhor suporte a Unicode.

### Depura√ß√£o de Chamadas de API

**Problema**: Erros de autentica√ß√£o, limites de taxa ou respostas inesperadas do modelo de IA

**Solu√ß√£o**: Os exemplos incluem `.logRequests(true)` e `.logResponses(true)` para mostrar chamadas de API no console. Isso ajuda a diagnosticar erros de autentica√ß√£o, limites de taxa ou respostas inesperadas. Remova essas flags em produ√ß√£o para reduzir o ru√≠do do log.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, por favor, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->