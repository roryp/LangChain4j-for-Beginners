<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f538a51cfd13147d40d84e936a0f485c",
  "translation_date": "2025-12-13T16:59:32+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "br"
}
-->
# M√≥dulo 03: RAG (Gera√ß√£o Aumentada por Recupera√ß√£o)

## √çndice

- [O que voc√™ vai aprender](../../../03-rag)
- [Pr√©-requisitos](../../../03-rag)
- [Entendendo o RAG](../../../03-rag)
- [Como funciona](../../../03-rag)
  - [Processamento de Documentos](../../../03-rag)
  - [Criando Embeddings](../../../03-rag)
  - [Busca Sem√¢ntica](../../../03-rag)
  - [Gera√ß√£o de Respostas](../../../03-rag)
- [Executar a Aplica√ß√£o](../../../03-rag)
- [Usando a Aplica√ß√£o](../../../03-rag)
  - [Enviar um Documento](../../../03-rag)
  - [Fazer Perguntas](../../../03-rag)
  - [Verificar Refer√™ncias de Fonte](../../../03-rag)
  - [Experimentar com Perguntas](../../../03-rag)
- [Conceitos-Chave](../../../03-rag)
  - [Estrat√©gia de Chunking](../../../03-rag)
  - [Pontua√ß√µes de Similaridade](../../../03-rag)
  - [Armazenamento em Mem√≥ria](../../../03-rag)
  - [Gerenciamento da Janela de Contexto](../../../03-rag)
- [Quando o RAG √© Importante](../../../03-rag)
- [Pr√≥ximos Passos](../../../03-rag)

## O que voc√™ vai aprender

Nos m√≥dulos anteriores, voc√™ aprendeu como ter conversas com IA e estruturar seus prompts de forma eficaz. Mas h√° uma limita√ß√£o fundamental: modelos de linguagem s√≥ sabem o que aprenderam durante o treinamento. Eles n√£o conseguem responder perguntas sobre as pol√≠ticas da sua empresa, a documenta√ß√£o do seu projeto ou qualquer informa√ß√£o que n√£o tenha sido inclu√≠da no treinamento.

O RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) resolve esse problema. Em vez de tentar ensinar o modelo com suas informa√ß√µes (o que √© caro e impratic√°vel), voc√™ d√° a ele a capacidade de buscar em seus documentos. Quando algu√©m faz uma pergunta, o sistema encontra informa√ß√µes relevantes e as inclui no prompt. O modelo ent√£o responde com base nesse contexto recuperado.

Pense no RAG como dar ao modelo uma biblioteca de refer√™ncia. Quando voc√™ faz uma pergunta, o sistema:

1. **Consulta do Usu√°rio** - Voc√™ faz uma pergunta  
2. **Embedding** - Converte sua pergunta em um vetor  
3. **Busca Vetorial** - Encontra peda√ßos de documentos similares  
4. **Montagem do Contexto** - Adiciona os peda√ßos relevantes ao prompt  
5. **Resposta** - O LLM gera uma resposta baseada no contexto  

Isso fundamenta as respostas do modelo nos seus dados reais, em vez de depender do conhecimento do treinamento ou inventar respostas.

<img src="../../../translated_images/rag-architecture.ccb53b71a6ce407fa8a6394c7a747eb9ad40f6334b4c217be0439d700f22bbcc.br.png" alt="Arquitetura RAG" width="800"/>

*Fluxo de trabalho do RAG - da consulta do usu√°rio √† busca sem√¢ntica at√© a gera√ß√£o de resposta contextual*

## Pr√©-requisitos

- M√≥dulo 01 conclu√≠do (recursos Azure OpenAI implantados)  
- Arquivo `.env` no diret√≥rio raiz com credenciais Azure (criado pelo `azd up` no M√≥dulo 01)  

> **Nota:** Se voc√™ n√£o concluiu o M√≥dulo 01, siga as instru√ß√µes de implanta√ß√£o l√° primeiro.

## Como funciona

**Processamento de Documentos** - [DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

Quando voc√™ envia um documento, o sistema o divide em peda√ßos ‚Äî partes menores que cabem confortavelmente na janela de contexto do modelo. Esses peda√ßos se sobrep√µem ligeiramente para que voc√™ n√£o perca o contexto nas bordas.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) e pergunte:  
> - "Como o LangChain4j divide documentos em peda√ßos e por que a sobreposi√ß√£o √© importante?"  
> - "Qual √© o tamanho ideal dos peda√ßos para diferentes tipos de documentos e por qu√™?"  
> - "Como lidar com documentos em m√∫ltiplos idiomas ou com formata√ß√£o especial?"

**Criando Embeddings** - [LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Cada peda√ßo √© convertido em uma representa√ß√£o num√©rica chamada embedding ‚Äî essencialmente uma impress√£o digital matem√°tica que captura o significado do texto. Textos similares produzem embeddings similares.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```

<img src="../../../translated_images/vector-embeddings.2ef7bdddac79a327ad9e3e46cde9a86f5eeefbeb3edccd387e33018c1671cecd.br.png" alt="Espa√ßo de Embeddings Vetoriais" width="800"/>

*Documentos representados como vetores no espa√ßo de embeddings - conte√∫dos similares se agrupam*

**Busca Sem√¢ntica** - [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Quando voc√™ faz uma pergunta, sua pergunta tamb√©m vira um embedding. O sistema compara o embedding da sua pergunta com os embeddings de todos os peda√ßos de documentos. Ele encontra os peda√ßos com significados mais similares ‚Äî n√£o apenas palavras-chave correspondentes, mas similaridade sem√¢ntica real.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```

> **ü§ñ Experimente com o [GitHub Copilot](https://github.com/features/copilot) Chat:** Abra [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) e pergunte:  
> - "Como funciona a busca por similaridade com embeddings e o que determina a pontua√ß√£o?"  
> - "Qual limiar de similaridade devo usar e como isso afeta os resultados?"  
> - "Como lidar com casos onde nenhum documento relevante √© encontrado?"

**Gera√ß√£o de Respostas** - [RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

Os peda√ßos mais relevantes s√£o inclu√≠dos no prompt para o modelo. O modelo l√™ esses peda√ßos espec√≠ficos e responde sua pergunta com base nessa informa√ß√£o. Isso previne alucina√ß√µes ‚Äî o modelo s√≥ pode responder com o que est√° √† sua frente.

## Executar a Aplica√ß√£o

**Verifique a implanta√ß√£o:**

Certifique-se de que o arquivo `.env` existe no diret√≥rio raiz com as credenciais Azure (criado durante o M√≥dulo 01):  
```bash
cat ../.env  # Deve mostrar AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**Inicie a aplica√ß√£o:**

> **Nota:** Se voc√™ j√° iniciou todas as aplica√ß√µes usando `./start-all.sh` do M√≥dulo 01, este m√≥dulo j√° est√° rodando na porta 8081. Voc√™ pode pular os comandos de in√≠cio abaixo e ir direto para http://localhost:8081.

**Op√ß√£o 1: Usando o Spring Boot Dashboard (Recomendado para usu√°rios VS Code)**

O container de desenvolvimento inclui a extens√£o Spring Boot Dashboard, que fornece uma interface visual para gerenciar todas as aplica√ß√µes Spring Boot. Voc√™ pode encontr√°-la na Barra de Atividades √† esquerda do VS Code (procure o √≠cone do Spring Boot).

No Spring Boot Dashboard, voc√™ pode:  
- Ver todas as aplica√ß√µes Spring Boot dispon√≠veis no workspace  
- Iniciar/parar aplica√ß√µes com um clique  
- Visualizar logs da aplica√ß√£o em tempo real  
- Monitorar o status da aplica√ß√£o  

Basta clicar no bot√£o de play ao lado de "rag" para iniciar este m√≥dulo, ou iniciar todos os m√≥dulos de uma vez.

<img src="../../../translated_images/dashboard.fbe6e28bf4267ffe4f95a708ecd46e78f69fd46a562d2a766e73c98fe0f53922.br.png" alt="Spring Boot Dashboard" width="400"/>

**Op√ß√£o 2: Usando scripts shell**

Inicie todas as aplica√ß√µes web (m√≥dulos 01-04):

**Bash:**  
```bash
cd ..  # A partir do diret√≥rio raiz
./start-all.sh
```
  
**PowerShell:**  
```powershell
cd ..  # A partir do diret√≥rio raiz
.\start-all.ps1
```
  
Ou inicie apenas este m√≥dulo:

**Bash:**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell:**  
```powershell
cd 03-rag
.\start.ps1
```
  
Ambos os scripts carregam automaticamente as vari√°veis de ambiente do arquivo `.env` raiz e ir√£o construir os JARs se eles n√£o existirem.

> **Nota:** Se preferir construir todos os m√≥dulos manualmente antes de iniciar:  
>  
> **Bash:**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>  
> **PowerShell:**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
Abra http://localhost:8081 no seu navegador.

**Para parar:**

**Bash:**  
```bash
./stop.sh  # Apenas este m√≥dulo
# Ou
cd .. && ./stop-all.sh  # Todos os m√≥dulos
```
  
**PowerShell:**  
```powershell
.\stop.ps1  # Apenas este m√≥dulo
# Ou
cd ..; .\stop-all.ps1  # Todos os m√≥dulos
```
  
## Usando a Aplica√ß√£o

A aplica√ß√£o fornece uma interface web para envio de documentos e perguntas.

<a href="images/rag-homepage.png"><img src="../../../translated_images/rag-homepage.d90eb5ce1b3caa94987b4fa2923d3cb884a67987cf2f994ca53756c6586a93b1.br.png" alt="Interface da Aplica√ß√£o RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Interface da aplica√ß√£o RAG - envie documentos e fa√ßa perguntas*

**Enviar um Documento**

Comece enviando um documento ‚Äî arquivos TXT funcionam melhor para testes. Um `sample-document.txt` est√° dispon√≠vel neste diret√≥rio e cont√©m informa√ß√µes sobre recursos do LangChain4j, implementa√ß√£o do RAG e melhores pr√°ticas ‚Äî perfeito para testar o sistema.

O sistema processa seu documento, divide em peda√ßos e cria embeddings para cada peda√ßo. Isso acontece automaticamente ao enviar.

**Fazer Perguntas**

Agora fa√ßa perguntas espec√≠ficas sobre o conte√∫do do documento. Tente algo factual que esteja claramente declarado no documento. O sistema busca peda√ßos relevantes, os inclui no prompt e gera uma resposta.

**Verificar Refer√™ncias de Fonte**

Note que cada resposta inclui refer√™ncias de fonte com pontua√ß√µes de similaridade. Essas pontua√ß√µes (de 0 a 1) mostram o qu√£o relevante cada peda√ßo foi para sua pergunta. Pontua√ß√µes mais altas significam melhores correspond√™ncias. Isso permite que voc√™ verifique a resposta com o material fonte.

<a href="images/rag-query-results.png"><img src="../../../translated_images/rag-query-results.6d69fcec5397f3558c788388bb395191616dad4c7c0417f1a68bd18590ad0a0e.br.png" alt="Resultados da Consulta RAG" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Resultados da consulta mostrando resposta com refer√™ncias de fonte e pontua√ß√µes de relev√¢ncia*

**Experimentar com Perguntas**

Tente diferentes tipos de perguntas:  
- Fatos espec√≠ficos: "Qual √© o tema principal?"  
- Compara√ß√µes: "Qual a diferen√ßa entre X e Y?"  
- Resumos: "Resuma os pontos-chave sobre Z"  

Observe como as pontua√ß√µes de relev√¢ncia mudam conforme sua pergunta combina com o conte√∫do do documento.

## Conceitos-Chave

**Estrat√©gia de Chunking**

Documentos s√£o divididos em peda√ßos de 300 tokens com 30 tokens de sobreposi√ß√£o. Esse equil√≠brio garante que cada peda√ßo tenha contexto suficiente para ser significativo, mantendo-os pequenos o bastante para incluir m√∫ltiplos peda√ßos em um prompt.

**Pontua√ß√µes de Similaridade**

As pontua√ß√µes variam de 0 a 1:  
- 0.7-1.0: Altamente relevante, correspond√™ncia exata  
- 0.5-0.7: Relevante, bom contexto  
- Abaixo de 0.5: Filtrado, muito diferente  

O sistema s√≥ recupera peda√ßos acima do limiar m√≠nimo para garantir qualidade.

**Armazenamento em Mem√≥ria**

Este m√≥dulo usa armazenamento em mem√≥ria para simplicidade. Quando voc√™ reinicia a aplica√ß√£o, os documentos enviados s√£o perdidos. Sistemas de produ√ß√£o usam bancos de dados vetoriais persistentes como Qdrant ou Azure AI Search.

**Gerenciamento da Janela de Contexto**

Cada modelo tem uma janela m√°xima de contexto. Voc√™ n√£o pode incluir todos os peda√ßos de um documento grande. O sistema recupera os N peda√ßos mais relevantes (padr√£o 5) para ficar dentro dos limites, fornecendo contexto suficiente para respostas precisas.

## Quando o RAG √© Importante

**Use RAG quando:**  
- Responder perguntas sobre documentos propriet√°rios  
- Informa√ß√µes mudam frequentemente (pol√≠ticas, pre√ßos, especifica√ß√µes)  
- Precisar de precis√£o com atribui√ß√£o de fonte  
- Conte√∫do √© grande demais para caber em um √∫nico prompt  
- Voc√™ precisa de respostas verific√°veis e fundamentadas  

**N√£o use RAG quando:**  
- Perguntas requerem conhecimento geral que o modelo j√° tem  
- Dados em tempo real s√£o necess√°rios (RAG funciona com documentos enviados)  
- Conte√∫do √© pequeno o suficiente para incluir diretamente nos prompts  

## Pr√≥ximos Passos

**Pr√≥ximo M√≥dulo:** [04-tools - Agentes de IA com Ferramentas](../04-tools/README.md)

---

**Navega√ß√£o:** [‚Üê Anterior: M√≥dulo 02 - Engenharia de Prompt](../02-prompt-engineering/README.md) | [Voltar ao In√≠cio](../README.md) | [Pr√≥ximo: M√≥dulo 04 - Ferramentas ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->