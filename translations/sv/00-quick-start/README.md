<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "377b3e3e6f8d02965bf0fbbc9ccb45c5",
  "translation_date": "2025-12-13T14:58:45+00:00",
  "source_file": "00-quick-start/README.md",
  "language_code": "sv"
}
-->
# Module 00: Kom ig√•ng snabbt

## Inneh√•llsf√∂rteckning

- [Introduktion](../../../00-quick-start)
- [Vad √§r LangChain4j?](../../../00-quick-start)
- [LangChain4j beroenden](../../../00-quick-start)
- [F√∂ruts√§ttningar](../../../00-quick-start)
- [Installation](../../../00-quick-start)
  - [1. Skaffa din GitHub-token](../../../00-quick-start)
  - [2. St√§ll in din token](../../../00-quick-start)
- [K√∂r exemplen](../../../00-quick-start)
  - [1. Grundl√§ggande chatt](../../../00-quick-start)
  - [2. Promptm√∂nster](../../../00-quick-start)
  - [3. Funktionsanrop](../../../00-quick-start)
  - [4. Dokument Q&A (RAG)](../../../00-quick-start)
- [Vad varje exempel visar](../../../00-quick-start)
- [N√§sta steg](../../../00-quick-start)
- [Fels√∂kning](../../../00-quick-start)

## Introduktion

Denna snabbstart √§r avsedd att f√• dig ig√•ng med LangChain4j s√• snabbt som m√∂jligt. Den t√§cker det absolut grundl√§ggande f√∂r att bygga AI-applikationer med LangChain4j och GitHub Models. I n√§sta moduler kommer du att anv√§nda Azure OpenAI med LangChain4j f√∂r att bygga mer avancerade applikationer.

## Vad √§r LangChain4j?

LangChain4j √§r ett Java-bibliotek som f√∂renklar byggandet av AI-drivna applikationer. Ist√§llet f√∂r att hantera HTTP-klienter och JSON-parsing arbetar du med rena Java-API:er.

"Chain" i LangChain syftar p√• att kedja ihop flera komponenter ‚Äì du kan kedja en prompt till en modell till en parser, eller kedja flera AI-anrop d√§r en output matas in som n√§sta input. Denna snabbstart fokuserar p√• grunderna innan vi utforskar mer komplexa kedjor.

<img src="../../../translated_images/langchain-concept.ad1fe6cf063515e1e961a13c73d45cfa305fd03d81bd11e5d34d0e36ed28a44d.sv.png" alt="LangChain4j Chaining Concept" width="800"/>

*Kedjning av komponenter i LangChain4j ‚Äì byggstenar kopplas ihop f√∂r att skapa kraftfulla AI-arbetsfl√∂den*

Vi anv√§nder tre k√§rnkomponenter:

**ChatLanguageModel** ‚Äì Gr√§nssnittet f√∂r AI-modellinteraktioner. Anropa `model.chat("prompt")` och f√• en svarstr√§ng. Vi anv√§nder `OpenAiOfficialChatModel` som fungerar med OpenAI-kompatibla endpoints som GitHub Models.

**AiServices** ‚Äì Skapar typ-s√§kra AI-tj√§nstegr√§nssnitt. Definiera metoder, annotera dem med `@Tool`, och LangChain4j hanterar orkestreringen. AI:n anropar automatiskt dina Java-metoder vid behov.

**MessageWindowChatMemory** ‚Äì Beh√•ller konversationshistorik. Utan detta √§r varje f√∂rfr√•gan oberoende. Med detta minns AI tidigare meddelanden och beh√•ller kontext √∂ver flera turer.

<img src="../../../translated_images/architecture.eedc993a1c57683951f20244f652fc7a9853f571eea835bc2b2828cf0dbf62d0.sv.png" alt="LangChain4j Architecture" width="800"/>

*LangChain4j-arkitektur ‚Äì k√§rnkomponenter som samarbetar f√∂r att driva dina AI-applikationer*

## LangChain4j beroenden

Denna snabbstart anv√§nder tv√• Maven-beroenden i [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

Modulen `langchain4j-open-ai-official` tillhandah√•ller klassen `OpenAiOfficialChatModel` som kopplar till OpenAI-kompatibla API:er. GitHub Models anv√§nder samma API-format, s√• ingen speciell adapter beh√∂vs ‚Äì peka bara bas-URL:en till `https://models.github.ai/inference`.

## F√∂ruts√§ttningar

**Anv√§nder du Dev Container?** Java och Maven √§r redan installerade. Du beh√∂ver bara en GitHub Personal Access Token.

**Lokal utveckling:**
- Java 21+, Maven 3.9+
- GitHub Personal Access Token (instruktioner nedan)

> **Notera:** Denna modul anv√§nder `gpt-4.1-nano` fr√•n GitHub Models. √Ñndra inte modellnamnet i koden ‚Äì det √§r konfigurerat f√∂r att fungera med GitHubs tillg√§ngliga modeller.

## Installation

### 1. Skaffa din GitHub-token

1. G√• till [GitHub Inst√§llningar ‚Üí Personal Access Tokens](https://github.com/settings/personal-access-tokens)
2. Klicka p√• "Generate new token"
3. S√§tt ett beskrivande namn (t.ex. "LangChain4j Demo")
4. S√§tt utg√•ngsdatum (7 dagar rekommenderas)
5. Under "Account permissions", hitta "Models" och s√§tt till "Read-only"
6. Klicka p√• "Generate token"
7. Kopiera och spara din token ‚Äì du kommer inte att se den igen

### 2. St√§ll in din token

**Alternativ 1: Anv√§nda VS Code (Rekommenderas)**

Om du anv√§nder VS Code, l√§gg till din token i `.env`-filen i projektets rotmapp:

Om `.env`-filen inte finns, kopiera `.env.example` till `.env` eller skapa en ny `.env`-fil i projektets rotmapp.

**Exempel p√• `.env`-fil:**
```bash
# I /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

D√§refter kan du enkelt h√∂gerklicka p√• vilken demo-fil som helst (t.ex. `BasicChatDemo.java`) i Utforskaren och v√§lja **"Run Java"** eller anv√§nda startkonfigurationerna fr√•n panelen K√∂r och Debugga.

**Alternativ 2: Anv√§nda terminal**

S√§tt token som en milj√∂variabel:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## K√∂r exemplen

**Anv√§nder du VS Code:** H√∂gerklicka p√• vilken demo-fil som helst i Utforskaren och v√§lj **"Run Java"**, eller anv√§nd startkonfigurationerna fr√•n panelen K√∂r och Debugga (se till att du f√∂rst lagt till din token i `.env`-filen).

**Anv√§nder du Maven:** Alternativt kan du k√∂ra fr√•n kommandoraden:

### 1. Grundl√§ggande chatt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Promptm√∂nster

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Visar zero-shot, few-shot, chain-of-thought och rollbaserad prompting.

### 3. Funktionsanrop

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

AI anropar automatiskt dina Java-metoder vid behov.

### 4. Dokument Q&A (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

St√§ll fr√•gor om inneh√•llet i `document.txt`.

## Vad varje exempel visar

**Grundl√§ggande chatt** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

B√∂rja h√§r f√∂r att se LangChain4j i sin enklaste form. Du skapar en `OpenAiOfficialChatModel`, skickar en prompt med `.chat()` och f√•r tillbaka ett svar. Detta visar grunden: hur man initierar modeller med anpassade endpoints och API-nycklar. N√§r du f√∂rst√•r detta m√∂nster bygger allt annat p√• det.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Prova med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) och fr√•ga:
> - "Hur byter jag fr√•n GitHub Models till Azure OpenAI i denna kod?"
> - "Vilka andra parametrar kan jag konfigurera i OpenAiOfficialChatModel.builder()?"
> - "Hur l√§gger jag till str√∂mmande svar ist√§llet f√∂r att v√§nta p√• hela svaret?"

**Prompt Engineering** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Nu n√§r du vet hur man pratar med en modell, l√•t oss utforska vad du s√§ger till den. Denna demo anv√§nder samma modellupps√§ttning men visar fyra olika promptm√∂nster. Prova zero-shot prompts f√∂r direkta instruktioner, few-shot prompts som l√§r sig fr√•n exempel, chain-of-thought prompts som visar resonemangssteg, och rollbaserade prompts som s√§tter kontext. Du kommer att se hur samma modell ger dramatiskt olika resultat beroende p√• hur du formulerar din f√∂rfr√•gan.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Prova med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) och fr√•ga:
> - "Vad √§r skillnaden mellan zero-shot och few-shot prompting, och n√§r ska jag anv√§nda varje?"
> - "Hur p√•verkar temperaturparametern modellens svar?"
> - "Vilka tekniker finns f√∂r att f√∂rhindra promptinjektionsattacker i produktion?"
> - "Hur kan jag skapa √•teranv√§ndbara PromptTemplate-objekt f√∂r vanliga m√∂nster?"

**Verktygsintegration** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

H√§r blir LangChain4j kraftfullt. Du anv√§nder `AiServices` f√∂r att skapa en AI-assistent som kan anropa dina Java-metoder. Annotera bara metoder med `@Tool("beskrivning")` och LangChain4j sk√∂ter resten ‚Äì AI:n best√§mmer automatiskt n√§r varje verktyg ska anv√§ndas baserat p√• vad anv√§ndaren fr√•gar. Detta demonstrerar funktionsanrop, en nyckelteknik f√∂r att bygga AI som kan agera, inte bara svara p√• fr√•gor.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Prova med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) och fr√•ga:
> - "Hur fungerar @Tool-annoteringen och vad g√∂r LangChain4j med den bakom kulisserna?"
> - "Kan AI anropa flera verktyg i f√∂ljd f√∂r att l√∂sa komplexa problem?"
> - "Vad h√§nder om ett verktyg kastar ett undantag ‚Äì hur b√∂r jag hantera fel?"
> - "Hur skulle jag integrera ett riktigt API ist√§llet f√∂r detta kalkylatorexempel?"

**Dokument Q&A (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

H√§r ser du grunden f√∂r RAG (retrieval-augmented generation). Ist√§llet f√∂r att f√∂rlita sig p√• modellens tr√§ningsdata laddar du inneh√•ll fr√•n [`document.txt`](../../../00-quick-start/document.txt) och inkluderar det i prompten. AI:n svarar baserat p√• ditt dokument, inte dess allm√§nna kunskap. Detta √§r f√∂rsta steget mot att bygga system som kan arbeta med dina egna data.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Notera:** Detta enkla tillv√§gag√•ngss√§tt laddar hela dokumentet i prompten. F√∂r stora filer (>10KB) √∂verskrider du kontextgr√§nser. Modul 03 t√§cker chunkning och vektors√∂kning f√∂r produktions-RAG-system.

> **ü§ñ Prova med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) och fr√•ga:
> - "Hur f√∂rhindrar RAG AI-hallucinationer j√§mf√∂rt med att anv√§nda modellens tr√§ningsdata?"
> - "Vad √§r skillnaden mellan detta enkla tillv√§gag√•ngss√§tt och att anv√§nda vektor-embeddingar f√∂r h√§mtning?"
> - "Hur skulle jag skala detta f√∂r att hantera flera dokument eller st√∂rre kunskapsbaser?"
> - "Vilka √§r b√§sta praxis f√∂r att strukturera prompten f√∂r att s√§kerst√§lla att AI bara anv√§nder den angivna kontexten?"

## Fels√∂kning

Exemplen inkluderar `.logRequests(true)` och `.logResponses(true)` f√∂r att visa API-anrop i konsolen. Detta hj√§lper till att fels√∂ka autentiseringsfel, hastighetsbegr√§nsningar eller ov√§ntade svar. Ta bort dessa flaggor i produktion f√∂r att minska loggbrus.

## N√§sta steg

**N√§sta modul:** [01-introduction - Kom ig√•ng med LangChain4j och gpt-5 p√• Azure](../01-introduction/README.md)

---

**Navigering:** [‚Üê Tillbaka till huvudmenyn](../README.md) | [N√§sta: Modul 01 - Introduktion ‚Üí](../01-introduction/README.md)

---

## Fels√∂kning

### F√∂rsta Maven-bygget

**Problem:** Initialt `mvn clean compile` eller `mvn package` tar l√•ng tid (10-15 minuter)

**Orsak:** Maven beh√∂ver ladda ner alla projektberoenden (Spring Boot, LangChain4j-bibliotek, Azure SDK:er, etc.) vid f√∂rsta bygget.

**L√∂sning:** Detta √§r normalt. Efterf√∂ljande byggen g√•r mycket snabbare eftersom beroenden cachas lokalt. Nedladdningstiden beror p√• din n√§tverkshastighet.

### PowerShell Maven-kommandosyntax

**Problem:** Maven-kommandon misslyckas med fel `Unknown lifecycle phase ".mainClass=..."`

**Orsak:** PowerShell tolkar `=` som en variabeltilldelningsoperator, vilket bryter Maven-egenskapsyntaxen

**L√∂sning:** Anv√§nd stopparsing-operatorn `--%` f√∂re Maven-kommandot:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

Operatorn `--%` talar om f√∂r PowerShell att skicka alla √•terst√•ende argument bokstavligt till Maven utan tolkning.

### Windows PowerShell Emoji-visning

**Problem:** AI-svar visar skr√§ptecken (t.ex. `????` eller `√¢??`) ist√§llet f√∂r emojis i PowerShell

**Orsak:** PowerShells standardkodning st√∂djer inte UTF-8-emojis

**L√∂sning:** K√∂r detta kommando innan du k√∂r Java-applikationer:
```cmd
chcp 65001
```

Detta tvingar UTF-8-kodning i terminalen. Alternativt kan du anv√§nda Windows Terminal som har b√§ttre Unicode-st√∂d.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfriskrivning**:
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, v√§nligen var medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r till f√∂ljd av anv√§ndningen av denna √∂vers√§ttning.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->