# Modul 00: Snabbstart

## Inneh√•llsf√∂rteckning

- [Introduktion](../../../00-quick-start)
- [Vad √§r LangChain4j?](../../../00-quick-start)
- [LangChain4j beroenden](../../../00-quick-start)
- [F√∂ruts√§ttningar](../../../00-quick-start)
- [Installation](../../../00-quick-start)
  - [1. Skaffa din GitHub-token](../../../00-quick-start)
  - [2. S√§tt din token](../../../00-quick-start)
- [K√∂r exemplen](../../../00-quick-start)
  - [1. Enkel chatt](../../../00-quick-start)
  - [2. Promptm√∂nster](../../../00-quick-start)
  - [3. Funktionsanrop](../../../00-quick-start)
  - [4. Dokument Q&A (RAG)](../../../00-quick-start)
  - [5. Ansvarsfull AI](../../../00-quick-start)
- [Vad varje exempel visar](../../../00-quick-start)
- [N√§sta steg](../../../00-quick-start)
- [Fels√∂kning](../../../00-quick-start)

## Introduktion

Denna snabbstart √§r avsedd att f√• dig ig√•ng med LangChain4j s√• snabbt som m√∂jligt. Den t√§cker det absoluta grunderna f√∂r att bygga AI-applikationer med LangChain4j och GitHub Models. I de kommande modulerna kommer du att anv√§nda Azure OpenAI med LangChain4j f√∂r att bygga mer avancerade applikationer.

## Vad √§r LangChain4j?

LangChain4j √§r ett Java-bibliotek som f√∂renklar skapandet av AI-drivna applikationer. Ist√§llet f√∂r att hantera HTTP-klienter och JSON-parsing arbetar du med rena Java-API:er.

"Chain" i LangChain syftar p√• att kedja ihop flera komponenter - du kan kedja en prompt till en modell till en parser, eller kedja flera AI-anrop d√§r en utdata matas in som n√§sta indata. Den h√§r snabbstarten fokuserar p√• grunderna innan vi utforskar mer komplexa kedjor.

<img src="../../../translated_images/sv/langchain-concept.ad1fe6cf063515e1.webp" alt="LangChain4j Chainingskoncept" width="800"/>

*Kedjning av komponenter i LangChain4j - byggstenar kopplas ihop f√∂r att skapa kraftfulla AI-arbetsfl√∂den*

Vi anv√§nder tre k√§rnkomponenter:

**ChatLanguageModel** - Gr√§nssnittet f√∂r AI-modellinteraktioner. Anropa `model.chat("prompt")` och f√• tillbaka en svarstr√§ng. Vi anv√§nder `OpenAiOfficialChatModel` som fungerar med OpenAI-kompatibla slutpunkter som GitHub Models.

**AiServices** - Skapar typs√§kra AI-tj√§nstegr√§nssnitt. Definiera metoder, annotera dem med `@Tool` och LangChain4j sk√∂ter orkestreringen. AI:n anropar automatiskt dina Java-metoder vid behov.

**MessageWindowChatMemory** - Underh√•ller konversationshistorik. Utan detta √§r varje f√∂rfr√•gan oberoende. Med det minns AI:n tidigare meddelanden och uppr√§tth√•ller kontext √∂ver flera v√§ndor.

<img src="../../../translated_images/sv/architecture.eedc993a1c576839.webp" alt="LangChain4j Arkitektur" width="800"/>

*LangChain4j-arkitektur - k√§rnkomponenter som samarbetar f√∂r att driva dina AI-applikationer*

## LangChain4j beroenden

Denna snabbstart anv√§nder tv√• Maven-beroenden i [`pom.xml`](../../../00-quick-start/pom.xml):

```xml
<!-- Core LangChain4j library -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>

<!-- OpenAI integration (works with GitHub Models) -->
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

Modulen `langchain4j-open-ai-official` tillhandah√•ller klassen `OpenAiOfficialChatModel` som kopplar till OpenAI-kompatibla API:er. GitHub Models anv√§nder samma API-format, s√• ingen specialadapter beh√∂vs - peka bara bas-URL:en till `https://models.github.ai/inference`.

## F√∂ruts√§ttningar

**Anv√§nder du Dev Container?** Java och Maven √§r redan installerade. Du beh√∂ver endast en GitHub Personal Access Token.

**Lokal utveckling:**
- Java 21+, Maven 3.9+
- GitHub Personal Access Token (instruktioner nedan)

> **Notera:** Denna modul anv√§nder `gpt-4.1-nano` fr√•n GitHub Models. √Ñndra inte modellnamnet i koden ‚Äì det √§r konfigurerat f√∂r att fungera med GitHubs tillg√§ngliga modeller.

## Installation

### 1. Skaffa din GitHub-token

1. G√• till [GitHub Inst√§llningar ‚Üí Personal Access Tokens](https://github.com/settings/personal-access-tokens)
2. Klicka p√• "Generate new token"
3. S√§tt ett beskrivande namn (t.ex. "LangChain4j Demo")
4. Ange utg√•ngstid (7 dagar rekommenderas)
5. Under "Account permissions" hitta "Models" och s√§tt till "Read-only"
6. Klicka p√• "Generate token"
7. Kopiera och spara din token - du kommer inte se den igen

### 2. S√§tt din token

**Alternativ 1: Anv√§nda VS Code (rekommenderas)**

Om du anv√§nder VS Code, l√§gg till din token i `.env`-filen i projektets rotmapp:

Om `.env`-filen inte finns, kopiera `.env.example` till `.env` eller skapa en ny `.env`-fil i projektets rot.

**Exempel p√• `.env`-fil:**
```bash
# I /workspaces/LangChain4j-for-Beginners/.env
GITHUB_TOKEN=your_token_here
```

Sedan kan du enkelt h√∂gerklicka p√• valfri demo-fil (t.ex. `BasicChatDemo.java`) i Utforskaren och v√§lja **"Run Java"** eller anv√§nda startkonfigurationerna fr√•n panelen K√∂r och Fels√∂k.

**Alternativ 2: Anv√§nda terminal**

S√§tt token som en milj√∂variabel:

**Bash:**
```bash
export GITHUB_TOKEN=your_token_here
```

**PowerShell:**
```powershell
$env:GITHUB_TOKEN=your_token_here
```

## K√∂r exemplen

**Anv√§nder du VS Code:** H√∂gerklicka p√• valfri demo-fil i Utforskaren och v√§lj **"Run Java"**, eller anv√§nd startkonfigurationerna fr√•n panelen K√∂r och Fels√∂k (se till att du f√∂rst lagt till din token i `.env`-filen).

**Anv√§nder du Maven:** Du kan ocks√• k√∂ra via kommandoraden:

### 1. Enkel chatt

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

### 2. Promptm√∂nster

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.PromptEngineeringDemo
```

Visar zero-shot, few-shot, chain-of-thought, och rollbaserad prompting.

### 3. Funktionsanrop

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ToolIntegrationDemo
```

AI:n anropar automatiskt dina Java-metoder vid behov.

### 4. Dokument Q&A (RAG)

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.SimpleReaderDemo
```

St√§ll fr√•gor om inneh√•llet i `document.txt`.

### 5. Ansvarsfull AI

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.ResponsibleAIDemo
```

Se hur AI-s√§kerhetsfilter blockerar skadligt inneh√•ll.

## Vad varje exempel visar

**Enkel chatt** - [BasicChatDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java)

B√∂rja h√§r f√∂r att se LangChain4j i sin enklaste form. Du skapar en `OpenAiOfficialChatModel`, skickar en prompt med `.chat()`, och f√•r tillbaka ett svar. Detta visar grunden: hur man initierar modeller med anpassade slutpunkter och API-nycklar. N√§r du f√∂rst√•r detta m√∂nster bygger allt annat p√• det.

```java
ChatLanguageModel model = OpenAiOfficialChatModel.builder()
    .baseUrl("https://models.github.ai/inference")
    .apiKey(System.getenv("GITHUB_TOKEN"))
    .modelName("gpt-4.1-nano")
    .build();

String response = model.chat("What is LangChain4j?");
System.out.println(response);
```

> **ü§ñ Testa med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`BasicChatDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/BasicChatDemo.java) och fr√•ga:
> - "Hur skulle jag byta fr√•n GitHub Models till Azure OpenAI i denna kod?"
> - "Vilka andra parametrar kan jag konfigurera i OpenAiOfficialChatModel.builder()?"
> - "Hur l√§gger jag till str√∂mningssvar ist√§llet f√∂r att v√§nta p√• komplett svar?"

**Prompt Engineering** - [PromptEngineeringDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java)

Nu n√§r du vet hur du pratar med en modell, l√•t oss utforska vad du s√§ger till den. Denna demo anv√§nder samma modellupps√§ttning men visar fyra olika promptm√∂nster. Testa zero-shot-prompter f√∂r direkta instruktioner, few-shot-prompter som l√§r sig fr√•n exempel, chain-of-thought-prompter som avsl√∂jar resonemangssteg, och rollbaserade prompter som s√§tter kontext. Du ser hur samma modell ger dramatiskt olika resultat beroende p√• hur du formulerar din f√∂rfr√•gan.

```java
PromptTemplate template = PromptTemplate.from(
    "What's the best time to visit {{destination}} for {{activity}}?"
);

Prompt prompt = template.apply(Map.of(
    "destination", "Paris",
    "activity", "sightseeing"
));

String response = model.chat(prompt.text());
```

> **ü§ñ Testa med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`PromptEngineeringDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/PromptEngineeringDemo.java) och fr√•ga:
> - "Vad √§r skillnaden mellan zero-shot och few-shot prompting, och n√§r ska jag anv√§nda vardera?"
> - "Hur p√•verkar temperaturparametern modellens svar?"
> - "Vilka tekniker finns f√∂r att f√∂rebygga promptinjektioner i produktion?"
> - "Hur kan jag skapa √•teranv√§ndbara PromptTemplate-objekt f√∂r vanliga m√∂nster?"

**Verktygsintegration** - [ToolIntegrationDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java)

H√§r blir LangChain4j kraftfullt. Du anv√§nder `AiServices` f√∂r att skapa en AI-assistent som kan anropa dina Java-metoder. M√§rk bara metoder med `@Tool("beskrivning")` och LangChain4j sk√∂ter resten - AI:n best√§mmer automatiskt n√§r varje verktyg ska anv√§ndas baserat p√• vad anv√§ndaren fr√•gar. Detta demonstrerar funktionsanrop, en nyckelteknik f√∂r att bygga AI som kan agera, inte bara svara p√• fr√•gor.

```java
@Tool("Performs addition of two numeric values")
public double add(double a, double b) {
    return a + b;
}

MathAssistant assistant = AiServices.create(MathAssistant.class, model);
String response = assistant.chat("What is 25 plus 17?");
```

> **ü§ñ Testa med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`ToolIntegrationDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ToolIntegrationDemo.java) och fr√•ga:
> - "Hur fungerar @Tool-annoteringen och vad g√∂r LangChain4j med den bakom kulisserna?"
> - "Kan AI anropa flera verktyg i f√∂ljd f√∂r att l√∂sa komplexa problem?"
> - "Vad h√§nder om ett verktyg kastar ett undantag - hur borde jag hantera fel?"
> - "Hur skulle jag integrera ett riktigt API ist√§llet f√∂r detta kalkylexempel?"

**Dokument Q&A (RAG)** - [SimpleReaderDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java)

H√§r ser du grunden f√∂r RAG (retrieval-augmented generation). Ist√§llet f√∂r att f√∂rlita dig p√• modellens tr√§ningsdata laddar du inneh√•ll fr√•n [`document.txt`](../../../00-quick-start/document.txt) och inkluderar det i prompten. AI:n svarar baserat p√• ditt dokument, inte dess allm√§nna kunskap. Detta √§r f√∂rsta steget mot att bygga system som kan arbeta med dina egna data.

```java
Document document = FileSystemDocumentLoader.loadDocument("document.txt");
String content = document.text();

String prompt = "Based on this document: " + content + 
                "\nQuestion: What is the main topic?";
String response = model.chat(prompt);
```

> **Notera:** Denna enkla metod laddar hela dokumentet i prompten. F√∂r stora filer (>10KB) √∂verskrider du kontextgr√§nser. Modul 03 t√§cker chunking och vektors√∂kning f√∂r produktions-RAG-system.

> **ü§ñ Testa med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`SimpleReaderDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/SimpleReaderDemo.java) och fr√•ga:
> - "Hur f√∂rhindrar RAG AI-hallucinationer j√§mf√∂rt med att anv√§nda modellens tr√§ningsdata?"
> - "Vad √§r skillnaden mellan denna enkla metod och att anv√§nda vektorembeddingar f√∂r h√§mtning?"
> - "Hur skulle jag skala detta f√∂r att hantera flera dokument eller st√∂rre kunskapsbaser?"
> - "Vilka √§r b√§sta metoder f√∂r att strukturera prompten s√• att AI bara anv√§nder den angivna kontexten?"

**Ansvarsfull AI** - [ResponsibleAIDemo.java](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java)

Bygg AI-s√§kerhet med f√∂rsvar i djupet. Denna demo visar tv√• skyddslager som samarbetar:

**Del 1: LangChain4j Input Guardrails** - Blockera farliga promptar innan de n√•r LLM. Skapa egna skyddslinjer som kontrollerar f√∂rbjudna nyckelord eller m√∂nster. Dessa k√∂rs i din kod, s√• de √§r snabba och kostnadsfria.

```java
class DangerousContentGuardrail implements InputGuardrail {
    @Override
    public InputGuardrailResult validate(UserMessage userMessage) {
        String text = userMessage.singleText().toLowerCase();
        if (text.contains("explosives")) {
            return fatal("Blocked: contains prohibited keyword");
        }
        return success();
    }
}
```

**Del 2: Provider Safety Filters** - GitHub Models har inbyggda filter som f√•ngar vad dina skyddslinjer kan missa. Du ser h√•rda blockeringar (HTTP 400-fel) f√∂r allvarliga √∂vertr√§delser och mjuka avslag d√§r AI artigt v√§grar.

> **ü§ñ Testa med [GitHub Copilot](https://github.com/features/copilot) Chat:** √ñppna [`ResponsibleAIDemo.java`](../../../00-quick-start/src/main/java/com/example/langchain4j/quickstart/ResponsibleAIDemo.java) och fr√•ga:
> - "Vad √§r InputGuardrail och hur skapar jag min egen?"
> - "Vad √§r skillnaden mellan ett h√•rt block och ett mjukt avslag?"
> - "Varf√∂r anv√§nda b√•de skyddslinjer och leverant√∂rsfilter tillsammans?"

## N√§sta steg

**N√§sta modul:** [01-introduction - Kom ig√•ng med LangChain4j och gpt-5 p√• Azure](../01-introduction/README.md)

---

**Navigering:** [‚Üê Tillbaka till huvudmenyn](../README.md) | [N√§sta: Modul 01 - Introduktion ‚Üí](../01-introduction/README.md)

---

## Fels√∂kning

### F√∂rsta byggningen med Maven

**Problem**: Initial `mvn clean compile` eller `mvn package` tar l√•ng tid (10-15 minuter)

**Orsak**: Maven beh√∂ver ladda ner alla projektsberoenden (Spring Boot, LangChain4j-bibliotek, Azure SDK:er etc.) vid f√∂rsta bygget.

**L√∂sning**: Detta √§r normalt. Efterf√∂ljande byggen g√•r mycket snabbare d√• beroenden √§r cachade lokalt. Nedladdningstiden beror p√• din n√§tverkshastighet.

### PowerShell Maven-kommandsyntax

**Problem**: Maven-kommandon misslyckas med felmeddelandet `Unknown lifecycle phase ".mainClass=..."`

**Orsak**: PowerShell tolkar `=` som en variabeltilldelningsoperator och bryter Maven-egenskapsyntaxen.
**L√∂sning**: Anv√§nd stopp-analysoperatorn `--%` f√∂re Maven-kommandot:

**PowerShell:**
```powershell
mvn --% compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

**Bash:**
```bash
mvn compile exec:java -Dexec.mainClass=com.example.langchain4j.quickstart.BasicChatDemo
```

Operatorn `--%` talar om f√∂r PowerShell att skicka alla √•terst√•ende argument bokstavligt till Maven utan tolkning.

### Emoji-visning i Windows PowerShell

**Problem**: AI-svar visar skr√§ptecken (t.ex. `????` eller `√¢??`) ist√§llet f√∂r emojis i PowerShell

**Orsak**: PowerShells standardkodning st√∂djer inte UTF-8-emojis

**L√∂sning**: K√∂r detta kommando innan du k√∂r Java-applikationer:
```cmd
chcp 65001
```

Detta tvingar UTF-8-kodning i terminalen. Alternativt kan du anv√§nda Windows Terminal som har b√§ttre Unicode-st√∂d.

### Fels√∂kning av API-anrop

**Problem**: Autentiseringsfel, begr√§nsningar p√• antal f√∂rfr√•gningar eller ov√§ntade svar fr√•n AI-modellen

**L√∂sning**: Exemplen inkluderar `.logRequests(true)` och `.logResponses(true)` f√∂r att visa API-anrop i konsolen. Detta hj√§lper till att fels√∂ka autentiseringsfel, begr√§nsningar eller ov√§ntade svar. Ta bort dessa flaggor i produktion f√∂r att minska loggbrus.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfriskrivning**:
Detta dokument har √∂versatts med AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, v√§nligen observera att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktorit√§ra k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->