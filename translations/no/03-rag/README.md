<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "81d087662fb3dd7b7124bce1a9c9ec86",
  "translation_date": "2026-01-05T23:50:23+00:00",
  "source_file": "03-rag/README.md",
  "language_code": "no"
}
-->
# Module 03: RAG (Retrieval-Augmented Generation)

## Innholdsfortegnelse

- [Hva du vil l√¶re](../../../03-rag)
- [Forutsetninger](../../../03-rag)
- [Forst√• RAG](../../../03-rag)
- [Hvordan det fungerer](../../../03-rag)
  - [Dokumentbehandling](../../../03-rag)
  - [Opprette embeddings](../../../03-rag)
  - [Semantisk s√∏k](../../../03-rag)
  - [Svar-generering](../../../03-rag)
- [Kj√∏r applikasjonen](../../../03-rag)
- [Bruke applikasjonen](../../../03-rag)
  - [Last opp et dokument](../../../03-rag)
  - [Still sp√∏rsm√•l](../../../03-rag)
  - [Sjekk kildehenvisninger](../../../03-rag)
  - [Eksperimenter med sp√∏rsm√•l](../../../03-rag)
- [N√∏kkelkonsepter](../../../03-rag)
  - [Chunking-strategi](../../../03-rag)
  - [Likhetspoeng](../../../03-rag)
  - [Minnebasert lagring](../../../03-rag)
  - [Kontekst-vinduh√•ndtering](../../../03-rag)
- [N√•r RAG er viktig](../../../03-rag)
- [Neste steg](../../../03-rag)

## Hva du vil l√¶re

I de forrige modulene l√¶rte du hvordan du kan f√∏re samtaler med AI og strukturere promptene dine effektivt. Men det finnes en grunnleggende begrensning: spr√•kmodeller vet bare det de l√¶rte under treningen. De kan ikke svare p√• sp√∏rsm√•l om din bedrifts retningslinjer, ditt prosjektdokumentasjon, eller annen informasjon de ikke er trent p√•.

RAG (Retrieval-Augmented Generation) l√∏ser dette problemet. I stedet for √• pr√∏ve √• l√¶re modellen din informasjon (noe som er dyrt og upraktisk), gir du den muligheten til √• s√∏ke gjennom dokumentene dine. N√•r noen stiller et sp√∏rsm√•l, finner systemet relevant informasjon og inkluderer det i prompten. Modellen svarer s√• basert p√• den hentede konteksten.

Tenk p√• RAG som √• gi modellen et referansebibliotek. N√•r du stiller et sp√∏rsm√•l, gj√∏r systemet:

1. **Brukersp√∏rsm√•l** - Du stiller et sp√∏rsm√•l  
2. **Embedding** - Konverterer sp√∏rsm√•let ditt til en vektor  
3. **Vektors√∏k** - Finner lignende dokumentbiter  
4. **Kontekstsamling** - Legger relevante biter til prompten  
5. **Svar** - LLM genererer et svar basert p√• konteksten  

Dette forankrer modellens svar i dine faktiske data i stedet for √• stole p√• treningskunnskap eller √• finne p√• svar.

<img src="../../../translated_images/rag-architecture.ccb53b71a6ce407f.no.png" alt="RAG Architecture" width="800"/>

*RAG arbeidsflyt - fra brukersp√∏rsm√•l til semantisk s√∏k til kontekstuell svar-generering*

## Forutsetninger

- Fullf√∏rt modul 01 (Azure OpenAI-ressurser distribuert)  
- `.env`-fil i rotmappen med Azure-legitimasjon (laget av `azd up` i modul 01)  

> **Merk:** Hvis du ikke har fullf√∏rt modul 01, f√∏lg distribusjonsinstruksjonene der f√∏rst.

## Hvordan det fungerer

### Dokumentbehandling

[DocumentService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java)

N√•r du laster opp et dokument, deler systemet det opp i biter ‚Äì mindre deler som passer komfortabelt i modellens kontekstvindu. Disse bitene overlapper litt for at du ikke skal miste kontekst ved grensen mellom dem.

```java
Document document = FileSystemDocumentLoader.loadDocument("sample-document.txt");

DocumentSplitter splitter = DocumentSplitters
    .recursive(300, 30, new OpenAiTokenizer());

List<TextSegment> segments = splitter.split(document);
```
  
> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öpne [`DocumentService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/DocumentService.java) og sp√∏r:  
> - "Hvordan deler LangChain4j dokumenter i biter, og hvorfor er overlapp viktig?"  
> - "Hva er optimal bit-st√∏rrelse for ulike dokumenttyper og hvorfor?"  
> - "Hvordan h√•ndterer jeg dokumenter p√• flere spr√•k eller med spesiell formatering?"

### Opprette embeddings

[LangChainRagConfig.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/config/LangChainRagConfig.java)

Hver bit blir konvertert til en numerisk representasjon kalt en embedding ‚Äì i praksis et matematisk fingeravtrykk som fanger meningen i teksten. Lignende tekst gir lignende embeddings.

```java
@Bean
public EmbeddingModel embeddingModel() {
    return OpenAiOfficialEmbeddingModel.builder()
        .baseUrl(azureOpenAiEndpoint)
        .apiKey(azureOpenAiKey)
        .modelName(azureEmbeddingDeploymentName)
        .build();
}

EmbeddingStore<TextSegment> embeddingStore = 
    new InMemoryEmbeddingStore<>();
```
  
<img src="../../../translated_images/vector-embeddings.2ef7bdddac79a327.no.png" alt="Vector Embeddings Space" width="800"/>

*Dokumenter representert som vektorer i embedding-rom ‚Äì lignende innhold grupperes sammen*

### Semantisk s√∏k

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

N√•r du stiller et sp√∏rsm√•l, blir sp√∏rsm√•let ditt ogs√• en embedding. Systemet sammenligner sp√∏rsm√•lets embedding med embeddingene til alle dokumentbitene. Det finner de bitene med mest lignende mening ‚Äì ikke bare matchende n√∏kkelord, men faktisk semantisk likhet.

```java
Embedding queryEmbedding = embeddingModel.embed(question).content();

List<EmbeddingMatch<TextSegment>> matches = 
    embeddingStore.findRelevant(queryEmbedding, 5, 0.7);

for (EmbeddingMatch<TextSegment> match : matches) {
    String relevantText = match.embedded().text();
    double score = match.score();
}
```
  
> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öpne [`RagService.java`](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java) og sp√∏r:  
> - "Hvordan fungerer likhetss√∏k med embeddings, og hva avgj√∏r poengsummen?"  
> - "Hvilken likhetsterskel b√∏r jeg bruke, og hvordan p√•virker det resultatene?"  
> - "Hvordan h√•ndterer jeg tilfeller der ingen relevante dokumenter finnes?"

### Svar-generering

[RagService.java](../../../03-rag/src/main/java/com/example/langchain4j/rag/service/RagService.java)

De mest relevante bitene inkluderes i prompten til modellen. Modellen leser disse bitene og svarer p√• sp√∏rsm√•let ditt basert p√• denne informasjonen. Dette forhindrer hallusinasjoner ‚Äì modellen kan bare svare ut fra det den har foran seg.

## Kj√∏r applikasjonen

**Verifiser distribusjon:**  

S√∏rg for at `.env`-filen finnes i rotmappen med Azure-legitimasjon (laget under modul 01):  
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```
  
**Start applikasjonen:**  

> **Merk:** Hvis du allerede har startet alle applikasjonene ved bruk av `./start-all.sh` fra modul 01, kj√∏rer denne modulen allerede p√• port 8081. Du kan hoppe over start-kommandoene under og g√• direkte til http://localhost:8081.

**Alternativ 1: Bruke Spring Boot Dashboard (Anbefalt for VS Code-brukere)**  

Dev containeren inkluderer Spring Boot Dashboard-utvidelsen, som gir et visuelt grensesnitt for √• administrere alle Spring Boot-applikasjoner. Du finner det i Aktivitetslinjen p√• venstre side i VS Code (se etter Spring Boot-ikonet).

Fra Spring Boot Dashboard kan du:  
- Se alle tilgjengelige Spring Boot-applikasjoner i arbeidsomr√•det  
- Starte/stopp applikasjoner med ett klikk  
- Se applikasjonslogger i sanntid  
- Overv√•ke applikasjonsstatus  

Klikk bare p√• "play"-knappen ved siden av "rag" for √• starte denne modulen, eller start alle moduler samtidig.

<img src="../../../translated_images/dashboard.fbe6e28bf4267ffe.no.png" alt="Spring Boot Dashboard" width="400"/>

**Alternativ 2: Bruke shell-skript**

Start alle webapplikasjoner (moduler 01-04):

**Bash:**  
```bash
cd ..  # Fra rotkatalog
./start-all.sh
```
  
**PowerShell:**  
```powershell
cd ..  # Fra rotkatalogen
.\start-all.ps1
```
  
Eller start bare denne modulen:

**Bash:**  
```bash
cd 03-rag
./start.sh
```
  
**PowerShell:**  
```powershell
cd 03-rag
.\start.ps1
```
  
Begge skriptene laster automatisk milj√∏variabler fra rotens `.env`-fil og bygger JAR-filene hvis de ikke finnes.

> **Merk:** Hvis du foretrekker √• bygge alle moduler manuelt f√∏r du starter:  
>  
> **Bash:**  
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
> **PowerShell:**  
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
  
√Öpne http://localhost:8081 i nettleseren din.

**For √• stoppe:**  

**Bash:**  
```bash
./stop.sh  # Bare denne modulen
# Eller
cd .. && ./stop-all.sh  # Alle moduler
```
  
**PowerShell:**  
```powershell
.\stop.ps1  # Bare denne modulen
# Eller
cd ..; .\stop-all.ps1  # Alle moduler
```
  
## Bruke applikasjonen

Applikasjonen tilbyr et webgrensesnitt for dokumentopplasting og sp√∏rsm√•l.

<a href="images/rag-homepage.png"><img src="../../../translated_images/rag-homepage.d90eb5ce1b3caa94.no.png" alt="RAG Application Interface" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*RAG applikasjonsgrensesnitt ‚Äì last opp dokumenter og still sp√∏rsm√•l*

### Last opp et dokument

Begynn med √• laste opp et dokument ‚Äì TXT-filer fungerer best for testing. En `sample-document.txt` er lagt ved i denne mappen som inneholder informasjon om LangChain4j-funksjoner, RAG-implementering og beste praksis ‚Äì perfekt for √• teste systemet.

Systemet prosesserer dokumentet ditt, deler det i biter, og lager embeddings for hver bit. Dette skjer automatisk n√•r du laster opp.

### Still sp√∏rsm√•l

Still n√• spesifikke sp√∏rsm√•l om dokumentinnholdet. Pr√∏v noe faktabaserte som er tydelig angitt i dokumentet. Systemet s√∏ker etter relevante biter, inkluderer dem i prompten, og genererer et svar.

### Sjekk kildehenvisninger

Merk at hvert svar inkluderer kildehenvisninger med likhetspoeng. Disse poengene (fra 0 til 1) viser hvor relevant hver bit var for sp√∏rsm√•let ditt. H√∏yere poeng betyr bedre treff. Dette lar deg verifisere svaret mot kildematerialet.

<a href="images/rag-query-results.png"><img src="../../../translated_images/rag-query-results.6d69fcec5397f355.no.png" alt="RAG Query Results" width="800" style="border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.1);"/></a>

*Sp√∏rringsresultater som viser svar med kildehenvisninger og relevanspoeng*

### Eksperimenter med sp√∏rsm√•l

Pr√∏v ulike typer sp√∏rsm√•l:  
- Spesifikke fakta: "Hva er hovedtemaet?"  
- Sammenligninger: "Hva er forskjellen mellom X og Y?"  
- Sammendrag: "Oppsummer hovedpunktene om Z"

Se hvordan relevanspoengene endres basert p√• hvor godt sp√∏rsm√•let ditt matcher dokumentinnholdet.

## N√∏kkelkonsepter

### Chunking-strategi

Dokumenter deles opp i 300-token biter med 30 token overlapp. Denne balansen sikrer at hver bit har nok kontekst til √• v√¶re meningsfull, samtidig som det er sm√• nok biter til √• inkludere flere i en prompt.

### Likhetspoeng

Poengene g√•r fra 0 til 1:  
- 0.7-1.0: Sv√¶rt relevant, eksakt treff  
- 0.5-0.7: Relevant, god kontekst  
- Under 0.5: Filtrert ut, for ulik  

Systemet henter kun biter over minimumsterskelen for √• sikre kvalitet.

### Minnebasert lagring

Denne modulen bruker minnelagring for enkelhetens skyld. N√•r du starter applikasjonen p√• nytt, g√•r opplastede dokumenter tapt. Produksjonssystemer bruker persistente vektordatabaser som Qdrant eller Azure AI Search.

### Kontekst-vinduh√•ndtering

Hver modell har et maksimalt kontekstvindu. Du kan ikke inkludere hver bit fra et stort dokument. Systemet henter de top N mest relevante bitene (standard 5) for √• holde seg innenfor begrensningene samtidig som det gir nok kontekst til n√∏yaktige svar.

## N√•r RAG er viktig

**Bruk RAG n√•r:**  
- Du skal svare p√• sp√∏rsm√•l om propriet√¶re dokumenter  
- Informasjonen endres ofte (retningslinjer, priser, spesifikasjoner)  
- N√∏yaktighet krever kildehenvisning  
- Innholdet er for stort til √• passe i en enkelt prompt  
- Du trenger etterpr√∏vbare, forankrede svar  

**Ikke bruk RAG n√•r:**  
- Sp√∏rsm√•l krever generell kunnskap modellen allerede har  
- Sanntidsdata er n√∏dvendig (RAG bruker opplastede dokumenter)  
- Innholdet er lite nok til √• inkluderes direkte i promptene  

## Neste steg

**Neste modul:** [04-tools - AI Agents with Tools](../04-tools/README.md)

---

**Navigasjon:** [‚Üê Forrige: Modul 02 - Prompt Engineering](../02-prompt-engineering/README.md) | [Tilbake til hovedsiden](../README.md) | [Neste: Modul 04 - Tools ‚Üí](../04-tools/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi etterstreber n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• sitt originale spr√•k skal betraktes som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->