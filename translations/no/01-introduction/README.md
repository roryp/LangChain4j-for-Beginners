<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c3e07ca58d0b8a3f47d3bf5728541e0a",
  "translation_date": "2025-12-13T13:42:53+00:00",
  "source_file": "01-introduction/README.md",
  "language_code": "no"
}
-->
# Module 01: Komme i gang med LangChain4j

## Innholdsfortegnelse

- [Hva du vil l√¶re](../../../01-introduction)
- [Forutsetninger](../../../01-introduction)
- [Forst√• kjernen i problemet](../../../01-introduction)
- [Forst√• tokens](../../../01-introduction)
- [Hvordan minne fungerer](../../../01-introduction)
- [Hvordan dette bruker LangChain4j](../../../01-introduction)
- [Distribuer Azure OpenAI-infrastruktur](../../../01-introduction)
- [Kj√∏r applikasjonen lokalt](../../../01-introduction)
- [Bruke applikasjonen](../../../01-introduction)
  - [Stateless Chat (venstre panel)](../../../01-introduction)
  - [Stateful Chat (h√∏yre panel)](../../../01-introduction)
- [Neste steg](../../../01-introduction)

## Hva du vil l√¶re

Hvis du fullf√∏rte hurtigstarten, s√• du hvordan du sender prompts og f√•r svar. Det er grunnlaget, men ekte applikasjoner trenger mer. Denne modulen l√¶rer deg hvordan du bygger konversasjons-AI som husker kontekst og opprettholder tilstand ‚Äì forskjellen mellom en engangs-demo og en produksjonsklar applikasjon.

Vi bruker Azure OpenAI sin GPT-5 gjennom hele denne guiden fordi dens avanserte resonneringsevner gj√∏r oppf√∏rselen til ulike m√∏nstre mer tydelig. N√•r du legger til minne, vil du klart se forskjellen. Dette gj√∏r det enklere √• forst√• hva hver komponent tilf√∏rer applikasjonen din.

Du vil bygge √©n applikasjon som demonstrerer begge m√∏nstrene:

**Stateless Chat** ‚Äì Hver foresp√∏rsel er uavhengig. Modellen har ikke noe minne om tidligere meldinger. Dette er m√∏nsteret du brukte i hurtigstarten.

**Stateful Conversation** ‚Äì Hver foresp√∏rsel inkluderer samtalehistorikk. Modellen opprettholder kontekst over flere runder. Dette er hva produksjonsapplikasjoner krever.

## Forutsetninger

- Azure-abonnement med tilgang til Azure OpenAI
- Java 21, Maven 3.9+
- Azure CLI (https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)
- Azure Developer CLI (azd) (https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/install-azd)

> **Merk:** Java, Maven, Azure CLI og Azure Developer CLI (azd) er forh√•ndsinstallert i den medf√∏lgende devcontaineren.

> **Merk:** Denne modulen bruker GPT-5 p√• Azure OpenAI. Distribusjonen konfigureres automatisk via `azd up` ‚Äì ikke endre modellnavnet i koden.

## Forst√• kjernen i problemet

Spr√•kmodeller er stateless. Hver API-kall er uavhengig. Hvis du sender "Mitt navn er John" og deretter sp√∏r "Hva er navnet mitt?", har ikke modellen noen anelse om at du nettopp introduserte deg. Den behandler hver foresp√∏rsel som om det er den f√∏rste samtalen du noen gang har hatt.

Dette er greit for enkle sp√∏rsm√•l og svar, men ubrukelig for ekte applikasjoner. Kundeserviceboter m√• huske hva du fortalte dem. Personlige assistenter trenger kontekst. Enhver samtale med flere runder krever minne.

<img src="../../../translated_images/stateless-vs-stateful.cc4a4765e649c41a.no.png" alt="Stateless vs Stateful Conversations" width="800"/>

*Forskjellen mellom stateless (uavhengige kall) og stateful (kontekstbevisste) samtaler*

## Forst√• tokens

F√∏r du dykker inn i samtaler, er det viktig √• forst√• tokens ‚Äì de grunnleggende tekst-enhetene som spr√•kmodeller behandler:

<img src="../../../translated_images/token-explanation.c39760d8ec650181.no.png" alt="Token Explanation" width="800"/>

*Eksempel p√• hvordan tekst deles opp i tokens ‚Äì "I love AI!" blir til 4 separate behandlingsenheter*

Tokens er hvordan AI-modeller m√•ler og behandler tekst. Ord, tegnsetting og til og med mellomrom kan v√¶re tokens. Modellen din har en grense for hvor mange tokens den kan behandle samtidig (400 000 for GPT-5, med opptil 272 000 input-tokens og 128 000 output-tokens). √Ö forst√• tokens hjelper deg √• styre samtalelengde og kostnader.

## Hvordan minne fungerer

Chat-minne l√∏ser det stateless problemet ved √• opprettholde samtalehistorikk. F√∏r du sender foresp√∏rselen til modellen, legger rammeverket til relevante tidligere meldinger foran. N√•r du sp√∏r "Hva er navnet mitt?", sender systemet faktisk hele samtalehistorikken, slik at modellen kan se at du tidligere sa "Mitt navn er John."

LangChain4j tilbyr minneimplementasjoner som h√•ndterer dette automatisk. Du velger hvor mange meldinger som skal beholdes, og rammeverket styrer kontekstvinduet.

<img src="../../../translated_images/memory-window.bbe67f597eadabb3.no.png" alt="Memory Window Concept" width="800"/>

*MessageWindowChatMemory opprettholder et glidende vindu med nylige meldinger, og fjerner automatisk gamle*

## Hvordan dette bruker LangChain4j

Denne modulen utvider hurtigstarten ved √• integrere Spring Boot og legge til samtaleminne. Slik passer delene sammen:

**Avhengigheter** ‚Äì Legg til to LangChain4j-biblioteker:

```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-open-ai-official</artifactId> <!-- Inherited from BOM in root pom.xml -->
</dependency>
```

**Chat-modell** ‚Äì Konfigurer Azure OpenAI som en Spring bean ([LangChainConfig.java](../../../01-introduction/src/main/java/com/example/langchain4j/config/LangChainConfig.java)):

```java
@Bean
public OpenAiOfficialChatModel openAiOfficialChatModel() {
    return OpenAiOfficialChatModel.builder()
            .baseUrl(azureEndpoint)
            .apiKey(azureApiKey)
            .modelName(deploymentName)
            .timeout(Duration.ofMinutes(5))
            .maxRetries(3)
            .build();
}
```

Builderen leser legitimasjon fra milj√∏variabler satt av `azd up`. √Ö sette `baseUrl` til din Azure-endepunkt gj√∏r at OpenAI-klienten fungerer med Azure OpenAI.

**Samtaleminne** ‚Äì Spor chat-historikk med MessageWindowChatMemory ([ConversationService.java](../../../01-introduction/src/main/java/com/example/langchain4j/service/ConversationService.java)):

```java
ChatMemory memory = MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("My name is John"));
memory.add(AiMessage.from("Nice to meet you, John!"));

memory.add(UserMessage.from("What's my name?"));
AiMessage aiMessage = chatModel.chat(memory.messages()).aiMessage();
memory.add(aiMessage);
```

Opprett minne med `withMaxMessages(10)` for √• beholde de siste 10 meldingene. Legg til bruker- og AI-meldinger med typede wrappers: `UserMessage.from(text)` og `AiMessage.from(text)`. Hent historikk med `memory.messages()` og send den til modellen. Tjenesten lagrer separate minneinstanser per samtale-ID, slik at flere brukere kan chatte samtidig.

> **ü§ñ Pr√∏v med [GitHub Copilot](https://github.com/features/copilot) Chat:** √Öpne [`ConversationService.java`](../../../01-introduction/src/main/java/com/example/langchain4j/service/ConversationService.java) og sp√∏r:
> - "Hvordan bestemmer MessageWindowChatMemory hvilke meldinger som skal droppes n√•r vinduet er fullt?"
> - "Kan jeg implementere egendefinert minnelagring ved √• bruke en database i stedet for minne?"
> - "Hvordan kan jeg legge til oppsummering for √• komprimere gammel samtalehistorikk?"

Stateless chat-endepunktet hopper over minne helt ‚Äì bare `chatModel.chat(prompt)` som i hurtigstarten. Stateful endepunkt legger til meldinger i minnet, henter historikk og inkluderer den konteksten med hver foresp√∏rsel. Samme modellkonfigurasjon, forskjellige m√∏nstre.

## Distribuer Azure OpenAI-infrastruktur

**Bash:**
```bash
cd 01-introduction
azd up  # Velg abonnement og plassering (eastus2 anbefales)
```

**PowerShell:**
```powershell
cd 01-introduction
azd up  # Velg abonnement og plassering (eastus2 anbefales)
```

> **Merk:** Hvis du f√•r en timeout-feil (`RequestConflict: Cannot modify resource ... provisioning state is not terminal`), kj√∏r bare `azd up` p√• nytt. Azure-ressurser kan fortsatt v√¶re under provisjonering i bakgrunnen, og et nytt fors√∏k lar distribusjonen fullf√∏res n√•r ressursene n√•r en terminal tilstand.

Dette vil:
1. Distribuere Azure OpenAI-ressurs med GPT-5 og text-embedding-3-small modeller
2. Automatisk generere `.env`-fil i prosjektets rot med legitimasjon
3. Sette opp alle n√∏dvendige milj√∏variabler

**Har du problemer med distribusjonen?** Se [Infrastructure README](infra/README.md) for detaljert feils√∏king inkludert konflikter med subdomener, manuelle distribusjonstrinn i Azure Portal og veiledning for modellkonfigurasjon.

**Bekreft at distribusjonen lyktes:**

**Bash:**
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, osv.
```

**PowerShell:**
```powershell
Get-Content ..\.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, osv.
```

> **Merk:** Kommandoen `azd up` genererer automatisk `.env`-filen. Hvis du trenger √• oppdatere den senere, kan du enten redigere `.env`-filen manuelt eller regenerere den ved √• kj√∏re:
>
> **Bash:**
> ```bash
> cd ..
> bash .azd-env.sh
> ```
>
> **PowerShell:**
> ```powershell
> cd ..
> .\.azd-env.ps1
> ```

## Kj√∏r applikasjonen lokalt

**Bekreft distribusjon:**

S√∏rg for at `.env`-filen finnes i rotkatalogen med Azure-legitimasjon:

**Bash:**
```bash
cat ../.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**PowerShell:**
```powershell
Get-Content ..\.env  # Skal vise AZURE_OPENAI_ENDPOINT, API_KEY, DEPLOYMENT
```

**Start applikasjonene:**

**Alternativ 1: Bruke Spring Boot Dashboard (anbefalt for VS Code-brukere)**

Devcontaineren inkluderer Spring Boot Dashboard-utvidelsen, som gir et visuelt grensesnitt for √• administrere alle Spring Boot-applikasjoner. Du finner den i aktivitetslinjen p√• venstre side i VS Code (se etter Spring Boot-ikonet).

Fra Spring Boot Dashboard kan du:
- Se alle tilgjengelige Spring Boot-applikasjoner i arbeidsomr√•det
- Starte/stoppe applikasjoner med ett klikk
- Se applikasjonslogger i sanntid
- Overv√•ke applikasjonsstatus

Klikk bare p√• play-knappen ved siden av "introduction" for √• starte denne modulen, eller start alle moduler samtidig.

<img src="../../../translated_images/dashboard.69c7479aef09ff6b.no.png" alt="Spring Boot Dashboard" width="400"/>

**Alternativ 2: Bruke shell-skript**

Start alle webapplikasjoner (moduler 01-04):

**Bash:**
```bash
cd ..  # Fra rotkatalogen
./start-all.sh
```

**PowerShell:**
```powershell
cd ..  # Fra rotkatalogen
.\start-all.ps1
```

Eller start bare denne modulen:

**Bash:**
```bash
cd 01-introduction
./start.sh
```

**PowerShell:**
```powershell
cd 01-introduction
.\start.ps1
```

Begge skriptene laster automatisk milj√∏variabler fra rotens `.env`-fil og bygger JAR-filene hvis de ikke finnes.

> **Merk:** Hvis du foretrekker √• bygge alle moduler manuelt f√∏r oppstart:
>
> **Bash:**
> ```bash
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```
>
> **PowerShell:**
> ```powershell
> cd ..  # Go to root directory
> mvn clean package -DskipTests
> ```

√Öpne http://localhost:8080 i nettleseren din.

**For √• stoppe:**

**Bash:**
```bash
./stop.sh  # Kun denne modulen
# Eller
cd .. && ./stop-all.sh  # Alle moduler
```

**PowerShell:**
```powershell
.\stop.ps1  # Kun denne modulen
# Eller
cd ..; .\stop-all.ps1  # Alle moduler
```

## Bruke applikasjonen

Applikasjonen tilbyr et webgrensesnitt med to chat-implementasjoner side om side.

<img src="../../../translated_images/home-screen.121a03206ab910c0.no.png" alt="Application Home Screen" width="800"/>

*Dashboard som viser b√•de Simple Chat (stateless) og Conversational Chat (stateful) alternativer*

### Stateless Chat (venstre panel)

Pr√∏v dette f√∏rst. Sp√∏r "Mitt navn er John" og deretter umiddelbart "Hva er navnet mitt?" Modellen vil ikke huske fordi hver melding er uavhengig. Dette demonstrerer kjernen i problemet med grunnleggende spr√•kmodellintegrasjon ‚Äì ingen samtalekontekst.

<img src="../../../translated_images/simple-chat-stateless-demo.13aeb3978eab3234.no.png" alt="Stateless Chat Demo" width="800"/>

*AI husker ikke navnet ditt fra forrige melding*

### Stateful Chat (h√∏yre panel)

Pr√∏v n√• samme sekvens her. Sp√∏r "Mitt navn er John" og deretter "Hva er navnet mitt?" Denne gangen husker den. Forskjellen er MessageWindowChatMemory ‚Äì den opprettholder samtalehistorikk og inkluderer den med hver foresp√∏rsel. Slik fungerer produksjonsklar konversasjons-AI.

<img src="../../../translated_images/conversational-chat-stateful-demo.e5be9822eb23ff59.no.png" alt="Stateful Chat Demo" width="800"/>

*AI husker navnet ditt fra tidligere i samtalen*

Begge panelene bruker samme GPT-5-modell. Den eneste forskjellen er minne. Dette gj√∏r det tydelig hva minne tilf√∏rer applikasjonen din og hvorfor det er essensielt for reelle bruksomr√•der.

## Neste steg

**Neste modul:** [02-prompt-engineering - Prompt Engineering med GPT-5](../02-prompt-engineering/README.md)

---

**Navigasjon:** [‚Üê Forrige: Module 00 - Quick Start](../00-quick-start/README.md) | [Tilbake til hovedmeny](../README.md) | [Neste: Module 02 - Prompt Engineering ‚Üí](../02-prompt-engineering/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• originalspr√•ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->